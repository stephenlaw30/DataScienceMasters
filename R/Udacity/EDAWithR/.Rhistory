schedule <- data.frame(rbind(row1,row2,row3,row4,row5,row6,row7,row8,row9,row10,row11,row12,row13,row14,row15,row16,row17),
row.names = NULL)
# rename data frame columns
colnames(schedule) <- headers
# fix BYE WEEK
schedule
glimpse(schedule)
schedule[:,:5]
schedule[,:5]
schedule[,1:5]
schedule[,1:4]
schedule <- schedule[,1:4]
library(rtweet) # get tweets
library(dplyr)
library(magick)
library(stringr)
library(kableExtra)
library(knitr)
library(text2vec) #sentiment analysis
library(tm) #text mining (get_nrc_sentiment)
library(syuzhet) # nrc-word emotion associate lexicon
library(rvest) # html scraping
# Specifying url for site to be scraped
url <- 'http://www.espn.com/nfl/team/schedule/_/name/phi/philadelphia-eagles'
# Reading HTML code from the website
webpage <- read_html(url)
# get html from specific CSS selector from webpage
date_data_html <- html_nodes(webpage,'tr td')
# convert this data structure to text
date_data_text <- html_text(date_data_html)
# limit to just regular season
reg_season <- date_data_text[27:length(date_data_text)]
# get column headings from vector
headers <- reg_season[2:6]
# loops to get all game data into rows for each week
n = 7
i = 1
while (n < 52) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# BYE week causes some issues
assign(paste('row', as.character(10), sep = ''), reg_season[52:53])
n = 54
i = 11
while (n < length(reg_season)) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# build data frame
schedule <- data.frame(rbind(row1,row2,row3,row4,row5,row6,row7,row8,row9,row10,row11,row12,row13,row14,row15,row16,row17),
row.names = NULL)
# rename data frame columns
colnames(schedule) <- headers
# remove tickets column
schedule <- schedule[,1:4]
schedule
schedule$WK <- as.integer(schedule$WK)
schedule$DATE <- as.character(schedule$DATE)
schedule$OPPONENT <- as.character(schedule$OPPONENT)
schedule$`TIME (ET)` <- as.integer(schedule$`TIME (ET)`)
glimpse(schedule)
library(rtweet) # get tweets
library(dplyr)
library(magick)
library(stringr)
library(kableExtra)
library(knitr)
library(text2vec) #sentiment analysis
library(tm) #text mining (get_nrc_sentiment)
library(syuzhet) # nrc-word emotion associate lexicon
library(rvest) # html scraping
# Specifying url for site to be scraped
url <- 'http://www.espn.com/nfl/team/schedule/_/name/phi/philadelphia-eagles'
# Reading HTML code from the website
webpage <- read_html(url)
# get html from specific CSS selector from webpage
date_data_html <- html_nodes(webpage,'tr td')
# convert this data structure to text
date_data_text <- html_text(date_data_html)
# limit to just regular season
reg_season <- date_data_text[27:length(date_data_text)]
# get column headings from vector
headers <- reg_season[2:6]
# loops to get all game data into rows for each week
n = 7
i = 1
while (n < 52) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# BYE week causes some issues
assign(paste('row', as.character(10), sep = ''), reg_season[52:53])
n = 54
i = 11
while (n < length(reg_season)) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# build data frame
schedule <- data.frame(rbind(row1,row2,row3,row4,row5,row6,row7,row8,row9,row10,row11,row12,row13,row14,row15,row16,row17),
row.names = NULL)
# rename data frame columns
colnames(schedule) <- headers
# remove tickets column
schedule <- schedule[,1:4]
schedule$WK <- as.integer(schedule$WK)
schedule$DATE <- as.character(schedule$DATE)
schedule$OPPONENT <- as.character(schedule$OPPONENT)
schedule$`TIME (ET)` <- as.character(schedule$`TIME (ET)`)
glimpse(schedule)
schedule[10,3] <- 'BYE WEEK'
schedule
library(rtweet) # get tweets
library(dplyr)
library(magick)
library(stringr)
library(kableExtra)
library(knitr)
library(text2vec) #sentiment analysis
library(tm) #text mining (get_nrc_sentiment)
library(syuzhet) # nrc-word emotion associate lexicon
library(rvest) # html scraping
# Specifying url for site to be scraped
url <- 'http://www.espn.com/nfl/team/schedule/_/name/phi/philadelphia-eagles'
# Reading HTML code from the website
webpage <- read_html(url)
# get html from specific CSS selector from webpage
date_data_html <- html_nodes(webpage,'tr td')
# convert this data structure to text
date_data_text <- html_text(date_data_html)
# limit to just regular season
reg_season <- date_data_text[27:length(date_data_text)]
# get column headings from vector
headers <- reg_season[2:6]
# loops to get all game data into rows for each week
n = 7
i = 1
while (n < 52) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# BYE week causes some issues
assign(paste('row', as.character(10), sep = ''), reg_season[52:53])
n = 54
i = 11
while (n < length(reg_season)) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# build data frame
schedule <- data.frame(rbind(row1,row2,row3,row4,row5,row6,row7,row8,row9,row10,row11,row12,row13,row14,row15,row16,row17),
row.names = NULL)
schedule
colnames(schedule) <- headers
schedule
as.integer(schedule$WK)
?as.integer
schedule$DATE <- as.character(schedule$DATE)
schedule$OPPONENT <- as.character(schedule$OPPONENT)
schedule$`TIME (ET)` <- as.character(schedule$`TIME (ET)`)
schedule
glimpse(schedule)
schedule <- schedule[,1:4]
glimpse(schedule)
schedule[10,3] <- 'BYE WEEK'
schedule[10,3:4] <- NA
schedule
schedule[10,3] <- 'BYE WEEK'
schedule[10,4] <- NA
schedule
schedule[10,c(2,4)] <- NA
schedule
schedule %>% separate(DATE, into = c('DAYOFWEEK', 'DATE'), sep = ',')
library(tidyverse)
schedule %>% separate(DATE, into = c('DAYOFWEEK', 'DATE'), sep = ',')
schedule <- schedule %>% separate(DATE, into = c('DAYOFWEEK', 'DATE'), sep = ',')
schedule
schedule['OPPONENT']
schedule['OPPONENT'][0]
schedule[1,'OPPONENT'][0]
print(schedule[1,'OPPONENT'][0])
schedule[1,'OPPONENT'][0]
schedule[1,3][0]
schedule[1,3][1]
schedule[1,4][1]
schedule[1,4][1][0]
schedule[1,4][1][1]
lapply(schedule, gsub, pattern='@', replacement='')
schedule %>% lapply(gsub, pattern='@', replacement='')
schedule %>%
lapply(gsub, pattern='@', replacement='') %>%
lapply(gsub, pattern='vs', replacement='')
schedule <- schedule %>%
lapply(gsub, pattern='@', replacement='') %>%
lapply(gsub, pattern='vs', replacement='')
schedule
schedule <- as.data.frame(schedule) %>%
lapply(gsub, pattern='@', replacement='') %>%
lapply(gsub, pattern='vs', replacement='')
schedule
library(rtweet) # get tweets
library(tidyverse)
library(magick)
library(stringr)
library(kableExtra)
library(knitr)
library(text2vec) #sentiment analysis
library(tm) #text mining (get_nrc_sentiment)
library(syuzhet) # nrc-word emotion associate lexicon
library(rvest) # html scraping
# Specifying url for site to be scraped
url <- 'http://www.espn.com/nfl/team/schedule/_/name/phi/philadelphia-eagles'
# Reading HTML code from the website
webpage <- read_html(url)
# get html from specific CSS selector from webpage
date_data_html <- html_nodes(webpage,'tr td')
# convert this data structure to text
date_data_text <- html_text(date_data_html)
# limit to just regular season
reg_season <- date_data_text[27:length(date_data_text)]
# get column headings from vector
headers <- reg_season[2:6]
# loops to get all game data into rows for each week
n = 7
i = 1
while (n < 52) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# BYE week causes some issues
assign(paste('row', as.character(10), sep = ''), reg_season[52:53])
n = 54
i = 11
while (n < length(reg_season)) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# build data frame
schedule <- data.frame(rbind(row1,row2,row3,row4,row5,row6,row7,row8,row9,row10,row11,row12,row13,row14,row15,row16,row17),
row.names = NULL)
# rename data frame columns
colnames(schedule) <- headers
# remove tickets column
schedule <- schedule[,1:4]
# convert from factor
#schedule$WK <- as.integer(schedule$WK)
schedule$DATE <- as.character(schedule$DATE)
schedule$OPPONENT <- as.character(schedule$OPPONENT)
schedule$`TIME (ET)` <- as.character(schedule$`TIME (ET)`)
# fix BYE WEEK
schedule[10,3] <- 'BYE WEEK'
schedule[10,4] <- NA
# split out date field
schedule <- schedule %>% separate(DATE, into = c('DAYOFWEEK', 'DATE'), sep = ',')
# remove @ symbol and 'vs' from opponent
schedule <- as.data.frame(schedule) %>%
lapply(gsub, pattern='@', replacement='') %>%
lapply(gsub, pattern='vs', replacement='')
schedule
schedule %>%
sapply(gsub, pattern='@', replacement='') %>%
sapply(gsub, pattern='vs', replacement='')
library(rtweet) # get tweets
library(tidyverse)
library(magick)
library(stringr)
library(kableExtra)
library(knitr)
library(text2vec) #sentiment analysis
library(tm) #text mining (get_nrc_sentiment)
library(syuzhet) # nrc-word emotion associate lexicon
library(rvest) # html scraping
# Specifying url for site to be scraped
url <- 'http://www.espn.com/nfl/team/schedule/_/name/phi/philadelphia-eagles'
# Reading HTML code from the website
webpage <- read_html(url)
# get html from specific CSS selector from webpage
date_data_html <- html_nodes(webpage,'tr td')
# convert this data structure to text
date_data_text <- html_text(date_data_html)
# limit to just regular season
reg_season <- date_data_text[27:length(date_data_text)]
# get column headings from vector
headers <- reg_season[2:6]
# loops to get all game data into rows for each week
n = 7
i = 1
while (n < 52) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# BYE week causes some issues
assign(paste('row', as.character(10), sep = ''), reg_season[52:53])
n = 54
i = 11
while (n < length(reg_season)) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# build data frame
schedule <- data.frame(rbind(row1,row2,row3,row4,row5,row6,row7,row8,row9,row10,row11,row12,row13,row14,row15,row16,row17),
row.names = NULL)
# rename data frame columns
colnames(schedule) <- headers
# remove tickets column
schedule <- schedule[,1:4]
# convert from factor
#schedule$WK <- as.integer(schedule$WK)
schedule$DATE <- as.character(schedule$DATE)
schedule$OPPONENT <- as.character(schedule$OPPONENT)
schedule$`TIME (ET)` <- as.character(schedule$`TIME (ET)`)
# fix BYE WEEK
schedule[10,3] <- 'BYE WEEK'
schedule[10,4] <- NA
# split out date field
schedule <- schedule %>% separate(DATE, into = c('DAYOFWEEK', 'DATE'), sep = ',')
schedule
schedule %>%
sapply(gsub, pattern='@', replacement='') %>%
sapply(gsub, pattern='vs', replacement='')
schedule %>%
aapply(gsub, pattern='@', replacement='') %>%
aapply(gsub, pattern='vs', replacement='')
schedule %>%
apply(gsub, pattern='@', replacement='') %>%
apply(gsub, pattern='vs', replacement='')
schedule %>%
apply(FUN = gsub, pattern='@', replacement='') %>%
apply(FUN = gsub, pattern='vs', replacement='')
schedule
schedule %>%
apply(gsub, pattern='@', replacement='') %>%
apply(gsub, pattern='vs', replacement='')
schedule %>%
apply(gsub, pattern='@', replacement='')
schedule %>%
lapply(gsub, pattern='@', replacement='')
schedule %>%
ldply(gsub, pattern='@', replacement='')
library(plyr)
schedule %>%
ldply(gsub, pattern='@', replacement='')
schedule[] <- schedule %>%
lapply(gsub, pattern='@', replacement='') %>%
lapply(gsub, pattern='vs', replacement='')
schedule
separate(schedule, `TIME (ET)``, into = c("TIME", "CHANNEL"), sep = " (?=[^ ]+$)")
)
separate(schedule, `TIME (ET)`, into = c("TIME", "CHANNEL"), sep = " (?=[^ ]+$)")
separate(schedule, `TIME (ET)`, into = c("TIME", "CHANNEL"), sep = " (?=[^ ]+$)")
length(schedule)
schedule
schedule <- schedule %>%
separate(`TIME (ET)`, into = c("TIME", "CHANNEL"), sep = " (?=[^ ]+$)")
schedule <- schedule[,1:length(schedule)]
schedule
library(rtweet) # get tweets
library(tidyverse)
library(magick)
library(stringr)
library(kableExtra)
library(knitr)
library(text2vec) #sentiment analysis
library(tm) #text mining (get_nrc_sentiment)
library(syuzhet) # nrc-word emotion associate lexicon
library(rvest) # html scraping
# Specifying url for site to be scraped
url <- 'http://www.espn.com/nfl/team/schedule/_/name/phi/philadelphia-eagles'
# Reading HTML code from the website
webpage <- read_html(url)
# get html from specific CSS selector from webpage
date_data_html <- html_nodes(webpage,'tr td')
# convert this data structure to text
date_data_text <- html_text(date_data_html)
# limit to just regular season
reg_season <- date_data_text[27:length(date_data_text)]
# get column headings from vector
headers <- reg_season[2:6]
# loops to get all game data into rows for each week
n = 7
i = 1
while (n < 52) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# BYE week causes some issues
assign(paste('row', as.character(10), sep = ''), reg_season[52:53])
n = 54
i = 11
while (n < length(reg_season)) {
assign(paste('row', as.character(i), sep = ''), reg_season[n:(n+4)])
n <- n + 5
i <- i + 1
}
# build data frame
schedule <- data.frame(rbind(row1,row2,row3,row4,row5,row6,row7,row8,row9,row10,row11,row12,row13,row14,row15,row16,row17),
row.names = NULL)
# rename data frame columns
colnames(schedule) <- headers
# remove tickets column
schedule <- schedule[,1:4]
# convert from factor
#schedule$WK <- as.integer(schedule$WK)
schedule$DATE <- as.character(schedule$DATE)
schedule$OPPONENT <- as.character(schedule$OPPONENT)
schedule$`TIME (ET)` <- as.character(schedule$`TIME (ET)`)
# fix BYE WEEK
schedule[10,3] <- 'BYE WEEK'
schedule[10,4] <- NA
# split out date field
schedule <- schedule %>% separate(DATE, into = c('DAYOFWEEK', 'DATE'), sep = ',')
# remove @ symbol and 'vs' from opponent
schedule[] <- schedule %>%
lapply(gsub, pattern='@', replacement='') %>%
lapply(gsub, pattern='vs', replacement='')
schedule <- schedule %>%
separate(`TIME (ET)`, into = c("TIME", "CHANNEL"), sep = " (?=[^ ]+$)")
schedule <- schedule[,1:(length(schedule)-1)]
schedule
setwd('C:/Users/Nimz/Dropbox/DataScienceMasters/R/Udacity/EDAWithR')
list.files()
facebook <- read.csv('pseudo_facebook.tsv', sep = '\t')
head(facebook)
library(tidyverse)
glimpse(facebook)
dim(facebook)
ggplot(facebook) + geom_histogram(aes(x = dob_day))
qplot(facebook$dob_day)
ggplot(facebook) + geom_histogram(aes(x = dob_day)) +
scale_x_discrete(breaks = 1:31)
qplot(facebook$dob_day) +
scale_x_discrete(breaks = 1:31)
qplot(dob_day, facebook) +
scale_x_discrete(breaks = 1:31)
qplot(x = dob_day, facebook) +
scale_x_discrete(breaks = 1:31)
qplot(x = dob_day, data = facebook) +
scale_x_discrete(breaks = 1:31)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1)
qplot(x = dob_day, data = facebook)
qplot(x = dob_day, data = facebook) +
scale_x_discrete(breaks = 1:31)
qplot(x = dob_day, data = facebook) +
scale_x_discrete(breaks = 1:31) +
stat_count(width = 1)
qplot(x = dob_day, data = facebook) +
scale_x_discrete(breaks = 1:31, stat = count)
qplot(x = dob_day, data = facebook, stat = count))
qplot(x = dob_day, data = facebook, stat = count)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_grid(dob_month)
glimpse(facebook)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_grid(~ dob_month)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_grid(~ dob_month, 3)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_grid(~ dob_month, ncol = 3)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_wrap(~ dob_month, 3)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_wrap(~ dob_month)
# now break out into 12 months into 3 cols
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_wrap(~ dob_month, ncols = 3)
ggplot(facebook) + geom_histogram(aes(x = dob_day), binwidth = 1) +
facet_wrap(~ dob_month, ncol = 3)
glimpse(facebook)
ggplot(facebook) + geom_histogram(aes(x = friend_count)
ggplot(facebook) + geom_histogram(aes(x = friend_count))
ggplot(facebook) + geom_histogram(aes(x = friend_count))
qplot(x = friend_count, data = facebook)
qplot(x = friend_count, data = facebook, xlim = c(0,1000))
ggplot(facebook) +
geom_histogram(aes(x = friend_count)) +
scale_x_continuous(limits = c(0, 1000))
qplot(x = friend_count, data = facebook, xlim = c(0,1000), binwidth = 25) +
scale_x_continuous(limiits = c(0,1000), breaks = seq(0,1000,50))
qplot(x = friend_count, data = facebook, xlim = c(0,1000), binwidth = 25) +
scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000,50))
ggplot(facebook) +
geom_histogram(aes(x = friend_count), binwidth = 25) +
scale_x_continuous(limits = c(0, 1000), breaks = seq(0,1000,50))
geom_histogram(aes(x = friend_count), binwidth = 25) +
scale_x_continuous(limits = c(0, 1000), breaks = seq(0,1000,50)) +
facet_wrap(~ gender)
geom_histogram(aes(x = friend_count), binwidth = 25) +
scale_x_continuous(limits = c(0, 1000), breaks = seq(0,1000,50))
ggplot(facebook) +
geom_histogram(aes(x = friend_count), binwidth = 25) +
scale_x_continuous(limits = c(0, 1000), breaks = seq(0,1000,50))
ggplot(facebook) +
geom_histogram(aes(x = friend_count), binwidth = 25) +
scale_x_continuous(limits = c(0, 1000), breaks = seq(0,1000,50)) +
facet_wrap(~ gender)
qplot(x = friend_count, data = facebook, xlim = c(0,1000), binwidth = 25) +
scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000,50)) +
facet_wrap(~ gender)
