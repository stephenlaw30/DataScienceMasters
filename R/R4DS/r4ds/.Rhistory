(obesity.rate <- obese.n / total.n)
(exp.obesity.cnt.dating <- round(obesity.rate*dating.n))
(exp.obesity.cnt.cohabiting <- round(obesity.rate*cohabint.n))
(exp.obesity.cnt.married <- floor(obesity.rate*married.n))
sum(exp.obesity.cnt.cohabiting,exp.obesity.cnt.dating,exp.obesity.cnt.married)
(not.obese.rate <- not.obese.n / total.n)
(exp.not.obese.cnt.dating <- round(not.obese.rate*dating.n))
(exp.not.obese.cnt.cohabiting <- round(not.obese.rate*cohabint.n))
(exp.not.obese.cnt.married <- ceiling(not.obese.rate*married.n))
sum(exp.not.obese.cnt.cohabiting,exp.not.obese.cnt.dating,exp.not.obese.cnt.married)
obese.counts <- c(obese.dating,obese.cohabiting,obese.married)
exp.obese.counts <- c(exp.obesity.cnt.dating,exp.obesity.cnt.cohabiting,exp.obesity.cnt.married)
chi.sq.obese <- sum((obese.counts - exp.obese.counts)^2/exp.obese.counts)
not.obese.counts <- c(not.obese.dating,not.obese.cohabiting,not.obese.married)
exp.not.obese.counts <- c(exp.not.obese.cnt.dating,exp.not.obese.cnt.cohabiting,
exp.not.obese.cnt.married)
chi.sq.not.obese <- sum((not.obese.counts - exp.not.obese.counts)^2/exp.not.obese.counts)
chi.sq <- sum(chi.sq.obese,chi.sq.not.obese)
rows <- 2
cols <- 3
dF <- (rows - 1)*(cols - 1)
obese.dating <- 81
obese.cohabiting <- 103
obese.married <- 147
not.obese.dating <- 359
not.obese.cohabiting<- 326
not.obese.married <- 277
obese.n <- sum(obese.married,obese.cohabiting,obese.dating)
not.obese.n <- sum(not.obese.married,not.obese.cohabiting,not.obese.dating)
dating.n <- sum(obese.dating,not.obese.dating)
cohabint.n <- sum(obese.cohabiting,not.obese.cohabiting)
married.n <- sum(obese.married,not.obese.married)
total.n <- sum(obese.n,not.obese.n)
(obesity.rate <- obese.n / total.n)
(exp.obesity.cnt.dating <- round(obesity.rate*dating.n))
(exp.obesity.cnt.cohabiting <- round(obesity.rate*cohabint.n))
(exp.obesity.cnt.married <- floor(obesity.rate*married.n))
sum(exp.obesity.cnt.cohabiting,exp.obesity.cnt.dating,exp.obesity.cnt.married)
(not.obese.rate <- not.obese.n / total.n)
(exp.not.obese.cnt.dating <- round(not.obese.rate*dating.n))
(exp.not.obese.cnt.cohabiting <- round(not.obese.rate*cohabint.n))
(exp.not.obese.cnt.married <- ceiling(not.obese.rate*married.n))
sum(exp.not.obese.cnt.cohabiting,exp.not.obese.cnt.dating,exp.not.obese.cnt.married)
obese.counts <- c(obese.dating,obese.cohabiting,obese.married)
exp.obese.counts <- c(exp.obesity.cnt.dating,exp.obesity.cnt.cohabiting,exp.obesity.cnt.married)
chi.sq.obese <- sum((obese.counts - exp.obese.counts)^2/exp.obese.counts)
not.obese.counts <- c(not.obese.dating,not.obese.cohabiting,not.obese.married)
exp.not.obese.counts <- c(exp.not.obese.cnt.dating,exp.not.obese.cnt.cohabiting,
exp.not.obese.cnt.married)
chi.sq.not.obese <- sum((not.obese.counts - exp.not.obese.counts)^2/exp.not.obese.counts)
chi.sq <- sum(chi.sq.obese,chi.sq.not.obese)
rows <- 2
cols <- 3
dF <- (rows - 1)*(cols - 1)
pchisq(chi.sq,dF,lower.tail = F)
yes.2012 <- 493
no.2012 <- 514
undec.2012 <- 30
total.2012 <- sum(yes.2012,no.2012,undec.2012)
yes.2013 <- 596
no.2013 <- 401
undec.2013 <- 31
total.2013 <- sum(yes.2013,no.2013,undec.2013)
yes.2012 <- 493
no.2012 <- 514
undec.2012 <- 30
total.2012 <- sum(yes.2012,no.2012,undec.2012)
prop.yes.2012 <- yes.2012 / total.2012
yes.2013 <- 596
no.2013 <- 401
undec.2013 <- 31
total.2013 <- sum(yes.2013,no.2013,undec.2013)
prop.yes.2013 <- yes.2013 / total.2013
yes.2012 <- 493
no.2012 <- 514
undec.2012 <- 30
total.2012 <- sum(yes.2012,no.2012,undec.2012)
prop.yes.2012 <- yes.2012 / total.2012
yes.2013 <- 596
no.2013 <- 401
undec.2013 <- 31
total.2013 <- sum(yes.2013,no.2013,undec.2013)
prop.yes.2013 <- yes.2013 / total.2013
pooled.prop.point.estimate <- (yes.2012 + yes.2013) / (total.2012 + total.2013))
yes.2012 <- 493
no.2012 <- 514
undec.2012 <- 30
total.2012 <- sum(yes.2012,no.2012,undec.2012)
prop.yes.2012 <- yes.2012 / total.2012
yes.2013 <- 596
no.2013 <- 401
undec.2013 <- 31
total.2013 <- sum(yes.2013,no.2013,undec.2013)
prop.yes.2013 <- yes.2013 / total.2013
pooled.prop.point.estimate <- (yes.2012 + yes.2013) / (total.2012 + total.2013)
yes.2012 <- 493
no.2012 <- 514
undec.2012 <- 30
total.2012 <- sum(yes.2012,no.2012,undec.2012)
prop.yes.2012 <- yes.2012 / total.2012
yes.2013 <- 596
no.2013 <- 401
undec.2013 <- 31
total.2013 <- sum(yes.2013,no.2013,undec.2013)
prop.yes.2013 <- yes.2013 / total.2013
pooled.prop.point.estimate <- (yes.2012 + yes.2013) / (total.2012 + total.2013)
(se.prop.ht <- sqrt(((pooled.prop.point.estimate*(1-pooled.prop.point.estimate))/total.2012) +
((pooled.prop.point.estimate*(1-pooled.prop.point.estimate))/total.2013)))
library(tidyverse)
library(ggplot2)
who
who1 <- who %>%
gather(new_sp_m014:newrel_f65,  # gather
key = "key", value = "cases", na.rm = TRUE)
(who1 <- who %>%
gather(new_sp_m014:newrel_f65,  # gather
key = "key", value = "cases", na.rm = TRUE))
who1 %>%
count(key)
(who2 <- who1 %>%
mutate(key = stringr::str_replace(key, "newrel", "new_rel")))
(who3 <- who2 %>%
separate(key, into = c("new", "type", "sexage"), sep = "_"))
(who3 <- who2 %>%
separate(key, into = c("new", "type", "sexage"), sep = "_"))
(who4 <- who3 %>%
separate(sexage, into = c("sex", "age"), sep = 1)) # 1 = 1st char
who4 %>%
count(new)
(who5 <- who4 %>%
select(-new, -iso2, -iso3))
who
who %>%
gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE)' %>% # gather sequence of cols into 'code' and
who %>%
gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE)' %>% # gather sequence of cols into code and
mutate(code = stringr::str_replace(code, "newrel", "new_rel")) %>%
separate(code, c("new", "var", "sexage")) %>%
select(-new, -iso2, -iso3) %>%
separate(sexage, c("sex", "age"), sep = 1)'
who %>%
gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE)
who %>%
gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% # gather sequence of cols into "code" col and counts into "cases"
mutate(code = stringr::str_replace(code, "newrel", "new_rel")) %>% # fix code name
separate(code, c("new", "var", "sexage")) %>% # seperate out code by underscore
select(-new, -iso2, -iso3) %>%# remove redundant cols
separate(sexage, c("sex", "age"), sep = 1) # sepearte out sexage into sex and age
library(tidyverse)
library(ggplot2)
library(caTools)
# Importing dataset
social <- read_csv('Social_Network_Ads.csv')
library(tidyverse)
library(ggplot2)
library(caTools)
# Importing dataset
social <- read_csv('Social_Network_Ads.csv')
social
library(tidyverse)
library(ggplot2)
library(caTools)
# Importing dataset
(social <- read_csv('Social_Network_Ads.csv') %>%
select(Age,EstimatedSalary,Purchased))
# Encode outcome
social %>%
mutate(Purchased <- factor(Purchased, levels = c(0,1)))
head(social)
# Encode outcome
social %>%
mutate(Purchased <- factor(Purchased, levels = c(0,1)))
levels(social$Purchased)
# Encode outcome
social %>%
mutate(Purchased <- factor(social$Purchased, levels = c(0,1)))
levels(social$Purchased)
# Encode outcome
social %>%
mutate(Purchased = factor(Purchased, levels = c(0,1)))
levels(social$Purchased)
# Encode outcome
social <- social %>%
mutate(Purchased = factor(Purchased, levels = c(0,1)))
levels(social$Purchased)
# split data into Training + Test sets
set.seed(123)
split <- social %>%
sample.split(Purchased, SplitRatio = 0.75)
# split data into Training + Test sets
set.seed(123)
split <- social %>%
sample.split(Purchased, SplitRatio = 0.75)
social
# split data into Training + Test sets
set.seed(123)
split <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
training <- social %>%
subset(split == TRUE)
test <- social %>%
subset(split == FALSE)
#test_set = subset(dataset, split == FALSE)
# split data into Training + Test sets
set.seed(123)
split <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
(training <- social %>%
subset(split == TRUE))
(test <- social %>%
subset(split == FALSE))
install.packages("e1071")
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
# Importing dataset
(social <- read_csv('Social_Network_Ads.csv') %>%
select(Age,EstimatedSalary,Purchased))
# Encode outcome
social <- social %>%
mutate(Purchased = factor(Purchased, levels = c(0,1)))
levels(social$Purchased)
# split data into Training + Test sets
set.seed(123)
split <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
(training <- social %>%
subset(split == TRUE))
(test <- social %>%
subset(split == FALSE))
?vsm
?svm
# split data into Training + Test sets
set.seed(123)
spl <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
(training <- social %>%
subset(spl == TRUE))
(test <- social %>%
subset(spl == FALSE))
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'linear')
# Predict on test set results
y_pred.svm <- predict(social.svm, test_set[-3])
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'linear')
# Predict on test set results
y_pred.svm <- predict(social.svm, test[-3])
# Making the Confusion Matrix
cm <= table(test_set[, 3], y_pred)
## Making the Confusion Matrix
cm <= table(test[, 3], y_pred.svm)
## Making the Confusion Matrix
cm <= table(test[, 3], y_pred.svm)
y_pred.svm
test[, 3]
## Making the Confusion Matrix
cm <- table(test[, 3], y_pred.svm)
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
## import data
social <- read_csv("Social_Network_Ads.csv")
## Cut down dataset
social <- social %>%
select(Age,EstimatedSalary,Purchased) %>% # cut down cols
mutate(Purchased = factor(Purchased, levels = c(0,1)), # encode outcome
# scale data (age is in 10s, salary in 10k's)
Age = c(scale(Age)), # use c(scale)) to prevent scale from changing class of the column
EstimatedSalary = c(scale(EstimatedSalary))) # Encode target/outcome variable as fact
# split data into Training + Test sets
set.seed(123)
spl <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
(training <- social %>%
subset(spl == TRUE))
(test <- social %>%
subset(spl == FALSE))
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'linear')
# Predict on test set results
y_pred.svm <- predict(social.svm, test[-3])
## Making the Confusion Matrix
(cm <- table(test[, 3], y_pred.svm))
## Making the Confusion Matrix
(cm <- table(y_pred.svm))
## Making the Confusion Matrix
(cm <- table(test[, 3]))
## Making the Confusion Matrix
(cm <- table(y_pred.svm))
## Making the Confusion Matrix
(cm <- table(test[, 3], y_pred.svm))
## Making the Confusion Matrix
(table(test$Purchased, y_pred.svm))
## Making the Confusion Matrix
(table(test$Purchased, y_pred.svm))
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
## import data
social <- read_csv("Social_Network_Ads.csv")
## Cut down dataset
social <- social %>%
select(Age,EstimatedSalary,Purchased) %>% # cut down cols
mutate(Purchased = factor(Purchased, levels = c(0,1)), # encode outcome
# scale data (age is in 10s, salary in 10k's)
Age = c(scale(Age)), # use c(scale)) to prevent scale from changing class of the column
EstimatedSalary = c(scale(EstimatedSalary))) # Encode target/outcome variable as fact
# split data into Training + Test sets
set.seed(123)
spl <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
(training <- social %>%
subset(spl == TRUE))
(test <- social %>%
subset(spl == FALSE))
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'linear')
# Predict on test set results
y_pred.svm <- predict(social.svm, test[-3])
## Making the Confusion Matrix
(table(test$Purchased, y_pred.svm))
## Making the Confusion Matrix
(table(test$Purchased, y_pred.svm))
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
library(ElemStatLearn)
## Create function to visualize different set results
plot.svm.model <- function(set) {
x1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.05) # get sminimum scaled age + go up to the max by increments of .1
x2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.05) # get minimum scaled salary + go up to the max by increments of .1
set.grid <- expand.grid(x1,x2) # Create DF from all possible combos of the age + salary vectors to make a grid
colnames(set.grid) <- c("Age","EstimatedSalary")
y_pred.svm <- predict(social.svm, set.grid) # use grid to predict values w/ our model
plot(set[,-3],
main = c("SVM (", deparse(substitute(set))," set)"), # get set name from argument given
xlab = "Age",
ylab = "Estimated Salary",
xlim = range(x1),
ylim = range(x2))
contour(x1,x2, matrix(as.numeric(y.pred.grid), length(x1), length(x2)), add = T) # add logistic regression "split" line
points(set.grid, pch = 19, col = if_else(y.pred.grid == 1, "springgreen3", "tomato"))
points(set, pch = 19, col = if_else(set[,3] == 1, "green4", "red3"))
}
plot.svm.model(training)
## Create function to visualize different set results
plot.svm.model <- function(set) {
x1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.05) # get sminimum scaled age + go up to the max by increments of .1
x2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.05) # get minimum scaled salary + go up to the max by increments of .1
set.grid <- expand.grid(x1,x2) # Create DF from all possible combos of the age + salary vectors to make a grid
colnames(set.grid) <- c("Age","EstimatedSalary")
y_pred.svm.grid <- predict(social.svm, set.grid) # use grid to predict values w/ our model
plot(set[,-3],
main = c("SVM (", deparse(substitute(set))," set)"), # get set name from argument given
xlab = "Age",
ylab = "Estimated Salary",
xlim = range(x1),
ylim = range(x2))
contour(x1,x2, matrix(as.numeric(y_pred.svm.grid), length(x1), length(x2)), add = T) # add logistic regression "split" line
points(set.grid, pch = 19, col = if_else(y_pred.svm.grid == 1, "springgreen3", "tomato"))
points(set, pch = 19, col = if_else(set[,3] == 1, "green4", "red3"))
}
plot.svm.model(training)
## Create function to visualize different set results
plot.svm.model <- function(set) {
x1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.05) # get sminimum scaled age + go up to the max by increments of .1
x2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.05) # get minimum scaled salary + go up to the max by increments of .1
set.grid <- expand.grid(x1,x2) # Create DF from all possible combos of the age + salary vectors to make a grid
colnames(set.grid) <- c("Age","EstimatedSalary")
y_pred.svm.grid <- predict(social.svm, set.grid) # use grid to predict values w/ our model
plot(set[,-3],
main = c("SVM (", deparse(substitute(set))," set)"), # get set name from argument given
xlab = "Age",
ylab = "Estimated Salary",
xlim = range(x1),
ylim = range(x2))
contour(x1,x2, matrix(as.numeric(y_pred.svm.grid), length(x1), length(x2)), add = T) # add logistic regression "split" line
points(set.grid, pch = 19, col = if_else(y_pred.svm.grid == 1, "springgreen3", "tomato"))
points(set, pch = 19, col = if_else(set[,3] == 1, "green4", "red3"))
}
plot.svm.model(training)
plot.svm.model(test)
library(statsr)
library(tidyverse)
library(ggplot2)
library(statsr) # Duke package
library(tidyverse)
library(ggplot2)
data(atheism)
head(atheism)
us12 <- atheism %>%
filter(nationality == "United States" , atheism$year == "2012")
us12 <- atheism %>%
filter(nationality == "United States" , atheism$year == "2012")
table(us12$response)
us12 <- atheism %>%
filter(nationality == "United States" , atheism$year == "2012") %>%
group_by(response) %>%
summarise(prop = mean(response))
#table(us12$response)
us12 <- atheism %>%
filter(nationality == "United States" , atheism$year == "2012")# %>%
#group_by(response) %>%
#summarise(prop = mean(response))
prop.table(us12$response)
us12 <- atheism %>%
filter(nationality == "United States" , atheism$year == "2012")# %>%
#group_by(response) %>%
#summarise(prop = mean(response))
prop.table(table(us12$response))
inference(y = response, data = us12, statistic = "proportion", type = "ci", method = "theoretical", success = "atheist")
.0499 * .0364
.0499 * .0354
.0499 - .0364
ire12 <- atheism %>%
filter(nationality == "Ireland" , atheism$year == "2012")# %>%
#group_by(response) %>%
#summarise(prop = mean(response))
prop.table(table(ire12$response))
ire12 <- atheism %>%
filter(nationality == "Ireland" , atheism$year == "2012")
prop.table(table(ire12$response))
pol12 <- atheism %>%
filter(nationality == "Poland" , atheism$year == "2012")
prop.table(table(pol12$response))
ire12 <- atheism %>%
filter(nationality == "Ireland" , atheism$year == "2012")
prop.table(table(ire12$response))
inference(y = response, data = ire12, statistic = "proportion", type = "ci", method = "theoretical", success = "atheist")
pol12 <- atheism %>%
filter(nationality == "Poland" , atheism$year == "2012")
prop.table(table(pol12$response))
inference(y = response, data = pol12, statistic = "proportion", type = "ci", method = "theoretical", success = "atheist")
ire.moe <- .0990099 - .0806
pol.moe <- .04952381 - 0.031
i(re.moe <- .0990099 - .0806)
(ire.moe <- .0990099 - .0806)
(pol.moe <- .04952381 - 0.031)
d <- data.frame(p <- seq(0, 1, 0.01))
n <- 1000
d <- d %>%
mutate(me = 1.96*sqrt(p*(1 - p)/n))
d %>%
ggplot(aes(p, me)) +
geom_line()
?inference
esp12 <- atheism %>%
filter(nationality == "Spain") %>%
inference(esp12, est = "proportion", type = "ht", method = "theoretical", success = "atheist",
null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain") %>%
inference(esp12, statistic = "proportion", type = "ht", method = "theoretical", success = "atheist",
null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain") %>%
inference(data = esp12, statistic = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(esp12, statistic = "proportion", type = "ht", method = "theoretical", success = "atheist",
null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(data = esp12, statistic = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
library(tidyverse)
source("http://bit.ly/dasi_inference")
# create set of the actual observed values
paul <- factor(c(rep("y",8),rep("n",0)), levels = c("y","n"))
# perform 10k simulations (default) to estimate a proportion using a hyp. test via a simulation
inference(paul, est = "proportion", type = "ht", method = "simulation", success = "y",
null = .5, alternative = "greater")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(factor(esp12), statistic = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(data = factor(esp12), statistic = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(data = factor(esp12$year), statistic = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(factor(esp12$year), statistic = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(factor(esp12$year), est = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
esp12 <- atheism %>%
filter(nationality == "Spain")
inference(esp12$response, factor(esp12$year), est = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
esp <- atheism %>%
filter(nationality == "Spain")
inference(esp12$response, factor(esp$year), est = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
View(esp12)
us <- atheism %>%
filter(nationality == "Spain")
inference(us$response, factor(us$year), est = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
us <- atheism %>%
filter(nationality == "Spain")
inference(us$response, factor(us$year), est = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
us <- atheism %>%
filter(nationality == "United States")
inference(us$response, factor(us$year), est = "proportion", type = "ht", method = "theoretical",
success = "atheist", null = 0, alternative = "twosided")
# sig level * # of countries
39 * .05
tail(d)
