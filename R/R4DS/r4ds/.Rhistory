summarise(count = n(na.rm = T), na.rm = T)
candy %>%
group_by(`Q1: GOING OUT?`) %>%
summarise(count = n())
candy %>%
group_by(`Q2: GENDER?`) %>%
summarise(count = n())
candy %>%
group_by(`Q2: GENDER`) %>%
summarise(count = n())
candy %>%
filter(`Q2: GENDER` = "Female") %>%
parse_integer(`Q3: AGE`)
candy %>%
filter(`Q2: GENDER` == "Female") %>%
parse_integer(`Q3: AGE`)
candy %>%
filter(`Q2: GENDER` == "Female") %>%
as.integer(`Q3: AGE`)
candy %>%
filter(`Q2: GENDER` == "Female") #%>%
# as.integer(`Q3: AGE`)
candy <- candy %>%
as.integer(`Q3: AGE`)
#candy <- candy %>%
as.integer(candy$.Q3: AGE`)
#candy <- candy %>%
head(as.integer(candy$.`Q3: AGE`))
#candy <- candy %>%
head(as.integer(candy$`Q3: AGE`))
candy <- candy %>%
as.integer(`Q3: AGE`)
candy <- candy %>%
as.integer(candy$`Q3: AGE`)
candy$`Q3: AGE` <- as.integer(candy$`Q3: AGE`)
candy$`Q3: AGE` <- as.integer(candy$`Q3: AGE`)
candy %>%
filter(is.na(`Q3: AGE`) == F)
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Female") %>%
ggplot() +
geom_hist(aes(`Q3: AGE`))
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Female") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`))
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Female") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`))
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Male") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`))
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Female") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Male") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Female") %>%
ggplot() +
geom_bar(aes(`Q1: GOING OUT?`))
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Male") %>%
ggplot() +
geom_bar(aes(`Q1: GOING OUT?`))
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Female") %>%
ggplot() +
geom_bar(aes(`Q1: GOING OUT?`), na.rm = T)
candy %>%
filter(is.na(`Q3: AGE`) == F,
`Q2: GENDER` == "Male") %>%
ggplot() +
geom_bar(aes(`Q1: GOING OUT?`), na.rm = T)
candy %>%
filter(is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Female") %>%
ggplot() +
geom_bar(aes(`Q1: GOING OUT?`))
candy %>%
filter(is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Male") %>%
ggplot() +
geom_bar(aes(`Q1: GOING OUT?`))
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Female",
`Q1: GOING OUT?` == "Yes") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Female",
`Q1: GOING OUT?` == "No") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Female",
`Q1: GOING OUT?` == "Yes") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 1)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Female",
`Q1: GOING OUT?` == "No") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Female",
`Q1: GOING OUT?` == "Yes") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 3)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Female",
`Q1: GOING OUT?` == "No") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Male",
`Q1: GOING OUT?` == "Yes") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 3)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Male",
`Q1: GOING OUT?` == "No") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Male",
`Q1: GOING OUT?` == "Yes") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 4)
candy %>%
filter(is.na(`Q3: AGE`) == F,
is.na(`Q1: GOING OUT?`) == F,
`Q2: GENDER` == "Male",
`Q1: GOING OUT?` == "No") %>%
ggplot() +
geom_histogram(aes(`Q3: AGE`), binwidth = 2)
candy %>%
sapply(function(x)length(unique(x)))
candy %>%
summarise_all(funs(n_distinct(.)))
?funs
candy %>%
summarise_all(n_distinct(.))
candy %>%
summarise_all(funs(n_distinct(.)))
candy %>%
distinct() %>%
count(var)
candy %>%
gather(var, value) %>%
distinct() %>%
count(var)
# %>%
candy %>%
group_by(`Q1: GOING OUT?`) %>%
summarise(no_rows = length(`Q1: GOING OUT?`))
# %>%
candy %>%
group_by(6) %>%
summarise(no_rows = length(6))
# %>%
candy %>%
group_by([6]) %>%
library(tidyverse)
library(ggplot2)
demons <- read_csv("WDB_DemonicPact.csv")
devil <- read_csv("WDB_DevilAppearance.csv")
head(devil)
demons <- read_csv("WDB_DemonicPact.csv")
devil <- read_csv("WDB_DevilAppearance.csv")
head(devil)
head(demons)
demons <- read_csv("WDB_DemonicPact.csv")
devil <- read_csv("WDB_DevilAppearance.csv")
head(devil)
head(demons)
devil2 <- devil %>%
select(DevilRef,DevilID,CaseRef,Devil_Type)
demon2 <- demon %>%
select(DemonicRef,DemonicID,CaseReg,Demonic_Type)
demons <- read_csv("WDB_DemonicPact.csv")
devil <- read_csv("WDB_DevilAppearance.csv")
head(devil)
head(demons)
devil2 <- devil %>%
select(DevilRef,DevilID,CaseRef,Devil_Type)
demons2 <- demons %>%
select(DemonicRef,DemonicID,CaseReg,Demonic_Type)
demons <- read_csv("WDB_DemonicPact.csv")
devil <- read_csv("WDB_DevilAppearance.csv")
head(devil)
head(demons)
devil2 <- devil %>%
select(DevilRef,DevilID,CaseRef,Devil_Type)
demons2 <- demons %>%
select(DemonicRef,DemonicID,CaseRef,Demonic_Type)
devil2 %>%
inner_join(demons2, by = "CaseRef")
demons <- read_csv("WDB_DemonicPact.csv")
devil <- read_csv("WDB_DevilAppearance.csv")
head(devil)
head(demons)
devil2 <- devil %>%
select(DevilRef,DevilID,CaseRef,Devil_Type)
demons2 <- demons %>%
select(DemonicRef,DemonicID,CaseRef,Demonic_Type)
devil_demon <- devil2 %>%
inner_join(demons2, by = "CaseRef")
table(devil_demon$Devil_Type)
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
library(ElemStatLearn)
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
library(ElemStatLearn)
## import data
social <- read_csv("Social_Network_Ads.csv")
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
library(ElemStatLearn)
## import data
social <- read_csv("Social_Network_Ads.csv")
## Cut down dataset
social <- social %>%
select(Age,EstimatedSalary,Purchased) %>% # cut down cols
mutate(Purchased = factor(Purchased, levels = c(0,1)), # encode outcome
# scale data (age is in 10s, salary in 10k's)
Age = c(scale(Age)), # use c(scale)) to prevent scale from changing class of the column
EstimatedSalary = c(scale(EstimatedSalary))) # Encode target/outcome variable as fact
social
## import data
social <- read_csv("Social_Network_Ads.csv")
## Cut down dataset
social <- social %>%
select(Age,EstimatedSalary,Purchased) %>% # cut down cols
mutate(Purchased = factor(Purchased, levels = c(0,1)), # encode outcome
# scale data (age is in 10s, salary in 10k's)
Age = c(scale(Age)), # use c(scale)) to prevent scale from changing class of the column
EstimatedSalary = c(scale(EstimatedSalary))) # Encode target/outcome variable as fact
## import data
social <- read_csv("Social_Network_Ads.csv")
## Cut down dataset
social <- social %>%
select(Age,EstimatedSalary,Purchased) %>% # cut down cols
mutate(Purchased = factor(Purchased, levels = c(0,1)), # encode outcome
# scale data (age is in 10s, salary in 10k's)
Age = c(scale(Age)), # use c(scale)) to prevent scale from changing class of the column
EstimatedSalary = c(scale(EstimatedSalary))) # Encode target/outcome variable as fact
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'linear')
# split data into Training + Test sets
set.seed(123)
spl <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
(training <- social %>%
subset(spl == TRUE))
(test <- social %>%
subset(spl == FALSE))
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'linear')
# Predict on test set results
y_pred.svm <- predict(social.svm, test[-3])
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'radial')
# Predict on test set results
y_pred.svm <- predict(social.svm, test[-3])
## Making the Confusion Matrix
(table(test$Purchased, y_pred.svm))
## Create function to visualize different set results
plot.svm.model <- function(set) {
x1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.05) # get sminimum scaled age + go up to the max by increments of .1
x2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.05) # get minimum scaled salary + go up to the max by increments of .1
set.grid <- expand.grid(x1,x2) # Create DF from all possible combos of the age + salary vectors to make a grid
colnames(set.grid) <- c("Age","EstimatedSalary")
y_pred.svm.grid <- predict(social.svm, set.grid) # use grid to predict values w/ our model
plot(set[,-3],
main = c("SVM (", deparse(substitute(set))," set)"), # get set name from argument given
xlab = "Age",
ylab = "Estimated Salary",
xlim = range(x1),
ylim = range(x2))
contour(x1,x2, matrix(as.numeric(y_pred.svm.grid), length(x1), length(x2)), add = T) # add logistic regression "split" line
points(set.grid, pch = 19, col = if_else(y_pred.svm.grid == 1, "springgreen3", "tomato"))
points(set, pch = 19, col = if_else(set[,3] == 1, "green4", "red3"))
}
plot.svm.model(training)
plot.svm.model(test)
## Create function to visualize different set results
plot.svm.model <- function(set) {
x1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.05) # get sminimum scaled age + go up to the max by increments of .1
x2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.05) # get minimum scaled salary + go up to the max by increments of .1
set.grid <- expand.grid(x1,x2) # Create DF from all possible combos of the age + salary vectors to make a grid
colnames(set.grid) <- c("Age","EstimatedSalary")
y_pred.svm.grid <- predict(social.svm, set.grid) # use grid to predict values w/ our model
plot(set[,-3],
main = c("Radial SVM (", deparse(substitute(set))," set)"), # get set name from argument given
xlab = "Age",
ylab = "Estimated Salary",
xlim = range(x1),
ylim = range(x2))
contour(x1,x2, matrix(as.numeric(y_pred.svm.grid), length(x1), length(x2)), add = T) # add logistic regression "split" line
points(set.grid, pch = 19, col = if_else(y_pred.svm.grid == 1, "springgreen3", "tomato"))
points(set, pch = 19, col = if_else(set[,3] == 1, "green4", "red3"))
}
plot.svm.model(training)
plot.svm.model(test)
library(tidyverse)
library(ggplot2)
library(caTools)
library(e1071) # most popular SVM libary, other is `kernlab`
library(ElemStatLearn)
## import data
social <- read_csv("Social_Network_Ads.csv")
## Cut down dataset
social <- social %>%
select(Age,EstimatedSalary,Purchased) %>% # cut down cols
mutate(Purchased = factor(Purchased, levels = c(0,1)), # encode outcome
# scale data (age is in 10s, salary in 10k's)
Age = c(scale(Age)), # use c(scale)) to prevent scale from changing class of the column
EstimatedSalary = c(scale(EstimatedSalary))) # Encode target/outcome variable as fact
# split data into Training + Test sets
set.seed(123)
spl <- sample.split(social$Purchased, SplitRatio = 0.75) # tidy does not work here
(training <- social %>%
subset(spl == TRUE))
(test <- social %>%
subset(spl == FALSE))
social.svm <- svm(Purchased ~ ., training, type = 'C-classification', kernel = 'linear')
# Predict on test set results
y_pred.svm <- predict(social.svm, test[-3])
## Making the Confusion Matrix
(table(test$Purchased, y_pred.svm))
## Create function to visualize different set results
plot.svm.model <- function(set) {
x1 <- seq(min(set[,1]) - 1, max(set[,1]) + 1, by = 0.05) # get sminimum scaled age + go up to the max by increments of .1
x2 <- seq(min(set[,2]) - 1, max(set[,2]) + 1, by = 0.05) # get minimum scaled salary + go up to the max by increments of .1
set.grid <- expand.grid(x1,x2) # Create DF from all possible combos of the age + salary vectors to make a grid
colnames(set.grid) <- c("Age","EstimatedSalary")
y_pred.svm.grid <- predict(social.svm, set.grid) # use grid to predict values w/ our model
plot(set[,-3],
main = c("SVM (", deparse(substitute(set))," set)"), # get set name from argument given
xlab = "Age",
ylab = "Estimated Salary",
xlim = range(x1),
ylim = range(x2))
contour(x1,x2, matrix(as.numeric(y_pred.svm.grid), length(x1), length(x2)), add = T) # add logistic regression "split" line
points(set.grid, pch = 19, col = if_else(y_pred.svm.grid == 1, "springgreen3", "tomato"))
points(set, pch = 19, col = if_else(set[,3] == 1, "green4", "red3"))
}
plot.svm.model(training)
plot.svm.model(test)
install.packages("arules")
install.packages("arulesViz")
install.packages("bitops")
install.packages("ca")
install.packages("caTools")
install.packages("e1071")
install.packages("MASS")
install.packages("rgl")
install.packages("RODBC")
install.packages("tree")
install.packages("rpart")
install.packages("XML")
install.packages("rJava")
install.packages("RJDBC")
install.packages("DBI")
install.packages(c("data.table", "heatmaply", "irlba", "kableExtra", "mice", "purrr", "quantreg", "tidyr"))
a <- matrix (1:16,4,4)
# get val in row 2 col 3
a[2,3]
a[1:3,2:4
]
a[1:2,]
# get all vals in all rows from cols 1 + 2
a[,1:2]
a[-1:3,]
a[-1:3,]
a[-c(1,3),]
a[-c(1,3),-c(1,2,4)]
a[1:3,2:4]
a[-c(1,3),-c(1,2,4)]
auto <- read.table("Auto.data",header=T,na.strings ="?")
attach(mtcars)
plot(cyl,mpg)
cyl <- as.factor(cyl)
plot(cyl,mpg)
plot(cyl , mpg , col ="red", varwidth =T, xlab="cylinders ", ylab="MPG")
hist(mpg, col = 2, breaks = 15)
pairs(mtcars)
pairs(~ mpg + disp + hp + wt + qsec, mtcars)
?identify
plot(hp,mpg)
pairs(mtcars)
head(mtcars)
head(Auto)
load(Auto)
??Auto
?identify
plot(hp,mpg)
identify(x = hp, y = mpg, labels = disp)
identify(x = hp, y = mpg, labels = disp)
plot(hp,mpg)
identify(x = hp, y = mpg, labels = as.character(disp))
b0.bf.perc <- -20.062
b1.abdomen.circum <- .877
se <- .067
null <- 0
(t <- (b1 - null) / se)
b0.bf.perc <- -20.062
b1.abdomen.circum <- .877
se <- .067
null <- 0
(t <- (b1.abdomen.circum) / se)
b0.bf.perc <- -20.062
b1.abdomen.circum <- .877
se <- .067
null <- 0
(t <- (b1.abdomen.circum) / se)
n <- 252
dF <- n - 2
pt.est <- b1
b0.bf.perc <- -20.062
b1.abdomen.circum <- .877
se <- .067
null <- 0
(t <- (b1.abdomen.circum) / se)
n <- 252
dF <- n - 2
pt.est <- b1.abdomen.circum
(t.crit <- abs(qt(p = .025, df = 251)))
mOe <- t.crit*se
(lower <- pe - mOe)
b0.bf.perc <- -20.062
b1.abdomen.circum <- .877
se <- .067
null <- 0
(t <- (b1.abdomen.circum) / se)
n <- 252
dF <- n - 2
pt.est <- b1.abdomen.circum
(t.crit <- abs(qt(p = .025, df = 251)))
mOe <- t.crit*se
(lower <- pt.est - mOe)
(upper <- pt.est + mOe)
library(tidyverse)
library(ggplot2)
library(nycflights13)
library(stringr)
double_quote <- "\"" # or '"'
single_quote <- '\'' # or "'"
double_quote <- "\"" # or '"'
single_quote <- '\'' # or "'"
double_quote
x <- c("\"", "\\")
x
writeLines(x)
x <- "\u00b5"
x
str_length(c("a", "R for data science", NA))
str_c("x", "y")
str_c("x", "y", "z")
str_c("x", "y")
str_c("x", "y", "z")
#control how seperate
str_c("x", "y", sep = ", ")
x <- c("abc", NA)
str_c("|-", x, "-|")
str_c("|-", str_replace_na(x), "-|")
str_c("prefix-", c("a", "b", "c"), "-suffix")
name <- "Hadley"
time_of_day <- "morning"
birthday <- FALSE
str_c(
"Good ", time_of_day, " ", name,
if (birthday) " and HAPPY BIRTHDAY",
"."
)
str_c(c("x", "y", "z"), collapse = ", ")
