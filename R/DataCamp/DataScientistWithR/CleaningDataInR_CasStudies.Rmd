---
title: "Cleaning Data: Case Studies"
author: "Steve Newns"
date: "December 5, 2017"
output: html_document
---

# Ticket Sales

```{r}
sales <- read.csv("sales.csv", stringsAsFactors = F)
# View dimensions of sales
dim(sales)

# Inspect first 6 rows of sales
head(sales)

# View column names of sales
names(sales)
```

 rows appear to represent individual purchases and the columns contain different pieces of information about each purchase. 
 
```{r}
 # Look at structure of sales
str(sales)

# View a summary of sales
summary(sales)

# Load dplyr
library(dplyr)

# Get a glimpse of sales
glimpse(sales)

# Remove the first column (just a duplication of the row numbers)  of sales: sales2
sales2 <- sales[,-1]
```
 
# Information not worth keeping

Many of the columns have information that's of no use to us. For example, the first four columns contain internal codes representing particular events. The last fifteen columns also aren't worth keeping; there are too many missing values to make them worthwhile.

An easy way to get rid of unnecessary columns is to create a vector containing the column indices you want to keep, then subset the data based on that vector using single bracket subsetting.
Instructions
100xp

    Create a vector called keep that contains the indices of the columns you want to save. Remember: you want to keep everything besides the first 4 and last 15 columns of sales2.
    Subset the columns of sales2 using your vector and assign the result to sales3.
```{r}
## sales2 is available in your workspace

# Define a vector of column indices: keep = 1st 4 cols = internal codes, last 15 cols = too many missing valuesa
keep <- c(5:(length(sales2) - 15))

# Subset sales2 using keep: sales3
sales3 <- sales2[,keep]
```

## Separating columns

Some of the columns in your data frame include multiple pieces of information that should be in separate columns. In this exercise, you will separate such a column into two: one for date and one for time. You will use the separate() function from the tidyr package (already installed for you).

Take a look at the event_date_time column by typing head(sales3$event_date_time) in the console. You'll notice that the date and time are separated by a space. Therefore, you'll use sep = " " as an argument to separate().
Instructions
100xp

    Load the tidyr package.
    Split the event_date_time column of sales3 into "event_dt" and "event_time". Assign the result to sales4.
    Split the sales_ord_create_dttm column of sales4 into "ord_create_dt" and "ord_create_time". Assign the result to sales5.
```{r}
## sales3 is pre-loaded in your workspace

# Load tidyr
library(tidyr)

# split the date-time cols = event_date_time + sales_ord_create_dttm

# Split event_date_time: sales4
sales4 <- separate(sales3, event_date_time, into = c("event_dt", "event_time"), sep = " ")

# Split sales_ord_create_dttm: sales5
sales5 <- separate(sales4, sales_ord_create_dttm, into = c("ord_create_dt", "ord_create_time"), sep = " ")
```

## Dealing with warnings

Looks like that second call to separate() threw a warning. Not to worry; warnings aren't as bad as error messages. It's not saying that the command didn't execute; it's just a heads-up that something unusual happened.

The warning says Too few values at 4 locations. You may be able to guess already what the issue is, but it's still good to take a look.

The locations (i.e. rows) given in the warning are 2516, 3863, 4082, and 4183. Have a look at the contents of the sales_ord_create_dttm column in those rows.
Instructions
100xp

    Assign a vector issues that contains the indices of the four troublesome rows: 2516, 3863, 4082, and 4183.
    Subset sales3$sales_ord_create_dttm to look at these observations. Remember to use sales3 (not sales4), since you want the data frame from before you separated columns!
    For comparison, print element 2517 of sales3$sales_ord_create_dttm, which did not cause a warning
```{r}
# Define an issues vector
issues <- c(2516,3863,4082,4183)

# Print values of sales_ord_create_dttm at these indices
sales3$sales_ord_create_dttm[issues] # NULL values

# Print a well-behaved value of sales_ord_create_dttm
sales3$sales_ord_create_dttm[2517]    
```

The warning was just because of four missing values. You'll ignore them for now, but if your analysis depended on complete date/time information, you would probably need to delete those rows.


## Identifying dates

Some of the columns in your dataset contain dates of different events. Right now, they are stored as character strings. That's fine if all you want to do is look up the date associated with an event, but if you want to do any comparisons or math with the dates, it's MUCH easier to store them as Date objects.

Luckily, all of the date columns in this dataset have the substring "dt" in their name, so you can use the str_detect() function of the stringr package to find the date columns. Then you can coerce them to Date objects using a function from the lubridate package.

You'll use lapply() to apply the appropriate lubridate function to all of the columns that contain dates. Recall the following syntax for lapply() applied to some data frame columns of interest:

lapply(my_data_frame[, cols], function_name)

Also recall that function names in lubridate combine the letters y, m, d, h, m, and s depending on the format of the date/time string being read in.
Instructions
100xp

    Load the stringr package.
    Use str_detect() to find values in the names() of sales5 containing the string "dt". Assign the resulting logical vector to the variable date_cols.
    Load the lubridate package.
    Coerce the date_cols into Date objects using lapply() and the appropriate function from lubridate. Conveniently, all date columns in sales5 are in year-month-day format, so you can use the ymd() function from lubridate.
```{r}
## sales5 is pre-loaded

# Load stringr
library(stringr)

# Find columns of sales5 containing "dt": date_cols
date_cols <- str_detect(names(sales5),"dt")

# Load lubridate
library(lubridate)

# Coerce date columns into Date objects
sales5[, date_cols] <- lapply(sales5[, date_cols], ymd)
```

code looks great, but there were a few more warnings… Sigh. You'll sort it out in the next exercise.
 
## More warnings!

As you saw, some of the calls to ymd() caused a failure to parse warning. That's probably because of more missing data, but again, it's good to check to be sure.

The first two lines of code (provided for you here) create a list of logical vectors called missing. Each vector in the list indicates the presence (or absence) of missing values in the corresponding column of sales5. See if the number of missing values in each column is the same as the number of rows that failed to parse in the previous exercise.

As a reminder, here are the warning messages:

Warning message:  2892 failed to parse.
Warning message:  101 failed to parse.
Warning message:  4 failed to parse.
Warning message:  424 failed to parse.

Instructions
100xp

    Run the first line as-is to regenerate the date_cols vector.
    Run the second line as-is to generate a list of logical vectors representing missing values in the date columns of sales5.
    Use sapply() to create a numerical vector containing the number of NA values in each date column. Call this vector num_missing.
    Print out the num_missing vector.
```{r}
## stringr is loaded

# Find date columns (don't change)
date_cols <- str_detect(names(sales5), "dt")

# Create logical vectors indicating missing values of all dates cols (don't change)
missing <- lapply(sales5[, date_cols], is.na)

# Create a numerical vector that counts missing values in each date col: num_missing
num_missing <- sapply(missing, sum)

# Print num_missing
num_missing
```

##Combining columns

Sure enough, the number of NAs in each column match the numbers from the warning messages, so missing data is the culprit. How to proceed depends on your desired analysis. If you really need complete sets of date/time information, you might delete the rows or columns containing NAs.

As your last step, you'll use the tidyr function unite() to combine the venue_city and venue_state columns into one column with the two values separated by a comma and a space. For example, "PORTLAND" "MAINE" should become "PORTLAND, MAINE".
Instructions
100xp

    Combine the venue_city and venue_state columns of sales5 into a new column called venue_city_state, containing the city and state names separated by a comma and a space. Call the resulting data frame sales6.
    View the first 6 rows of sales6.
```{r}
## tidyr is loaded

# Combine the venue_city and venue_state columns
sales6 <- unite(sales5, venue_city_state, venue_city, venue_state, sep = ", ")

# View the head of sales6
head(sales6)
```

This dataset is much cleaner. Your next steps would depend on what specific analyses you wanted to perform; for now, we'll call it a chapter. Next up, you'll look at some data about “the T”, Boston's public transit system. 

# MBTA Ridership Data

## Using readxl

The Massachusetts Bay Transportation Authority ("MBTA" or just "the T" for short) manages America's oldest subway, as well as Greater Boston's commuter rail, ferry, and bus systems.

It's your first day on the job as the T's data analyst and you've been tasked with analyzing average ridership through time. You're in luck, because this chapter of the course will guide you through cleaning a set of MBTA ridership data!

The dataset is stored as an Excel spreadsheet called mbta.xlsx in your working directory. You'll use the read_excel() function from Hadley Wickham's readxl package to import it.

The first time you import a dataset, you might not know how many rows need to be skipped. In this case, the first row is a title (see this Excel screenshot), so you'll need to skip the first row. You can also download the whole Excel spreadsheet here.
Instructions
100xp

    Load the readxl package.
    Import the ridership data using read_excel(). Set the skip argument to 1 and store the result to mbta.
```{r}
# Load readxl
library(readxl)

# Import mbta.xlsx and skip first row: mbta
mbta <- read_excel("mbta.xlsx", skip = 1)

str(mbta)

# View the first 6 rows of mbta
head(mbta)

# View a summary of mbta
summary(mbta)
```

## Removing unnecessary rows and columns

It appears that the data are organized with observations stored as columns rather than as rows. You can fix that.

First, though, you can address the missing data. All of the NA values are stored in the All Modes by Qtr row. This row really belongs in a different data frame; it is a quarterly average of weekday MBTA ridership. Since this dataset tracks monthly average ridership, you'll remove that row.

Similarly, the 7th row (Pct Chg / Yr) and the 11th row (TOTAL) are not really observations as much as they are analysis. Go ahead and remove the 7th and 11th rows as well.

The first column also needs to be removed because it's just listing the row numbers.

In case you were wondering, this dataset is stored as a tibble which is just a specific type of data frame. For more information, see here.
Instructions
100xp

    Remove the first, seventh, and eleventh rows of mbta (All Modes By Qtr, Pct Chg / Yr, and TOTAL). Name the resulting data frame mbta2.
    Remove the first column of mbta2. Name the resulting data frame mbta3.
```{r}
# Remove rows 1, 7, and 11 of mbta: mbta2
mbta2 <- mbta[-c(1,7,11),]

# Remove the first column of mbta2: mbta3
mbta3 <- mbta2[,-c(1)]
```

## Observations are stored in columns

Recall from a few exercises back that in your T ridership data, variables are stored in rows instead of columns. If you forget what that looked like, go ahead and enter head(mbta3) in the console and/or look at the screenshot.

The different modes of transportation (commuter rail, bus, subway, ferry, ...) are variables, providing information about each month's average ridership. The months themselves are observations. You can tell which is which because as you go through time, the month changes, but the modes of transport offered by the T do not.

As is customary, you want to represent variables in columns rather than rows. The first step is to use the gather() function from the tidyr package, which will gather columns into key-value pairs.
Instructions
100xp

    Load the tidyr package.
    Gather the columns of mbta3. Use the - operator to omit the mode column. Call your new columns month and thou_riders (for "thousand riders") and assign the result to mbta4.
```{r}
## mbta3 is pre-loaded

# Load tidyr
library(tidyr)

# Gather columns of mbta3: mbta4, not selecting mode to gather in
mbta4 <- gather(mbta3, key = month, value = thou_riders, -mode)

# View the head of mbta4
head(mbta4)    
```

Your dataset is long now – notice that the first column still stores variable names, but now, months have their own column instead of being headers. Also notice the data type of each column. 

##Type conversions

In a minute, you'll put variables where they belong (as column names). But first, take this opportunity to change the average weekday ridership column, thou_riders, into numeric values rather than character strings. That way, you'll be able to do things like compare values and do math.
Instructions
100xp

Coerce the ridership column, mbta4$thou_riders, into a numeric. You can just assign the result back to the same column in mbta4.

```{r}
# Coerce thou_riders to numeric
mbta4$thou_riders <- as.numeric(mbta4$thou_riders)
```

## Variables are stored in both rows and columns

Now, you can finish the job you started earlier: getting variables into columns. Right now, variables are stored as "keys" in the mode column. You'll use the tidyr function spread() to make them into columns containing average weekday ridership for the given month and mode of transport.
Instructions
100xp

    Use spread() to change values in the mode column of mbta4 into column names. The columns should contain the average weekday ridership values associated with that mode of transport. Call the resulting data frame mbta5.
    View the head of mbta5.
```{r}
mbta5 <- spread(mbta4, key = mode, value = thou_riders)
head(mbta5)
```

Separating columns

Your dataset is already looking much better! Your boss saw what a great job you're doing and now wants you to do an analysis of the T's ridership during certain months across all years.

Your dataset has month names in it, so that analysis will be a piece of cake. There's only one small problem: if you want to look at ridership on the T during every January (for example), the month and year are together in the same column, which makes it a little tricky.

In this exercise, you'll separate the month column into distinct month and year columns to make life easier.
Instructions
100xp

    Look at head(mbta5) to remind yourself what the month column currently looks like.
    Split the month column of mbta5 at the dash: create a new month column with only the month and a year column with only the year. Assign the resulting data frame to mbta6.
    View the head of mbta6.
```{r}
## tidyr and mbta5 are pre-loaded

# View the head of mbta5
head(mbta5)

# Split month column into month and year: mbta6 (does not keep old col)
mbta6 <- separate(mbta5, col = month, into = c("year", "month"), sep = "-")

# View the head of mbta6
head(mbta6)
```

# Do your values seem reasonable?

Before you write up the analysis for your boss, it's a good idea to screen the data for any obvious mistakes and/or outliers.

There are many valid techniques for doing this; you'll practice a couple of them here.
Instructions
100xp

    View a summary() of mbta6. Pay particular attention to the Boat column stats.
    Generate a histogram of the Commuter Boat ridership by calling hist() on the column mbta6$Boat.
```{r}
## mbta6 is pre-loaded

# View a summary of mbta6
summary(mbta6) # boat looks off

# Generate a histogram of Boat ridership
hist(mbta6$Boat)
```

That's quite an interesting histogram – every value clustered around 4 and one loner out around 40. You'll address that next…. 

#   Dealing with entry error

Think for a minute about that Boat histogram. Every month, average weekday commuter boat ridership was on either side of four thousand. Then, one month it jumped to 40 thousand without warning?

Unless the Olympics were happening in Boston that month (they weren't), this value is certainly an error. You can assume that whoever was entering the data that month accidentally typed 40 instead of 4.

Because it's an error, you don't want this value influencing your analysis. In this exercise, you'll locate the incorrect value and change it to 4.

After you make the change, you'll run the last two commands in the editor as-is. They use functions you may not know yet to produce some cool ridership plots: one showing the lesser-used modes of transport (take a look at the gorgeous seasonal variation in Boat ridership), and one showing all modes of transport. The plots are based on the long version of the data we produced in Exercise 4 -- a good example of using different data formats for different purposes.

If you'd like to learn how to do this on your own, check out DataCamp's Data Visualization with ggplot2 courses!
Instructions
100xp

    Create a numeric variable i to store the index of the incorrect Boat value in mbta6. Combine a call to which() with a comparison operator (i.e. >) to determine the row number.
    Overwrite the incorrect value of mbta6$Boat with a 4.
    Verify that the change was made by looking at another histogram of mbta6$Boat.
    Run the last two commands as-is to generate pretty plots.
```{r}
# Find the row number of the incorrect value: i
i <- which(mbta6$Boat > 20)

# Replace the incorrect value with 4
mbta6$Boat[i] <- 4

# Generate a histogram of Boat column
hist(mbta6$Boat)

# Look at Boat and Trackless Trolley ridership over time (don't change)
ggplot(mbta_boat, aes(x = month, y = thou_riders, col = mode)) +  geom_point() + 
  scale_x_discrete(name = "Month", breaks = c(200701, 200801, 200901, 201001, 201101)) + 
  scale_y_continuous(name = "Avg Weekday Ridership (thousands)")

# Look at all T ridership over time (don't change)
ggplot(mbta_all, aes(x = month, y = thou_riders, col = mode)) + geom_point() + 
  scale_x_discrete(name = "Month", breaks = c(200701, 200801, 200901, 201001, 201101)) +  
  scale_y_continuous(name = "Avg Weekday Ridership (thousands)")
```

Take a moment to cycle through the three plots you just created in the plotting window. Congratulations! Your dataset is now squeaky-clean. Of course, depending on your desired analysis, you may still need to make some adjustments. For now, though, head over to the next chapter. 

# World Food Facts

## Importing the data

As a person of many talents, it's time to take on a different job: nutrition analysis! Your goal is to analyze the sugar content of a sample of foods from around the world.

A large dataset called food.csv is ready for your use in the working directory. Instead of the usual read.csv(), however, you're going to use the faster fread() from the data.table package. The data will come in as a data table, but since you're used to working with data frames, you can just convert it.

[Note: In order to make these exercises manageable, we've taken a random subset of the original data. The dataset you'll be working with may not be large enough for fread() to make a huge difference, but be aware that there will be times when read.csv() just won't cut it.]
Instructions
100xp

    Load the data.table package.
    Import food.csv using fread(). Call the resulting data table dt_food.
    Convert dt_food to a data frame using data.frame() and call the resulting data frame df_food.
```{r}

```
