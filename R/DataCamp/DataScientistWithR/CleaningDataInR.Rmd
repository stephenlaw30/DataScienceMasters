---
title: "Cleaning Data in R"
author: "Steve Newns"
date: "December 9, 2017"
output: html_document
---

Which of the following is NOT an essential part of the data cleaning process as outlined in the previous video? = ** No one likes missing data, but it is dangerous to assume that it can simply be removed or replaced. Sometimes missing data tells us something important about whatever it is that we're measuring (i.e. The value of the variable that is missing may be related to the reason it is missing). Such data is called Missing not at Random, or MNAR. **

# Explorign Raw Data

## Getting a feel for your data

The first thing to do when you get your hands on a new dataset is to understand its structure. There are several ways to go about this in R, each of which may reveal different issues with your data that require attention.

In this course, we are only concerned with data that can be expressed in table format (i.e. two dimensions, rows and columns). As you may recall from earlier courses, tables in R often have the type data.frame. You can check the class of any object in R with the class() function.

Once you know that you are dealing with tabular data, you may also want to get a quick feel for the contents of your data. Before printing the entire dataset to the console, it's probably worth knowing how many rows and columns there are. The dim() command tells you this.
Instructions
100xp

We've loaded a dataset called bmi into your workspace. The data, which give the (age standardized) mean body mass index (BMI) among males in each country for the years 1980-2008, come from the School of Public Health, Imperial College London.

    Check the class of bmi
    Find the dimensions of bmi
    Print the bmi column names
## Viewing the structure of your data

Since bmi doesn't have a huge number of columns, you can view a quick snapshot of your data using the str() (for structure) command. In addition to the class and dimensions of your entire dataset, str() will tell you the class of each variable and give you a preview of its contents.

Although we won't go into detail on the dplyr package in this lesson (see the Data Manipulation in R with dplyr course), the glimpse() function from dplyr is a slightly cleaner alternative to str(). str() and glimpse() give you a preview of your data, which may reveal issues with the way columns are labelled, how variables are encoded, etc.

You can use the summary() command to get a better feel for how your data are distributed, which may reveal unusual or extreme values, unexpected missing data, etc. For numeric variables, this means looking at means, quartiles (including the median), and extreme values. For character or factor variables, you may be curious about the number of times each value appears in the data (i.e. counts), which summary() also reveals.
Instructions
100xp

    View the structure of bmi using the traditional method
    Load the dplyr package
    View the structure of bmi using dplyr
    Look at a summary() of bmi
## Looking at your data

You can look at all the summaries you want, but at the end of the day, there is no substitute for looking at your data -- either in raw table form or by plotting it.

The most basic way to look at your data in R is by printing it to the console. As you may know from experience, the print() command is not even necessary; you can just type the name of the object. The downside to this option is that R will attempt to print the entire dataset, which can be a nuisance if the dataset is too large.

One way around this is to use the head() and tail() commands, which only display the first and last 6 rows of data, respectively. You can view more (or fewer) rows by providing as a second argument to the function the number of rows you wish to view. These functions provide a useful method for quickly getting a sense of your data without overly cluttering the console.
Instructions
100xp

    Print the full dataset to the console (you don't need print() to do this)
    View the first 6 rows of bmi
    View the first 15 rows of bmi
    View the last 6 rows of bmi
    View the last 10 rows of bmi

## Visualizing your data

There are many ways to visualize data. Since this is not a course about data visualization, we will only touch on two types of plots that may be useful for quickly identifying extreme or suspicious values in your data: histograms and scatter plots.

A histogram, created with the hist() function, takes a vector (i.e. column) of data, breaks it up into intervals, then plots as a vertical bar the number of instances within each interval. A scatter plot, created with the plot() function, takes two vectors (i.e. columns) of data and plots them as a series of (x, y) coordinates on a two-dimensional plane.

Let's look at a quick example of each.
Instructions
100xp

For the bmi dataset:

    Use hist() to look at the distribution of average BMI across all countries in 2008
    Use plot() to see how each country's average BMI in 1980 (x-axis) compared with its BMI in 2008 (y-axis)
```{r}
# Histogram of BMIs from 2008
hist(bmi[,"Y2008"])

# Scatter plot comparing BMIs from 1980 to those from 2008
plot(bmi[,"Y1980"],bmi[,"Y2008"])
```

# Introduction to tidy data

Each observation forms a row, each variable forms a column, and each type of observational unit forms a table
Each value belongs to a variable and an observation
A dataset is a collection of values

symptoms of messy data:
Variables are stored in both rows and columns
Column headers are values, not variable names
A single observational unit is stored in multiple tables
Multiple variables stored in one column is messy, but there should be multiple values in each column. 

# Intro to tidyr

## What kind of messy are the BMI data?

Remember the bmi dataset from the previous chapter? We've loaded it for you so can play around in the console.

Which symptom of messy data is exhibited by bmi? = All of the year column names could be expressed as values of a new variable called year. 

## Gathering columns into key-value pairs

The most important function in tidyr is gather(). It should be used when you have columns that are not variables and you want to collapse them into key-value pairs.

The easiest way to visualize the effect of gather() is that it makes wide datasets long. As you saw in the video, running the following command on wide_df will make it long:

gather(wide_df, my_key, my_val, -col)

Experiment with this in the console before attempting the exercise.
Instructions
100xp

    Apply the gather() function to bmi, saving the result to bmi_long. This will create two new columns:
        year, containing as values what are currently column headers
        bmi_val, the actual BMI values
    View the first 20 rows of bmi_long
```{r}
# Apply gather() to bmi and save the result as bmi_long
# gather(wide_df, name_of_new_key, name_of_new_value, -col to keep as index)
bmi_long <- gather(bmi, year, bmi_val, -Country)

# View the first 20 rows of the result
head(bmi_long,20)
```

, instead of being represented in the column names, years are now all neatly represented in the year column. Try checking dim(bmi_long) and dim(bmi) before moving on. 
```{r}
dim(bmi)
dim(bmi_long)
```

## Spreading key-value pairs into columns

The opposite of gather() is spread(), which takes key-values pairs and spreads them across multiple columns. This is useful when values in a column should actually be column names (i.e. variables). It can also make data more compact and easier to read.

The easiest way to visualize the effect of spread() is that it makes long datasets wide. As you saw in the video, running the following command will make long_df wide:

spread(long_df, my_key, my_val)

Experiment with this in the console before attempting the exercise.
Instructions
100xp

    Use spread() to reverse the operation that you performed in the last exercise with gather(). In other words, make bmi_long wide again, saving the result to bmi_wide
    View the head of bmi_wide
```{r}
# Apply spread() to bmi_long = spread(long_df, col_to_split_to_cols, col_to_make_into_vals)
bmi_wide <- spread(bmi_long, year, bmi_val)

# View the head of bmi_wide
head(bmi_wide)
```

## Separating columns

The separate() function allows you to separate one column into multiple columns. Unless you tell it otherwise, it will attempt to separate on any character that is not a letter or number. You can also specify a specific separator using the sep argument.

We've loaded the small dataset from the video called treatments into your workspace. This dataset obeys the principles of tidy data, but we'd like to split the treatment dates into two separate columns: year and month. This can be accomplished with the following:

separate(treatments, year_mo, c("year", "month"))

Experiment with this in the console before attempting the exercise.
Instructions
100xp

We've loaded a dataset called bmi_cc into your workspace that is a slight variation of bmi_long, which you've already seen. The Country_ISO column of bmi_cc has the name of each country as well its two-letter ISO country code, separated by a forward slash.

    Apply the separate() function to bmi_cc
        Separate Country_ISO into two columns: Country and ISO
        Be sure to specify the correct separator with the sep argument
        Save the result to a new object called bmi_cc_clean
    View the head of the result
```{r}
# Apply separate() to bmi_cc
bmi_cc_clean <- separate(bmi_cc, col = Country_ISO, into = c("Country", "ISO"), sep = "/")

# Print the head of the result
head(bmi_cc_clean)
```
## Uniting columns

The opposite of separate() is unite(), which takes multiple columns and pastes them together. By default, the contents of the columns will be separated by underscores in the new column, but this behavior can be altered via the sep argument.

We've loaded the treatments data into your workspace again, but this time the year_mo column has been separated into year and month. The original column can be recreated by putting year and month back together:

unite(treatments, year_mo, year, month)

Experiment with this in the console before attempting the exercise.
Instructions
100xp

In the last exercise, you separated the Country_ISO column of the bmi_cc dataset into two columns (Country and ISO) and saved the result to bmi_cc_clean. Now you're going to put the columns back together!

    Apply the unite() function to bmi_cc_clean
        Reunite the Country and ISO columns into a single column called Country_ISO
        Separate each country name and code with a dash (-)
        Save the result as bmi_cc
    View the head of the result
```{r}
# Apply unite() to bmi_cc_clean
bmi_cc <- unite(bmi_cc_clean, Country_ISO, Country, ISO, sep = "-")

# View the head of the result
head(bmi_cc)
```

# Addressing common symptoms of messy data

## Column headers are values, not variable names

You saw earlier in the chapter how we sometimes come across datasets where column names are actually values of a variable (e.g. months of the year). This is often the case when working with repeated measures data, where measurements are taken on subjects of interest on multiple occasions over time. The gather() function is helpful in these situations.
Instructions
100xp

    View the head of census.
    Gather the month columns, creating two new columns (month and amount), saving the result to census2.
    Run the code given to arrange() the rows of census2 by the YEAR column.
    View the first 20 rows of the result.
```{r}
## tidyr and dplyr are already loaded for you

# View the head of census
head(census)

# Gather the month columns
census2 <- gather(census, month, amount, -YEAR)

# Arrange rows by YEAR using dplyr's arrange
census2 <- arrange(census2, YEAR)

# View first 20 rows of census2
head(census2,20)
```

Many datasets dealing with historical data appear in this format with time expressed horizontally. Understanding how to tidy these data is key for efficient data analysis. 

## Variables are stored in both rows and columns

Sometimes you'll run into situations where variables are stored in both rows and columns. To illustrate this, we've loaded the pets dataset from the video, which tells us in a convoluted way how many birds, cats, and dogs Jason, Lisa, and Terrence have. Print the pets dataset to see for yourself.

Although it may not be immediately obvious, if we treat the values in the type column as variables and create a separate column for each of them, we can set things straight. To do this, we use the spread() function. Run the following code to see for yourself:

spread(pets, type, num)

The result shows the exact same information in a much clearer way! Notice that the spread() function took in three arguments. The first argument takes the name of your messy dataset (pets), the second argument takes the name of the column to spread into new columns (type), and the third argument takes the column that contains the value with which to fill in the newly spread out columns (num).

Now let's try this on a new messy dataset census_long. What information does this tell us?
Instructions
100xp

    View the first 50 rows of census_long
    Decide which column of census_long would be best to spread, and which column of census_long would be best to display in the newly spread out columns. Use the spread() function accordingly and save the result to census_long2
    View the first 20 rows of census_long2
```{r}
## tidyr is already loaded for you

# View first 50 rows of census_long
head(census_long,50)

# Spread the type column
census_long2 <- spread(census_long, key = type, value = amount)

# View first 20 rows of census_long2
head(census_long2,20)
```

## Multiple values are stored in one column

It's also fairly common that you will find two variables stored in a single column of data. These variables may be joined by a separator like a dash, underscore, space, or forward slash.

The separate() function comes in handy in these situations. To practice using it, we have created a slight modification of last exercise's result. Keep in mind that the into argument, which specifies the names of the 2 new columns being formed, must be given as a character vector (e.g. c("column1", "column2")).
Instructions
100xp

    View the head of census_long3
    Use tidyr's separate() to split the yr_month column into two separate variables: year and month, saving the result to census_long4
    View the first 6 rows of the result
```{r}
## tidyr is already loaded for you

# View the head of census_long3
head(census_long3)

# Separate the yr_month column into two
census_long4 <- separate(census_long3, yr_month, into = c("year", "month"), sep = "_")

# View the first 6 rows of the result
head(census_long4)
```

# Type conversions

## Types of variables in R

As in other programming languages, R is capable of storing data in many different formats, most of which you've probably seen by now.

Loosely speaking, the class() function tells you what type of object you're working with. (There are subtle differences between the class, type, and mode of an object, but these distinctions are beyond the scope of this course.)
Change the object within each call of the class() function to make it evaluate to the following (in order):

    character
    numeric
    integer
    factor
    logical

Add or remove quotes, add an L to numerics to make them integers and use the factor() function when appropriate to accomplish this. 
```{r}
# Make this evaluate to character
class("true")

# Make this evaluate to numeric
class(8484.00)

# Make this evaluate to integer
class(as.integer(99))

# Make this evaluate to factor
class(as.factor("factor"))

# Make this evaluate to logical
class(FALSE)
```

## Common type conversions

It is often necessary to change, or coerce, the way that variables in a dataset are stored. This could be because of the way they were read into R (with read.csv(), for example) or perhaps the function you are using to analyze the data requires variables to be coded a certain way.

Only certain coercions are allowed, but the rules for what works are generally pretty intuitive. For example, trying to convert a character string to a number gives an error: as.numeric("some text").

There are a few less intuitive results. For example, under the hood, the logical values TRUE and FALSE are coded as 1 and 0, respectively. Therefore, as.logical(1) returns TRUE and as.numeric(TRUE) returns 1.
Instructions
100xp
Instructions
100xp

We've loaded a dataset called students into your workspace. These data provide information on 395 students including their grades in three classes (in the Grades column, separated by /).

    Use str() to preview students and see the class of each variable
    Coerce the following columns:
        Grades to character
        Medu to factor (categorical variable representing mother's education level)
        Fedu to factor (categorical variable representing father's education level)
    Use str() again to see the changes to students
```{r}
# Preview students with str()
str(students)

# Coerce Grades to character
students$Grades <- as.character(students$Grades)

# Coerce Medu to factor
students$Medu <- as.factor(students$Medu)

# Coerce Fedu to factor
students$Fedu <- as.factor(students$Fedu)
    
# Look at students once more with str()
str(students)
```

## Working with dates

Dates can be a challenge to work with in any programming language, but thanks to the lubridate package, working with dates in R isn't so bad. Since this course is about cleaning data, we only cover the most basic functions from lubridate to help us standardize the format of dates and times in our data.

As you saw in the video, these functions combine the letters y, m, d, h, m, s, which stand for year, month, day, hour, minute, and second, respectively. The order of the letters in the function should match the order of the date/time you are attempting to read in, although not all combinations are valid. Notice that the functions are "smart" in that they are capable of parsing multiple formats.
Instructions
100xp

We have loaded a dataset called students2 into your workspace. students2 is similar to students, except now instead of an age for each student, we have a (hypothetical) date of birth in the dob column. There's another new column called nurse_visit, which gives a timestamp for each student's most recent visit to the school nurse.

    Preview students2 with str(). Notice that dob and nurse_visit are both stored as character
    Load the lubridate package
    Print "17 Sep 2015" as a date
    Print "July 15, 2012 12:56" as a date and time (note there are hours and minutes, but no seconds!)
    Coerce dob to a date (with no time)
    Coerce nurse_visit to a date and time
    Use str() to see the changes to students2
```{r}
# Preview students2 with str()
str(students2)

# Load the lubridate package
library(lubridate)

# Parse as date
dmy("17 Sep 2015")

# Parse as date and time (with no seconds!)
mdy_hm("July 15, 2012 12:56")

# Coerce dob to a date (with no time)
students2$dob <- ymd(students2$dob) 

# Coerce nurse_visit to a date and time
students2$nurse_visit <- ymd_hms(students2$nurse_visit)
    
# Look at students2 once more with str()
str(students2)
```

# String manipulation

##Trimming and padding strings

One common issue that comes up when cleaning data is the need to remove leading and/or trailing white space. The str_trim() function from stringr makes it easy to do this while leaving intact the part of the string that you actually want.

> str_trim("  this is a test     ")
[1] "this is a test"

A similar issue is when you need to pad strings to make them a certain number of characters wide. One example is if you had a bunch of employee ID numbers, some of which begin with one or more zeros. When reading these data in, you find that the leading zeros have been dropped somewhere along the way (probably because the variable was thought to be numeric and in that case, leading zeros would be unnecessary.)

> str_pad("24493", width = 7, side = "left", pad = "0")
[1] "0024493"

Instructions
100xp
Instructions
100xp

    Load the stringr package
    Trim all leading and trailing white space from the first set of strings
    Pad the second set of strings with leading zeros such that all are 9 characters in length
```{r}
# Load the stringr package
library(stringr)

# Trim all leading and trailing whitespace
str_trim(c("   Filip ", "Nick  ", " Jonathan"))

# Pad these strings with leading zeros
str_pad(c("23485W", "8823453Q", "994Z"), width = "9", side = "left", pad = "0")
```

str_pad() function is useful when importing a dataset with US zip codes. Occasionally R will drop the leading 0 in a zipcode, thinking it's numeric. Now that you know how to coerce variable types and pad strings, this won't set you back! 

## Upper and lower case

In addition to trimming and padding strings, you may need to adjust their case from time to time. Making strings uppercase or lowercase is very straightforward in (base) R thanks to toupper() and tolower(). Each function takes exactly one argument: the character string (or vector/column of strings) to be converted to the desired case.
Instructions
100xp

There's a vector of state abbreviations called states in your workspace, but there's a problem...it's all lowercase. It's more common for state abbreviations to be all uppercase.

    Print states to the console
    Make states all uppercase and save the result to states_upper
    Make states_upper all lowercase again, but don't save the result
```{r}
# Print state abbreviations
states

# Make states all uppercase and save result to states_upper
states_upper <- toupper(states)

# Make states_upper all lowercase again
states_lower <- tolower(states)
```

## Finding and replacing strings

The stringr package provides two functions that are very useful for finding and/or replacing strings: str_detect() and str_replace().

Like all functions in stringr, the first argument of each is the string of interest. The second argument of each is the pattern of interest. In the case of str_detect(), this is the pattern we are searching for. In the case of str_replace(), this is the pattern we want to replace. Finally, str_replace() has a third argument, which is the string to replace with.
Instructions
100xp

The students2 dataset from earlier in the chapter has been loaded for you again.

    Look at the head() of students2 to remind yourself of how it looks
    Detect all dates of birth (dob) in 1997 using str_detect(). This should return a vector of TRUE and FALSE values.
    Replace all instances of "F" with "Female" in students2$sex
    Replace all instances of "M" with "Male" in students2$sex
    View the head() of students2 to see the result of these replacements
```{r}
## stringr has been loaded for you

# Look at the head of students2
head(students2)

# Detect all dates of birth (dob) in 1997
str_detect(students2$dob, "1997")

# In the sex column, replace "F" with "Female"...
students2$sex <- str_replace(students2$sex, "F", "Female")

# ...And "M" with "Male"
students2$sex <- str_replace(students2$sex, "M", "Male")

# View the head of students2
head(students2)
```


# Missing and special values

## Finding missing values

As you've seen, missing values in R should be represented by NA, but unfortunately you will not always be so lucky. Before you can deal with missing values, you have to find them in the data.

If missing values are properly coded as NA, the is.na() function will help you find them. Otherwise, if your dataset is too big to just look at the whole thing, you may need to try searching for some of the usual suspects like "", "#N/A", etc. You can also use the summary() and table() functions to turn up unexpected values in your data.

In this exercise, we've created a simple dataset called social_df that has 3 pieces of information for each of four friends:

    Name
    Number of friends on a popular social media platform
    Current "status" on the platform

Instructions
100xp

    Call is.na() on social_df to spot all NA values.
    Wrap the above with the any() function to ask the question "Are there any NA values in my dataset?".
    View a summary() of the dataset to see how missing values are broken out.
    Use table to identify odd values of the status variable
```{r}
# Call is.na() on the full social_df to spot all NAs
is.na(social_df)

# Use the any() function to ask whether there are any NAs in the data
any(is.na(social_df))

# View a summary() of the dataset
summary(social_df)

# Call table() on the status column
table(social_df$status)
```

## Dealing with missing values

Missing values can be a rather complex subject, but here we'll only look at the simple case where you are simply interested in normalizing and/or removing all missing values from your data. For more information on why this is not always the best strategy, search online for "missing not at random."

Looking at the social_df dataset again, we asked around a bit and figured out what's causing the missing values that you saw in the last exercise. Tom doesn't have a social media account on this particular platform, which explains why his number of friends and current status are missing (although coded in two different ways). Alice is on the platform, but is a passive user and never sets her status, hence the reason it's missing for her.
Instructions
100xp

    Replace all empty strings (i.e. "") with NA in the status column of social_df.
    Print the updated version of social_df to confirm your changes.
    Use complete.cases() to return a vector containing TRUE and FALSE to see which rows have NO missing values.
    Use na.omit() to remove all rows with one or more missing values (without saving the result).
```{r}
## The stringr package is preloaded

# Replace all empty strings in status with NA
social_df$status[social_df$status == ""] <- NA

# Print social_df to the console
social_df

# Use complete.cases() to see which rows have no missing values
complete.cases(social_df)

# Use na.omit() to remove all rows with any missing values
na.omit(social_df)
```

! Often times in data analyses, you'll want to get a feel for how many complete observations you have. This can be helpful in determining how you handle observations with missing data points. 

# Outliers and obvious errors

## Dealing with outliers and obvious errors

When dealing with strange values in your data, you often must decide whether they are just extreme or actually erroneous. Extreme values show up all over the place, but you, the data analyst, must figure out when they are plausible and when they are not.

We have loaded a dataset called students3, which is another slight variation of the original students dataset. Two variables appear to have suspicious values: age and absences. Let's explore these values further.
Instructions
100xp

    Call summary() on the full students3 dataset to expose the concerning values of age and absences.
    View a histogram (using hist()) of the age variable.
    View a histogram of the absences variable.
    View another histogram of absences, but force values of zero to be bucketed to the right of zero on the x-axis with right = FALSE (see ?hist for more info).
```{r}
# Look at a summary() of students3
summary(students3) # age + absences

# View a histogram of the age variable
hist(students3$age)

# View a histogram of the absences variable
hist(students3$absences)

# View a histogram of absences, but force zeros to be bucketed to the right of zero
hist(students3$absences, right = F)
```

 a simple histogram, displaying the distribution of a variable's values across all the observations can be key to identifying potential outliers as early as possible. 
 
 ##Another look at strange values

Another useful way of looking at strange values is with boxplots. Simply put, boxplots draw a box around the middle 50% of values for a given variable, with a bolded horizontal line drawn at the median. Values that fall far from the bulk of the data points (i.e. outliers) are denoted by open circles. (If you're curious about the exact formula for determining what is "far", check out ?hist.)

In this situation, we are concerned about three things:

    Since this dataset is about students and the only student above the age of 22 is 38 years old, we must wonder whether this is an error in the data or just an older student (perhaps returning to school after working for several years)
    There are four values of -1 for the absences variable, which is either a mistake or an intentional coding meant to say, for example, "this value is missing"
    There are several extreme values of absences in the positive direction, with a maximum value of 75 (which is over 18 times the median value of 4)

Instructions
100xp
Instructions
100xp

    View a boxplot() of the age variable from students3
    View a boxplot() of the absences variable from students3
```{R}
# View a boxplot of age
boxplot(students3$age)

# View a boxplot of absences
boxplot(students3$absences)
```