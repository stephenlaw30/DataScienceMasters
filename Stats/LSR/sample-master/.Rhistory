ggplot(diamonds) +
geom_histogram(aes(log10(price/carat)), binwidth = 0.1, color = 'white')
ggplot(diamonds) +
geom_histogram(aes(log10(price/carat)), binwidth = 0.1, color = 'white')
ggplot(diamonds) +
geom_histogram(aes(price/carat), binwidth = 1000, color = 'white')
ggplot(diamonds) +
geom_histogram(aes(log10(price/carat)), binwidth = 0.1, color = 'white') +
facet_grid(~cut)
# break out by cut
ggplot(diamonds) +
geom_histogram(aes(log10(price/carat)), binwidth = 0.05, color = 'white') +
facet_grid(~cut)
ggplot(diamonds) +
geom_boxplot(aes(price, clarity))
ggplot(diamonds) +
geom_boxplot(aes(clarity, price))
ggplot(diamonds) +
geom_boxplot(aes(cut, price))
ggplot(diamonds) +
geom_boxplot(aes(color, price))
ggplot(diamonds) +
geom_boxplot(aes(clarity, price)) +
coord_cartesian(ylim = c(0,7500))
by(diamonds$price,diamonds$clarity,summary)
ggplot(diamonds) +
geom_boxplot(aes(cut, price))
ggplot(diamonds) +
geom_boxplot(aes(cut, price)) +
coord_cartesian(ylim = c(0,7500))
by(diamonds$price,diamonds$cut,summary)
# all relatively similar max and min prices
ggplot(diamonds) +
geom_boxplot(aes(color, price))
ggplot(diamonds) +
geom_boxplot(aes(color, price)) +
coord_cartesian(ylim = c(0,7600))
by(diamonds$price,diamonds$color,summary)
iqr(diamonds$price)
library(lsr)
iqr(diamonds$price)
library(SDSFoundations)
iqr(diamonds$price)
IQR(diamonds$price)
?IQR
IQR(subset(diamonds, color == 'D')$price)
IQR(subset(diamonds, color == 'J')$price)
ggplot(diamonds) +
geom_boxplot(aes(color, price/carat))
ggplot(diamonds) +
geom_boxplot(aes(color, price/carat)) +
coord_cartesian(ylim = c(0,6000))
by(diamonds$price/diamonds$carat,diamonds$color,summary)
diamonds$price/diamonds$carat
by(diamonds$price/diamonds$carat,diamonds$color,summary)
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, y = ..count../sum(..count..), binwidth = 10)
)
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = 50))
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = 100))
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = 100)) +
scale_x_continuous()
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = 100)) +
scale_x_continuous(breaks = seq(0,5,.1))
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = 10)) +
scale_x_continuous(breaks = seq(0,5,.1))
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = 5)) +
scale_x_continuous(breaks = seq(0,5,.1))
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = .1)) +
scale_x_continuous(breaks = seq(0,5,.1))
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = .1)) +
scale_x_continuous(breaks = seq(0,5,.1))
table(diamonds$carat)
table(diamonds$carat) > 2000
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = .01)) +
scale_x_continuous(breaks = seq(0,5,.1))
table(diamonds$carat) > 2000
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = .01)) +
scale_x_continuous(xlim(c(0,5)) breaks = seq(0,5,.1))
table(diamonds$carat) > 2000
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = .01)) +
scale_x_continuous(limits = c(0,3) breaks = seq(0,5,.1))
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = .01)) +
scale_x_continuous(limits = c(0,3), breaks = seq(0,5,.1))
library(ggplot2)
data(diamonds)
library(tidyverse)
glimpse(diamonds)
levels(diamonds$cut)
# histogram of price
ggplot(diamonds) +
geom_histogram(aes(price))
summary(diamonds$price)
sum(diamonds$price < 500)
sum(diamonds$price < 250)
sum(diamonds$price >= 15000)
# explore peak
ggplot(diamonds) +
geom_histogram(aes(price), color = 'black', binwidth = 50) +
coord_cartesian(xlim = c(300,2000)) +
xlab('Price') +
ylab('Count') +
ggtitle('Limited Set of Diamond Price (<= $2,000)')
# see no diamonds cost $1500, and most are around $700
# histogram of price broken out by cut
ggplot(diamonds) +
geom_histogram(aes(price), binwidth = 1000) +
facet_wrap(~ cut)
by(diamonds$price,diamonds$cut,summary)
# odd that ideal diamond cut is tied for lowest price (with premium, the next highest cut)
# also odd that ideal diamond has lowest median, and premium has the most-expensive diamond
# looking at the medians and quartiles --> they are reasonably close = distributions should be smaller
# histograms don't show that
# Fair and good seem somewhat more uniform, excluding long tail to the right
# remove fixed-y axis
ggplot(diamonds) +
geom_histogram(aes(price), binwidth = 1000) +
facet_wrap(~ cut, scales = "free_y")
# now they look more similar
# histogram of price per carat
ggplot(diamonds) +
geom_histogram(aes(price/carat), binwidth = 1000, color = 'white')
#right-skew
# transform x-axis
ggplot(diamonds) +
geom_histogram(aes(log10(price/carat)), binwidth = 0.1, color = 'white')
# looks more normal
# break out by cut
ggplot(diamonds) +
geom_histogram(aes(log10(price/carat)), binwidth = 0.05, color = 'white') +
facet_grid(~cut)
# all look relatively normal, with very good looking a bit bimodal (premium a bit less so)
# boxplots
ggplot(diamonds) +
geom_boxplot(aes(clarity, price)) +
coord_cartesian(ylim = c(0,7500))
# clarity of S2 has highest median price, while IF and VVS1 have lowest, as well as least variability
# VS2 and VS1 have most variability (tallest boxes)
by(diamonds$price,diamonds$clarity,summary)
# all relatively similar max and min prices
ggplot(diamonds) +
geom_boxplot(aes(cut, price)) +
coord_cartesian(ylim = c(0,7500))
# cut of Premium has highest median price, while Ideal, Fair has least variability
# Premium also has most variability
by(diamonds$price,diamonds$cut,summary)
# all relatively similar max and min prices
ggplot(diamonds) +
geom_boxplot(aes(color, price)) +
coord_cartesian(ylim = c(0,7600))
# J "worst" color has highest median price, while "best" D is 2nd to lowest
# "worse" colors increase in median price, as well as variability
by(diamonds$price,diamonds$color,summary)
IQR(subset(diamonds, color == 'D')$price)
IQR(subset(diamonds, color == 'J')$price)
# price per carat across colors
ggplot(diamonds) +
geom_boxplot(aes(color, price/carat)) +
coord_cartesian(ylim = c(0,6000))
# relatively similar, while H is highest median, and E is lowest median
by(diamonds$price/diamonds$carat,diamonds$color,summary)
# weight of diamonds (carat) with frequency polygon
ggplot(diamonds) +
geom_freqpoly(aes(x = carat, binwidth = .01)) +
scale_x_continuous(limits = c(0,3), breaks = seq(0,5,.1))
table(diamonds$carat) > 2000
library(statsr)
library(dplyr)
library(ggplot2)
data(kobe_basket)
glimpse(kobe_basket)
head(kobe_basket)
?calc_streak
kobe_streak <- calc_streak(kobe_basket$shot)
kobe_streak
ggplot(kobe_streak) +
geom_histogram(aes(length), binwidth = 1)
IQR(kobe_streak)
IQR(kobe_streak)
kobe_streak
IQR(kobe_streak$length)
summary(kobe_streak)
coin_outcomes <- c("heads", "tails")
sample(coin_outcomes, size = 1, replace = TRUE)
sim_fair_coin <- sample(coin_outcomes, 100, TRUE)
table(sim_fair_coin)
sim_fair_coin <- sample(coin_outcomes, 100, TRUE, c(.2,.8))
table(sim_fair_coin)
shot_outcomes <- c("H", "M")
independent_shooter <- sample(shot_outcomes, 1, TRUE)
independent_shooter
independent_shooter <- sample(shot_outcomes, 1, TRUE, c(.45,.55))
independent_shooter
sim_basket <- sample(shot_outcomes, 133, TRUE, c(.45,.55))
sim_streak <- calc_streak(sim_basket)
sim_streak
summary(sim_streak)
sim_streak
ggplot(sim_streak) +
geom_histogram(aes(length), binwidth = 1)
summary(sim_streak)
pnorm(24,21,5)
(24-21)/5
pnorm(24,21,5)
(24-21)/5
qnorm(.90, 1500, 300)
qnorm(.1, 21, 5)
1 - pnorm(50,45,3.2)
(50 - 45)/3.2
qnorm(.2, 77, 5)
-.84(5) + 77
-0.84(5) + 77
-0.84*5 + 77
library(ggplot2)
library(tidyverse)
ggplot(diamonds) +
geom_bar(aes(cut, colour = cut))
#color bars w/ fill
ggplot(diamonds) +
geom_bar(aes(cut, fill = cut))
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity))
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity), alpha = 0.2, position = 'identity')
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity), position = 'identity',  alpha = 0.2)
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity), position = 'identity',  fill = NA)
ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) +
geom_bar(fill = NA, position = "identity")
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity), position = 'identity',  fill = NA)
ggplot(diamonds) +
geom_bar(aes(cut, color = clarity), position = 'identity',  fill = NA)
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity), position = 'fill')
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity), position = 'dodge')
ggplot(mpg) +
geom_point(aes(displ,hwy), position = "jitter")
ggplot(mpg) +
geom_point(aes(displ,hwy))
ggplot(mpg) +
geom_jitter(aes(displ,hwy))
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_jitter()
?geom_jitter
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_jitter(amount= 3)
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_count()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_jitter()
?geom_boxplot
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_boxplot()
ggplot(data = mpg, mapping = aes(x = cty, group = derv)) +
geom_boxplot()
ggplot(data = mpg, mapping = aes(x = cty, group = drv)) +
geom_boxplot()
?geom_boxplot
ggplot(data = mpg, mapping = aes(class, hwy)) +
geom_boxplot()
ggplot(data = mpg, mapping = aes(class, hwy)) +
geom_boxplot(position = 'fill')
ggplot(data = mpg, mapping = aes(class, hwy, color = class)) +
geom_boxplot(position = 'fill')
ggplot(data = mpg, mapping = aes(class, hwy, color = class)) +
geom_boxplot(position = 'identity')
ggplot(data = mpg, mapping = aes(class, hwy, color = class)) +
geom_boxplot(position = 'dodge')
ggplot(mpg, aes(class, hwy, color = class)) +
geom_boxplot(position = 'identity')
ggplot(mpg, aes(class, hwy, color = class)) +
geom_boxplot() +
coord_flip()
nz <- map_data("nz")
install.packages(c("nycflights13", "gapminder", "Lahman"))
install.packages("maps")
nz <- map_data("nz")
ggplot(nz, aes(long, lat, group = group)) +
geom_polygon(fill = "white", colour = "black")
ggplot(nz, aes(long, lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_quickmap()
bar <- ggplot(diamonds) +
geom_bar((cut, fill = cut), show.legend = FALSE, width = 1) +
theme(aspect.ratio = 1) +
labs(x = NULL, y = NULL)
bar <- ggplot(diamonds) +
geom_bar(aes(cut, fill = cut), show.legend = FALSE, width = 1) +
theme(aspect.ratio = 1) +
labs(x = NULL, y = NULL)
bar
bar + coord_flip()
bar + coord_polar()
ggplot(diamonds) +
geom_bar(aes(cut, fill = clarity)) +
coord_polar()
?labs
p <- ggplot(mtcars, aes(mpg, wt, colour = cyl)) + geom_point()
p + labs(colour = "Cylinders")
p + labs(x = "New x label")
p + labs(colour = "Cylinders")
ggplot(mtcars, aes(mpg, wt, colour = cyl)) +
geom_point() +
labs(colour = "Cylinders") + # legend
labs(x = "New x label") # x-axis
?coord_quickmap
nzmap + coord_map()
nz + coord_map()
ggplot(nz, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_map()
ggplot(nz, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_quickmap()
ggplot(nz, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_map()
nz <- map_data("nz")
ggplot(nz, aes(x = long, y = lat, group = group))
ggplot(nz, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = "white", colour = "black")
ggplot(nz, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_map()
ggplot(nz, aes(x = long, y = lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_quickmap()
ggplot(mpg, aes(cty, hwy)) +
geom_point() +
geom_abline() +
coord_fixed()
ggplot(mpg, aes(cty, hwy)) +
geom_point() +
geom_abline()
ggplot(mpg, aes(cty, hwy)) +
geom_point() +
geom_abline() +
coord_fixed()
?coord_fixed
?geom_abline
prob_success <-  .25
n <-  245
# estimate mean + SD
mean <- prob_success*n
sd <- sqrt(n*prob_success*(1-prob_success))
?dbinom
dbinom(mean,n,prob_success)
# calculate percentile
dbinom(mean,n,prob_success)
dbinom(70:n,n,prob_success)
sum(dbinom(70:n,n,prob_success))
dbinom(10,6,.56)
dbinom(10,6,0.56)
dbinom(6,10,.56)
dbinom(2,10,.56)
dbinom(600,1000,.56)
dbinom(60,100,.56)
dbinom(60:100,10,.56)
sumdbinom(60:100,100,.56))
sum(dbinom(60:100,100,.56))
dbinom(60,100,.56)
dbinom(2,3,.51)
choose(3,2)*(.51^2)*(.49^1)
dbinom(1,10,.07)
choose(10,1)*(.07^1)*(.93^9)
choose(10,1:10)*(.07^1)*(.93^9)
sum(dbinom(1:10,10,.07))
sum(choose(10,1:10)*(.07^1)*(.93^9))
dbinom(1:10,10,.07)
dbinom(1,10,.07))
dbinom(1,10,.07)
dbinom(1:2,10,.07)
dbinom(1:10,10,.07)
sum(dbinom(1:10,10,.07))
dbinom(35,3000000,.00001)
sum(dbinom(35:3000000,3000000,.00001))
sum(dbinom(35:3000000,3000000,.00001))
prob_success <-  .00001
n <-  3000000
sum(dbinom(35:n,n,prob_success))
sum(dbinom(36:n,n,prob_success))
setwd('C:/Users/NEWNSS/Dropbox/DataScienceMasters/Stats/LSR/sample-master')
load('zeppo.Rdata')
grades
mean(grades)
#higher than class average of 67.5
# 1
x_bar <- mean(grades)
# 2
sig_true <- 9.5 # true SD from assumptions
mu_null <- 67.5 # mean that null (H0) specifies
# 3
n = length(grades) # sample size
# 4
sem <- sig_true / sqrt(n)
# 5
z <- (x_bar - mu_null) / sem
# 2.2596
# calculate p-value
upper.area <- pnorm(q = z, lower.tail = FALSE) # lower.tail = F ==> calculate AUC from 2.26 upwards
lower.area <- pnorm(q = -z, lower.tail = TRUE)
p.value <- lower.area + upper.area
#0.02384574
'**********************************************************************************************'
'1 sample t-test'
'**********************************************************************************************'
# estimate of pop SD, sigma
sd(grades)
library(lsr)
oneSampleTTest(x = grades, mu = 67.5)
'**********************************************************************************************'
'Independent samples Student`s t-test'
'**********************************************************************************************'
load('harpo.Rdata')
head(harpo)
library(lsr)
independentSamplesTTest(grade ~ tutor, harpo, var.equal = T)
'**********************************************************************************************'
'Independent samples Welch`s t-test'
'**********************************************************************************************'
independentSamplesTTest(grade ~ tutor, harpo, var.equal = F)
chico <- read.csv("chico.Rdata")
'**********************************************************************************************'
'1-sample t-test'
'**********************************************************************************************'
# one-sided t-test --> interested if true mean was > 67.5
oneSampleTTest(grades, mu = 67.5, one.sided = "greater")
# interested if group A's scores were higher than group B's
independentSamplesTTest(
formula = grade ~ tutor,
data = harpo,
one.sided = "Anastasia"
)
'pairedSamplesTTest(
~ grade_test2 + grade_test1,
data = chico,
one.sided = "grade_test2"
)'
# use t-test function to do 1 sample t-test
t.test(grades, mu = 67.5)
# welch's independent samples
t.test(grade ~ tutor, harpo)
# student's independent samples
t.test(grade ~ tutor, harpo, var.equal = T)
# paired samples t-test
t.test(x = chico$grade_test2, y = chico$grade_test1, # variable 1 = "test2" scores, variable 2 = "test1" scores
paired = TRUE) # paired test
# Compute an effect size for the data from class:
cohensD(grades, 67.5) # compare students grades mean to hypothesized population mean
# compute Cohen's D in long format
(mean(grades) - 67.5) / sd(grades)
'psych students are achieving grades (mean = 72.3%) that are about .5 SDs higher than the level you`d
expect (67.5%) if they were performing at the same level as other students.
- Judged against Cohen`s rough guide, this is a MODERATE effect size.'
# compute effect size for Student t test (outcome ~ group)
cohensD(grade ~ tutor, harpo, method = "pooled")
# compute effect size for Welch's t-test
cohensD(grade ~ tutor, harpo, method = "unequal")
'version of Cohen`s d reported by independentSamplesTTest() whenever it runs a Welch t-test'
'**********************************************************************************************
Checking Normality
**********************************************************************************************'
# generate N = 100 normally distributed numbers
data <- rnorm(n = 100)
# histogram of sample
hist(data)
# qq plot
qqnorm(data)
'**********************************************************************************************
Shapiro-Wilk
**********************************************************************************************'
# normal data
shapiro.test(data)
# w = high = not a sig departure from normality p > .001
load('clinicaltrial.Rdata')
xtabs(~ drug, clin.trial)
?aggregate
aggregate(~ drug, clin.trial, summary)
aggregate(. ~ drug, clin.trial, summary)
aggregate(mood.gain ~ drug, clin.trial, summary)
library(tidyverse)
library(lsr)
select(aggregate(mood.gain ~ drug, clin.trial, summary), mood.gain.Mean)
select(aggregate(mood.gain ~ drug, clin.trial, summary), Mean)
aggregate(mood.gain ~ drug, clin.trial, mean)
aggregate(mood.gain ~ drug, clin.trial, sd)
library(gplots)
plotmeans(mood.gain ~ drug, data = clin.trial, xlab = "Drug Administered", ylab = "Mood Gain",
n.label = FALSE # don’t display sample size
library(gplots)
plotmeans(mood.gain ~ drug, data = clin.trial, xlab = "Drug Administered", ylab = "Mood Gain",
n.label = FALSE # don’t display sample size)
library(gplots)
plotmeans(mood.gain ~ drug, data = clin.trial, xlab = "Drug Administered", ylab = "Mood Gain",
n.label = FALSE) # don’t display sample size
