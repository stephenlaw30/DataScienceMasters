# takes a data frame + a set of col name/more complicated expressions to order by.
# provide more than 1 column name = mulitple levels
# arrange flights by YMD in ASC
arrange(flights, year, month, day)
# arrange flights GREATEST arrival delay
arrange(flights, desc(arr_delay))
# missing values = always sorted at end
df <- tibble(x = c(5, 2, NA))
arrange(df, x)
arrange(df, desc(x))
'******************************************************'
'5.3 EXERCISES'
'******************************************************'
# How could you use arrange() to sort all missing values to the start? (Hint: use is.na()).
summary(flights)
arrange(flights, desc(is.na(arr_delay)))
# Sort flights to find the most delayed flights.
arrange(flights, desc(dep_delay))
# Find the flights that left earliest.
arrange(flights, dep_time)
# Sort flights to find the fastest flights.
arrange(flights, desc(air_time/distance))
# Which flights travelled the longest?
arrange(flights, desc(distance))
# Which travelled the shortest?
arrange(flights, distance)
'******************************************************'
'5.4 SELECT()'
'******************************************************'
## allows you to rapidly zoom in on a useful subset using operations based on names of variables.
## useful w/ 100s-1000s of variables
# select only date cols
select(flights, year, month, day)
select(flights, year:day)
# select all cols except date cols
select(flights, -(year:day))
## Helper functions you can use within select():
##  - starts_with(), ends_with() , contains()
##  - matches(): selects variables that match a  RegEx
##  - num_range("x", 1:3) matches x1, x2 and x3.
select(flights, contains("dep"))
## can use select() to rename vars, but it drops all vars not explicitly mentioned
## instead use rename(df, new = old)
rename(flights, miles = distance)
## can use select() in conjunction w/ the everything() helper.
## useful w/ a handful of variables you'd like to move to the start of the data frame
select(flights, air_time, everything())
'******************************************************'
'5.4 EXERCISES'
'******************************************************'
## Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.
select(flights, "dep_time","dep_delay","arr_time","arr_delay")
select(flights, c(4,6,7,9))
select(flights, starts_with("dep"), starts_with("arr"))
select(flights, ends_with("time"), ends_with("delay"), -starts_with('sched'), -starts_with('air'))
select(flights, contains("dep_"), contains("arr_"), -starts_with('sched'))
## What happens if you include the name of a variable multiple times in a select() call?
select(flights, year, year)
# only shows up once
## What does one_of() function do? Why might it be helpful in conjunction with this vector?
select(flights, one_of(c("year", "month", "day", "dep_delay", "arr_delay")))
## Does the result of running the following code surprise you?
select(flights, contains("TIME"))
## How do the select helpers deal with case by default? How can you change that default?
select(flights, contains("TIME", ignore.case = F))
select(flights, contains("TIME", ignore.case = T))
'******************************************************'
'5.5 MUTATE()'
'******************************************************'
## mutate adds new variables as functions of existing ones --> only at end of dataset
# create smaller dataset to see mutate() results
flights_sml <- select(flights, year:day, ends_with("delay"), distance, air_time)
# new cols
mutate(flights_sml,
gain = arr_delay - dep_delay,
speed = (distance / air_time) * 60,
# refer to new vars in even newer var
hours = air_time / 60,
gain_per_hour = gain / hours)
## to only keep new vals use transmute()
transmute(flights_sml,
gain = arr_delay - dep_delay,
speed = (distance / air_time) * 60,
# refer to new vars in even newer var
hours = air_time / 60,
gain_per_hour = gain / hours)
'Many functions for creating new variables you can use w/ mutate().
- Key property = function must be *vectorised* = take a vector of values as input, return a vector w/ same # of values as output.
- Selection of functions that are frequently useful:
- Arithmetic operators: +, -, *, /, > ==> all vectorised, using "recycling rules"
- "recycling rules" = If 1 parameter is shorter than the other, it will be automatically extended to be the same length.
- most useful when 1 argument is a single number: air_time / 60, hours * 60 + minute, etc.
- Arithmetic operators are also useful in conjunction w/ the aggregate functions
- Ex: x / sum(x) calculates a proportion of a total, y - mean(y) computes difference from the mean.
- Modular arithmetic: %/% (integer division) + %% (remainder)
- x == y * (x %/% y) + (x %% y).
- Modular arithmetic = handy tool b/c allows you to break integers up into pieces.
- Can compute hour and minute from dep_time with:'
transmute(flights, hour = air_time %/% 60, minute = air_time %% 60)
transmute(flights, dep_time, hour = dep_time %/% 100, minute = dep_time %% 100)
' - Logs: log(), log2(), log10() = incredibly useful for dealing w/ data that ranges across multiple orders of magnitude.
- also convert multiplicative relationships to additive
- All else being equal, log2() = easiest to interpret --> difference of 1 on log scale = doubling on original scale +
a difference of -1 corresponds to halving.
- Offsets: lead() + lag() allow you to refer to leading or lagging values
- allows you to compute running differences (e.g. x - lag(x)) or find when values change (x != lag(x)).
- most useful in conjunction w/ group_by()'
x <- 1:10
lag(x,4) # lag vector by 4 positions (chop off last n elements)
lead(x,4) # lead vector by 4 positions (chop off 1st n elements)
'  - Cumulative + rolling aggregates = running sums, products, mins,  maxes w/ cumsum(), cumprod(), cummin(), cummax()
- dplyr provides cummean() for cumulative means
- For rolling aggregates (i.e. sum computed over a rolling window), try RcppRoll package'
cumsum(x)
cummean(x)
' - Logical comparisons, <, <=, >, >=, !=
- If doing a complex sequence of logical operations it`s often a good idea to store the interim values in new variables
so you can check that each step is working as expected.
- Ranking: # of ranking functions, but start w/ min_rank() = does most usual type of ranking (e.g. 1st, 2nd, 2nd, 4th).
- The default gives smallest values small ranks --> use desc(x) to give the largest values the smallest ranks.'
y <- c(1, 2, 2, NA, 3, 4)
?min_rank(y)
'[1]  1  2  2 NA  4  5 ==> 1st lowest, tied for 2nd, tied for 2nd (no 3rd), NA, 4th lowest (bc no 3rd), 5th least'
min_rank(desc(y))
'[1]  5  3  3 NA  2  1 ==> least greatest, tied for 3rd least greatest NA, 2nd least greatest, 1st least greatest'
'   - If min_rank() doesn`t do what you need, look at variants row_number(), dense_rank(), percent_rank(), cume_dist(), ntile(). '
row_number(y)
dense_rank(y)
percent_rank(y)
cume_dist(y)
'******************************************************'
'5.5 EXERCISES()'
'******************************************************'
## Currently dep_time and sched_dep_time are convenient to look at, but hard to compute w/ b/c they're not really continuous numbers.
## Convert them to a more convenient representation of number of minutes since midnight.
mutate(flights,
dep_midnight = (dep_time %/% 100)*60 + (dep_time %% 100),
sched_dep_time_after_midnight = (sched_dep_time %/% 100)*60 + (sched_dep_time %% 100)) %>%
select(dep_time,dep_midnight,sched_dep_time,sched_dep_time_after_midnight)
## Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it?
mutate(flights,
air_time_2 = ((arr_time %/% 100)*60 + (arr_time %% 100)) - ((dep_time %/% 100)*60 + (dep_time %% 100))) %>%
select(air_time, air_time_2)
# even after converting from clock format to minutes after midnight, they should be the same
## Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?
# expect sched_dep_time - dep_time = dep_delay
mutate(flights, dep_delay2 = dep_time - sched_dep_time) %>%
select(sched_dep_time, dep_time, dep_delay, dep_delay2)
# 2nd dep_delay is off due to clock formatting of time vars
##  Find the 10 most delayed flights using a ranking function. How do you want to handle ties?
# most delayed
as.data.frame(head(arrange(flights, desc(dep_delay)),15))
as.data.frame(head(arrange(flights, desc(dep_delay)),15)) %>%
mutate(delayed_rank = min_rank(-dep_delay)) %>%
select(1:5, delayed_rank)
# there are no ties for the top 10 most delayed
## What does 1:3 + 1:10 return? Why?
1:3 + 1:10
# mismatched length of data not currently vectorized
## What trigonometric functions does R provide?
'cos(x)
sin(x)
tan(x)
acos(x)
asin(x)
atan(x)
atan2(y, x)
cospi(x)
sinpi(x)
tanpi(x)'
'******************************************************
5.6 Grouped summaries with summarise()
******************************************************'
## summarize collapses dataframes to single rows
summarize(flights, delay = mean(dep_delay, na.rm = T))
## not terribly useful unless paired w/ group_by --> changes unit of analysis from a complete dataset to individual groups.
## when using dplyr verbs on a grouped data frame they'll be automatically applied "by group".
# get average delay by date
group_by(flights, year, month, day) %>%
summarize(delay = mean(dep_delay, na.rm = T))
## group_by() + summarise() provide 1 of the tools used most commonly when working w/ dplyr: grouped summaries.
# explore the relationship between the distance and average delay for each destination w/ pipes
group_by(flights, dest) %>%
summarize(count = n(),
dist = mean(distance, na.rm = T),
delay = mean(dep_delay, na.rm = T)) %>%
filter(count > 20, dest != "HNL") %>%
ggplot(aes(dist,delay)) + # graph scatterplot of relationship
geom_point(aes(size = count), alpha = 1/3) + # make each point grow according to count of flights leaving each destination
geom_smooth(se = FALSE) # remove CI bands
## x %>% f(y) turns into f(x, y), and x %>% f(y) %>% g(z) turns into g(f(x, y), z) and so on.
## aggregation functions obey the usual rule of missing values: if there's ANY missing value in the input, output = a missing value.
## Fortunately, all aggregation functions have na.rm arguments
# for missing values that represent cancelled flights, removing the cancelled flights
non_cancelled_flights <- filter(flights, !is.na(arr_delay), !is.na(dep_delay))
non_cancelled_flights %>% group_by(year,month,day) %>%
summarize(mean = mean(dep_delay))
## Whenever you do any aggregation = always good idea to include either a count (n()), or count of non-missing values (sum(!is.na(x))).
## helps check that you're not drawing conclusions based on very small amounts of data.
# look at planes (identified by their tail number) that have the highest average delays
delays <- non_cancelled_flights %>%
group_by(tailnum) %>%
summarize(delay = mean(dep_delay))# %>%
delays %>%
ggplot() +
geom_freqpoly(aes(delay), binwidth = 10)
# some planes have delays > 5 hrs (> 300 minutes)
# draw scatterplot of flights vs avg delay
delays2 <- non_cancelled_flights %>%
group_by(tailnum) %>%
summarize(delay = mean(dep_delay, na.rm = T),
n = n())
delays2 %>%
ggplot() +
geom_point(aes(n,delay), alpha = 1/10)
# very few DPs > 400 min delay
## Look at average performance of batters in baseball as related to at-bats
batting <- as.tibble(Lahman::Batting)
# plot skill of batter (measured by ba) against # of opportunities to hit the ball (at-bat, ab),
# 1) get BA + ABs per each player
batters <- batting %>%
group_by(playerID) %>%
summarize(ba = sum(H, na.rm = T) / sum(AB, na.rm = T),
ab = sum(AB, na.rm = T))
# plot it
batters %>%
filter(ab > 100) %>%
ggplot(aes(ab,ba)) +
geom_point() +
geom_smooth(se = F)
## as ABs increase, BA barely increases, and its a wide range for small #'s of ABs (not surprising)
## 2 patterns
##    1) As above, variation in our aggregate decreases as we get more DPs.
##    2) Have positive correlation between skill (BA) + opportunities to hit the ball (AB)
##        - This is b/c teams control who gets to play will obviously pick best players.
## This also has important implications for ranking.
# *naively* sort players w/ best BA
batters %>%
arrange(desc(ba)) %>%
mutate(ba_rank = min_rank(-ba))
# clearly lucky, not necessarily skilled:
## R provides many other useful summary functions:
##  - median()
##  - sometimes useful to combine aggregation w/ logical subsetting
non_cancelled_flights %>%
group_by(year, month, day) %>%
summarize(overall_avg_delay = mean(arr_delay),
positive_avg_delay = mean(arr_delay[arr_delay > 0]))
#     -see negative delays highly change data results
##  - measures of spread = sd(), IQR(), mad() - median absolute deviation
##      - 2nd two are more robust (less sensitive to outliers)
# Why is distance to some destinations more variable than to others?
non_cancelled_flights %>%
group_by(dest) %>%
summarize(distance_sd = sd(distance),
distance_iqr = IQR(distance),
distance_mad = mad(distance)) %>%
arrange(desc(distance_sd))
## measures of rank = min(), max(), quantile(x, .25) = value which 25% of data in x are below
##    - quantiles = generalization of median
# When do the first and last flights leave each day?
non_cancelled_flights %>%
group_by(year, month, day) %>%
summarize(first_flight = min(dep_time),
last_flight = max(dep_time))
## measures of position = first(), last(), nth(x,position) --> similar to x[1],x[2], etc.
##  - also similar to x[length(x)]
##  - THESE allow you to set default values for positions that don't exist (3rd element from [1,2])
non_cancelled_flights %>%
group_by(year, month, day) %>%
summarize(first_flight = first(dep_time,default = 2400),
last_flight = last(dep_time, default = 2399))
## position functions = complementary to filtering on ranks.
##    - Filtering gives you all variables, w/ each observation in a separate row:
non_cancelled_flights %>%
filter(year,month,day) %>%
mutate(rank = min_rank(desc(dep_time))) %>%
filter(rank %in% range(rank)) %>%
select(1:9,rank)
## n() returns counts/size of current group
## count non-missing values -> sum(!is.na(x))
## count distinct values --> n_distinct(x)
# Which destinations have the most carriers?
non_cancelled_flights %>%
group_by(dest) %>%
summarise(carriers = n_distinct(carrier)) %>%
arrange(desc(carriers))
# which airports had most destinations
non_cancelled_flights %>%
count(dest) %>%
arrange(desc(n))
## can optionally provide a weight variable
# use weights to count sum total number of miles a plane flew:
non_cancelled_flights %>%
count(tailnum, wt = distance)
## Counts + proportions of logical values: sum(x > 10), mean(y == 0).
##  - When used w/ numeric functions, TRUE converted to 1, FALSE to 0.
##  - This makes sum() + mean() very useful as sum(x) gives # of TRUEs in x + mean(x)
##      gives the proportion.
#  How many flights left before 5am on each day?
#   - (usually indicates delayed flights from previous day)
non_cancelled_flights %>%
group_by(year,month,day) %>%
summarize(early = sum(dep_time < 500))
# What proportion of flights are delayed by more than an hour?
non_cancelled_flights %>%
group_by(year,month,day) %>%
summarise(prop_delay_over_1hr = mean(arr_delay > 60))
'*******************5.6.5 Grouping by multiple variables***************************'
## multiple levels of grouping = makes it easier to progressively roll-up a dataset
daily <- flights %>%
group_by(year,month,day)
(per_day <- daily %>%
summarize(num_flights = n()))
(per_month <- per_day %>%
summarize(num_flights = sum(num_flights)))
(per_year <- per_month %>%
summarize(num_flights = sum(num_flights)))
## Be careful when progressively rolling up summaries --> OK for sums + counts,
##    - but need to think about weighting means + variances
##    - not possible to do it exactly for rank-based statistics like median.
##    - i.e. sum of groupwise sums = overall sum, but median of groupwise medians != overall median.
'****************UNGROUPING**************************'
daily %>%
ungroup() %>% # not longer grouped by date at all
summarize(num_flights = n()) # total flights in whole ungrouped dataset
'******************************************************'
'5.6 EXERCISES'
'******************************************************'
## Brainstorm 5+ different ways to assess typical delay characteristics of a group of flights.
## Consider the following scenarios:
##  - Flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.
non_cancelled_flights %>%
group_by(flight) %>%
summarise(prop_early_over_half = mean(arr_delay < -15, na.rm = T),
prop_late_over_half = mean(arr_delay > 15,  na.rm = T)) %>%
filter(prop_early_over_half == .5 & prop_late_over_half == .5)
# there are none
##  - A flight is always 10 minutes late.
non_cancelled_flights %>%
group_by(flight) %>%
filter(arr_delay == 10)
## A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.
non_cancelled_flights %>%
group_by(flight) %>%
summarise(prop_early_over_half = mean(arr_delay < -30, na.rm = T),
prop_late_over_half = mean(arr_delay > 30,  na.rm = T)) %>%
filter(prop_early_over_half == .5 & prop_late_over_half == .5)
## 99% of the time a flight is on time. 1% of the time it’s 2 hours late.
non_cancelled_flights %>%
group_by(flight) %>%
summarise(prop_on_time = mean(arr_delay == 0, na.rm = T),
prop_2hrs_late = mean(arr_delay == 120,  na.rm = T)) %>%
filter(prop_on_time == .99 & prop_2hrs_late == .01)
## Which is more important: arrival delay or departure delay?
## Come up w/ another approach to get the same output as: (without using count()).
non_cancelled_flights %>% count(dest)
non_cancelled_flights %>% group_by(dest) %>% summarize(count = n())
## Come up w/ another approach to get the same output as: (without using count()).
non_cancelled_flights %>% count(tailnum, wt = distance)
non_cancelled_flights %>% group_by(tailnum) %>% summarize(distance = sum(distance))
## Definition of cancelled flights ==> (is.na(dep_delay) | is.na(arr_delay) ) is slightly suboptimal.
# only need flights that did not depart, as they cannot arrive if they didn't depart
## Look at # of cancelled flights per day. Is there a pattern? Is the proportion of cancelled
##  flights related to the average delay?
flights %>%
group_by(year,month,day) %>%
summarise(cancelled_flights = sum(!is.na(dep_delay)),
prop_cancelled = mean(is.na(dep_delay)),
avg_delay = mean(dep_delay, na.rm = T)) %>%
arrange(desc(prop_cancelled)) %>%
ggplot(aes(avg_delay,prop_cancelled)) +
geom_point()
# looks like a slight positive one, with outliers
## Which carrier has the worst delays? Challenge:
non_cancelled_flights %>%
group_by(carrier) %>%
summarise(avg_delay = mean(dep_delay, na.rm = T)) %>%
arrange(desc(avg_delay))
## can you disentangle the effects of bad airports vs. bad carriers? Why/why not?
non_cancelled_flights %>% group_by(carrier, dest) %>% summarise(n())
flights_sml %>%
group_by(year, month, day) %>%
filter(rank(desc(arr_delay)) < 10)
(popular_dests <- flights %>%
group_by(dest) %>%
filter(n() > 365))
popular_dests %>%
filter(arr_delay > 0) %>%
mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
select(year:day, dest, arr_delay, prop_delay)
?aov
setwd('C:/Users/newnss/Dropbox/DataScienceMasters/Stats/LSR/sample-master')
load('clinicaltrial.Rdata')
library(tidyverse)
library(lsr)
drug.anova <- aov(mood.gain ~ drug, clin.trial)
class(drug.anova)
names(drug.anova)
print(drug.anova)
summary(drug.anova)
setwd('C:/Users/newnss/Dropbox/DataScienceMasters/Stats/LSR/sample-master')
load('clinicaltrial.Rdata')
library(tidyverse)
library(lsr)
'.	Suppose you`ve become involved in a clinical trial in testing a new antidepressant drug Joyzepam.
.	In order to construct a fair test of drug`s effectiveness, the study involves 3 separate drugs to be
administered = yours, a placebo, an existing antidepressant/anti-anxiety drug Anxifree.
.	A collection of 18 participants w/ moderate to severe depression are recruited for initial testing.
.	B/c the drugs are sometimes administered in conjunction w/ psychological therapy, study includes 9 people
undergoing cognitive behavioral therapy (CBT) + 9 who are not.
.	Participants are randomly assigned (doubly blinded) a treatment, such that there are 3 CBT people + 3
no-therapy people assigned to each of the 3 drugs.
.	A psychologist assesses mood of each person after a 3-month run w/ each drug + overall improvement in each
person`s mood is assessed on a scale ranging from -5 to 5'
# see how many people are in each test group (# of obsverations broken out by drug)
xtabs(~ drug, clin.trial)
xtabs(~ therapy + drug, clin.trial)
# 6 total, 3 CTB, 3 Non-CTB
# all groups have same # of observations = BALANCED experimental design
# Calculate means + SDs for mood.gain variable broken down by drug
aggregate(mood.gain ~ drug, clin.trial, mean)
aggregate(mood.gain ~ drug, clin.trial, sd)
# plot means for all 3 drug groups
library(gplots)
plotmeans(mood.gain ~ drug, data = clin.trial, xlab = "Drug Administered", ylab = "Mood Gain",
n.label = FALSE) # don't display sample size
# see larger improvement for our drug, but is this difference significant? (real or due to chance?)
'
H0: it is true that µP = µA = µJ
H1: it is not true that µP = µA = µJ '
outcome_var <- clin.trial$mood.gain
grouping_var <- clin.trial$drug
# get all group means for each observation
grp_means <- tapply(outcome_var, grouping_var, mean)
grp_means_split <-  grp_means[grouping_var]
# get group deviations from the group means
within_group_deviations <- outcome_var - grp_means_split
# get within-group SS
(SSw <- sum(within_group_deviations^2))
# get grand mean
grand_mean <- mean(clin.trial$mood.gain)
# get group mean deviations from grand mean
between_group_deviations_sq <- (grp_means - grand_mean)^2
# get # of observations in each groups
grp_size <- tapply(outcome_var, grouping_var, length)
# calculate SSb
(SSb <- sum(grp_size*between_group_deviations_sq))
# get dF
DFb <- length(grp_size)-1
DFw <- length(grp_means_split) - length(grp_size)
# get means square values
MSw <- SSw / DFw
MSb <- SSb / DFb
# calculate F ration
(F_value = MSb / MSw)
# large value needed (since F-test is always 1-sided), so this suggests we reject null
# check if result of F-test is significant
pf(F_value, df1 = DFb, df2 = DFw, lower.tail = F)
# very significant result (to the -5 power) unless we're being extremely conservative about Type I error rate
'F(2,15) = 18.6, P < .001'
'********************ANOVA IN R CODE********************'
drug.anova <- aov(mood.gain ~ drug, clin.trial)
class(drug.anova) # object is both an aov obj + a linear model
names(drug.anova) # lots of things w/in
print(drug.anova) # drug = SSb, Residuals = SSw (all other/leftover variability)
# get f-value + p-value
summary(drug.anova) # F(2,15) = 18.61, p < .0001
# effect size = eta squared
SS
SStot <- SSb + SSw
(eta_sq <- SSb/SStot)
(eta <- sqrt(eta_sq))
etaSquared(drug.anova)
?pairwise.t.test
pairwise.t.test(clin.trial$mood.gain, clin.trial$drug, p.adjust.method = "none")
posthocPairwiseT(drug.anova, p.adjust.method = "none")
posthocPairwiseT(drug.anova) # same output (almost)
pairwise.t.test(clin.trial$mood.gain, clin.trial$drug, p.adjust.method = "bonferri")
posthocPairwiseT(drug.anova, p.adjust.method = "bonferri") # same output (almost)
pairwise.t.test(clin.trial$mood.gain, clin.trial$drug, p.adjust.method = "bonferri")
posthocPairwiseT(drug.anova, p.adjust.method = "bonferri") # same output (almost)
pairwise.t.test(clin.trial$mood.gain, clin.trial$drug, p.adjust.method = "bonferroni")
posthocPairwiseT(drug.anova, p.adjust.method = "bonferroni") # same output (almost)
pairwise.t.test(clin.trial$mood.gain, clin.trial$drug)
posthocPairwiseT(drug.anova) # same output (almost)
library(tidyverse)
library(lsr)
?leveneTest
library(car)
leveneTest(drug.anova)
leveneTest(drug.anova, center = "mean") # not significant difference = data have homoscedasticity = population SD is the same for all groups.
leveneTest(mood.gain ~ drug, clin.trial)
leveneTest(clin.trial$mood.gain,clin.trial$drug)
oneway.test(mood.gain ~ drug, clin.trial, var.equal = F)
oneway.test(mood.gain ~ drug, clin.trial, var.equal = T)
drug_residuals <- drug.anova$residuals
hist(drug_residuals)
qqnorm(drug_residuals)
shapiro.test(drug_residuals)
kruskal.test(mood.gain ~ drug, clin.trial)
data <- list(clin.trial$mood.gain[clin.trial$drug == "placebo"],clin.trial$mood.gain[clin.trial$drug == "joyzepam"],
clin.trial$mood.gain[clin.trial$drug == "anxifree"])
data
kruskal.test(data)
summary(anova(mood.gain ~ therap, clin.trial))
summary(anova(mood.gain ~ therapy, clin.trial))
summary(aov(mood.gain ~ therapy, clin.trial))
t.test(mood.gain ~ therapy, clin.trial, var.equal = T)
-1.3068^2 == 1.708
-1.3068^2
(-1.3068)^2
