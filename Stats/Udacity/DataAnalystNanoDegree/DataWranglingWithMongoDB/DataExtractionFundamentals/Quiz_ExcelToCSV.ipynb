{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the time and value of max load for each of the regions COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# set data files\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "# open given file + extract\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "#def parse_file(datafile):\n",
    "    # open the workbook w/ xlrd library's open_workbook method and get the 1st sheet\n",
    "workbook = xlrd.open_workbook(datafile)\n",
    "sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "data = {}\n",
    "headers = ['Station','Year','Month','Day','Hour','Max Load']\n",
    "\n",
    "# for each of the stations\n",
    "for i in range(1,9):\n",
    "    # grab the station name from the value in current column n in the 1st row\n",
    "    station = sheet.cell_value(0,i)\n",
    "    \n",
    "    # grab all values in current column n from 2nd row until the end\n",
    "    col_values = sheet.col_values(i, start_rowx = 1, end_rowx = None)\n",
    "    \n",
    "    # get max value from current column n's values\n",
    "    max_col_value = round(max(col_values),0)\n",
    "    \n",
    "    # get index of this max value from column n\n",
    "    max_col_value_row_pos = col_values.index(max(col_values),0) + 1\n",
    "    \n",
    "    # get the date time for this max value from current column n\n",
    "    max_col_value_time = xlrd.xldate_as_tuple(sheet.cell_value(max_col_value_row_pos,0), 0)\n",
    "    \n",
    "    # input grabbed data into dictionary\n",
    "    data[station] = {'maxdate': max_col_value_time,\n",
    "                    'maxvalue': max_col_value}\n",
    "    \n",
    "# open file to write to \n",
    "with open(outfile, 'wt', newline='') as csvfile:\n",
    "    \n",
    "    data_writer = csv.writer(csvfile, delimiter ='|',quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # write in headers as own row\n",
    "    data_writer.writerow(headers)\n",
    "    \n",
    "    # for each kv-pair in the data dictionary\n",
    "    for s in data:\n",
    "        # unpack the dictionary's tuple value for the max value's date\n",
    "        year, month, day, hour, min, sec = data[s]['maxdate']\n",
    "        \n",
    "        # get the max value\n",
    "        value = data[s]['maxvalue']\n",
    "        \n",
    "        # write station, specified date field, and max value to the file as a row\n",
    "        data_writer.writerow([s, year, month, day, hour, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "ZIP file contents not a known type of workbook",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5b797beea4e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-5b797beea4e8>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mopen_zip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0msave_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-5b797beea4e8>\u001b[0m in \u001b[0;36mparse_file\u001b[0;34m(datafile)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mworkbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_by_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nimz\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'content.xml'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Openoffice.org ODS file; not supported'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ZIP file contents not a known type of workbook'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXLRDError\u001b[0m: ZIP file contents not a known type of workbook"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "'''\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    data = {}\n",
    "    headers = ['Station','Year','Month','Day','Hour','Max Load']\n",
    "\n",
    "    # for each desired column\n",
    "    for i in range(1,len(headers)):\n",
    "        # grab the station name from the value in current column n in the 1st row\n",
    "        station = sheet.cell_value(0,i)\n",
    "    \n",
    "        # grab all values in current column n from 2nd row until the end\n",
    "        col_values = sheet.col_values(i, start_rowx = 1, end_rowx = None)\n",
    "    \n",
    "        # get max value from current column n's values\n",
    "        max_col_value = round(max(col_values),0)\n",
    "    \n",
    "        # get index of this max value from column n\n",
    "        max_col_value_row_pos = col_values.index(max(col_values),0) + 1\n",
    "    \n",
    "        # get the date time for this max value from current column n\n",
    "        max_col_value_time = xlrd.xldate_as_tuple(sheet.cell_value(max_col_value_row_pos,0), 0)\n",
    "    \n",
    "        # input grabbed data into dictionary\n",
    "        data[station] = {'maxdate': max_col_value_time,\n",
    "                        'maxvalue': max_col_value}\n",
    "    \n",
    "        return data\n",
    "        \n",
    "def save_file(data, filename):\n",
    "    # open file to write to \n",
    "    with open(outfile, 'wt', newline='') as csvfile:\n",
    "    \n",
    "        data_writer = csv.writer(csvfile, delimiter ='|',quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "        # write in headers as own row\n",
    "        data_writer.writerow(headers)\n",
    "        \n",
    "        # for each kv-pair in the data dictionary\n",
    "        for s in data:\n",
    "            # unpack the dictionary's tuple value for the max value's date\n",
    "            year, month, day, hour, min, sec = data[s]['maxdate']\n",
    "        \n",
    "            # get the max value\n",
    "            value = data[s]['maxvalue']\n",
    "        \n",
    "            # write station, specified date field, and max value to the file as a row\n",
    "            data_writer.writerow([s, year, month, day, hour, value])\n",
    "    \n",
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "    save_file(data, outfile)\n",
    "\n",
    "    number_of_rows = 0\n",
    "    stations = []\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': '2281.2722140000024',\n",
    "                        'Year': '2013',\n",
    "                        'Month': '6',\n",
    "                        'Day': '26',\n",
    "                        'Hour': '17'}}\n",
    "    correct_stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH',\n",
    "                        'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    fields = ['Year', 'Month', 'Day', 'Hour', 'Max Load']\n",
    "\n",
    "    with open(outfile) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "            station = line['Station']\n",
    "            if station == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    # Check if 'Max Load' is within .1 of answer\n",
    "                    if field == 'Max Load':\n",
    "                        max_answer = round(float(ans[station][field]), 1)\n",
    "                        max_line = round(float(line[field]), 1)\n",
    "                        assert max_answer == max_line\n",
    "\n",
    "                    # Otherwise check for equality\n",
    "                    else:\n",
    "                        assert ans[station][field] == line[field]\n",
    "\n",
    "            number_of_rows += 1\n",
    "            stations.append(station)\n",
    "\n",
    "        # Output should be 8 lines not including header\n",
    "        assert number_of_rows == 8\n",
    "\n",
    "        # Check Station Names\n",
    "        assert set(stations) == set(correct_stations)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
