{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the time and value of max load for each of the regions COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# set data files\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "# open given file + extract\n",
    "#def open_zip(datafile):\n",
    "#    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "#        myzip.extractall()\n",
    "\n",
    "#def parse_file(datafile):\n",
    "# open the workbook w/ xlrd library's open_workbook method and get the 1st sheet\n",
    "workbook = xlrd.open_workbook(datafile)\n",
    "sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "data = {}\n",
    "\n",
    "# for each of the stations\n",
    "for i in range(1,9):\n",
    "    # grab the station name from the value in current column n in the 1st row\n",
    "    station = sheet.cell_value(0,i)\n",
    "    \n",
    "    # grab all values in current column n from 2nd row until the end\n",
    "    col_values = sheet.col_values(i, start_rowx = 1, end_rowx = None)\n",
    "    \n",
    "    # get max value from current column n's values\n",
    "    max_col_value = round(max(col_values),1)\n",
    "    \n",
    "    # get index of this max value from column n\n",
    "    max_col_value_row_pos = col_values.index(max(col_values),0) + 1\n",
    "    \n",
    "    # get the date time for this max value from current column n\n",
    "    max_col_value_time = xlrd.xldate_as_tuple(sheet.cell_value(max_col_value_row_pos,0), 0)\n",
    "    \n",
    "    # input grabbed data into dictionary\n",
    "    data[station] = {'maxdate': max_col_value_time,\n",
    "                    'maxvalue': max_col_value}\n",
    "    \n",
    "# open file to write to \n",
    "with open(outfile, 'wt', newline='') as csvfile:\n",
    "    \n",
    "    data_writer = csv.writer(csvfile, delimiter ='|',quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    headers = ['Station','Year','Month','Day','Hour','Max Load']\n",
    "    \n",
    "    # write in headers as own row\n",
    "    data_writer.writerow(headers)\n",
    "    \n",
    "    # for each kv-pair in the data dictionary\n",
    "    for s in data:\n",
    "        # unpack the dictionary's tuple value for the max value's date\n",
    "        year, month, day, hour, min, sec = data[s]['maxdate']\n",
    "        \n",
    "        # get the max value\n",
    "        value = data[s]['maxvalue']\n",
    "        \n",
    "        # write station, specified date field, and max value to the file as a row\n",
    "        data_writer.writerow([s, year, month, day, hour, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> ACTUAL SUBMISSION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "'''\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # for each of the stations\n",
    "    for i in range(1,9):\n",
    "        # grab the station name from the value in current column n in the 1st row\n",
    "        station = sheet.cell_value(0,i)\n",
    "        \n",
    "        # grab all values in current column n from 2nd row until the end\n",
    "        col_values = sheet.col_values(i, start_rowx = 1, end_rowx = None)\n",
    "        \n",
    "        # get max value from current column n's values\n",
    "        max_col_value = round(max(col_values),1)\n",
    "        \n",
    "        # get index of this max value from column n\n",
    "        max_col_value_row_pos = col_values.index(max(col_values),0) + 1\n",
    "        \n",
    "        # get the date time for this max value from current column n\n",
    "        max_col_value_time = xlrd.xldate_as_tuple(sheet.cell_value(max_col_value_row_pos,0), 0)\n",
    "        \n",
    "        # input grabbed data into dictionary\n",
    "        data[station] = {'maxdate': max_col_value_time,\n",
    "                        'maxvalue': max_col_value}\n",
    "    return data\n",
    "\n",
    "def save_file(data, filename):\n",
    "    # open file to write to \n",
    "    with open(outfile, 'wt') as csvfile:\n",
    "        \n",
    "        data_writer = csv.writer(csvfile, delimiter ='|',quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        headers = ['Station','Year','Month','Day','Hour','Max Load']\n",
    "\n",
    "        # write in headers as own row\n",
    "        data_writer.writerow(headers)\n",
    "        \n",
    "        # for each kv-pair in the data dictionary\n",
    "        for s in data:\n",
    "            # unpack the dictionary's tuple value for the max value's date\n",
    "            year, month, day, hour, min, sec = data[s]['maxdate']\n",
    "            \n",
    "            # get the max value\n",
    "            value = data[s]['maxvalue']\n",
    "            \n",
    "            # write station, specified date field, and max value to the file as a row\n",
    "            data_writer.writerow([s, year, month, day, hour, value])\n",
    "\n",
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "    save_file(data, outfile)\n",
    "\n",
    "    number_of_rows = 0\n",
    "    stations = []\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': '2281.2722140000024',\n",
    "                        'Year': '2013',\n",
    "                        'Month': '6',\n",
    "                        'Day': '26',\n",
    "                        'Hour': '17'}}\n",
    "    correct_stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH',\n",
    "                        'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    fields = ['Year', 'Month', 'Day', 'Hour', 'Max Load']\n",
    "\n",
    "    with open(outfile) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "            station = line['Station']\n",
    "            if station == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    # Check if 'Max Load' is within .1 of answer\n",
    "                    if field == 'Max Load':\n",
    "                        max_answer = round(float(ans[station][field]), 1)\n",
    "                        max_line = round(float(line[field]), 1)\n",
    "                        assert max_answer == max_line\n",
    "\n",
    "                    # Otherwise check for equality\n",
    "                    else:\n",
    "                        assert ans[station][field] == line[field]\n",
    "\n",
    "            number_of_rows += 1\n",
    "            stations.append(station)\n",
    "\n",
    "        # Output should be 8 lines not including header\n",
    "        assert number_of_rows == 8\n",
    "\n",
    "        # Check Station Names\n",
    "        assert set(stations) == set(correct_stations)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '2013_ERCOT_Hourly_Load_Data.xls',\n",
       " '2013_ERCOT_Hourly_Load_Data.zip',\n",
       " '2013_Max_Loads.csv',\n",
       " '745090.csv',\n",
       " 'beatles-diskography.csv',\n",
       " 'JSON-playground.ipynb',\n",
       " 'JSON-playground.py',\n",
       " 'Quiz_ExcelToCSV.ipynb',\n",
       " 'Quiz_UsingCSVModule.ipynb',\n",
       " 'readingExcelFiles.py',\n",
       " 'readingExcelFiles_alternate.py',\n",
       " 'simple.py',\n",
       " 'xlrdIntro.py']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
