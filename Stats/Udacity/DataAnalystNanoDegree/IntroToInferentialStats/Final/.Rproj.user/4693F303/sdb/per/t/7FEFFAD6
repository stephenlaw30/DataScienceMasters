{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Udacity Intro to Descriptive Statistics Final Project\"\noutput:\n  html_document: default\n  github_document: default\n  word_document: default\n---\n# *Questions for Investigation*\n\nFor the experiment, I have a standard deck of 52 playing cards divided into four suits (spades (&#9824;), hearts (&#9829;), diamonds (&#9830;), and clubs (&#9827;)), with each suit containing thirteen cards (Ace, the numbers 2 through 10, and the three face cards: Jack, Queen, and King). \n\nFor the first part of the experiment, I took 10,000 draws of a single card from the deck, and assigned each card a specified value\n\n  * Ace takes a value of 1\n  * Numbered cards take the value printed on the card\n  * Jack, Queen, and King each take a value of 10.\n\n```{r load data, echo = FALSE}\nvalues <- as.vector(read.csv('values.csv')[,2])\nsamples <- as.vector(read.csv('samples.csv')[,2])\noptions(warn=-1)\n\n```\n\nThen, we plot a histogram depicting the relative frequencies of the card values, with added lines for the median and mean.\n\n<center>\n```{r random draws histogram, echo = FALSE}\n#plot histogram w/ mean and median\nlibrary(ggplot2)\nggplot() + \n  aes(x=values) + \n  geom_histogram(binwidth = 1, boundary = 2, color = 'white', aes(fill = ..count..)) +\n  guides(fill=FALSE) +\n  ylab('Frequency') + \n  xlab('Card Value') +\n  ylim(0,5000) +\n  geom_vline(aes(xintercept=mean(values)),\n             color=\"green\", size=1) + \n  geom_vline(aes(xintercept=median(values)),\n             color=\"red\", size=1) +\n  geom_text(aes(x=mean(values)-0.5, label=\"Mean\", y=4000), \n            colour=\"black\", angle=0, size=4) +\n  geom_text(aes(x=median(values)+0.5, label=\"Median\", y=4000), \n            colour=\"black\", angle=0, size=4)\n```\n</center>\n\nSo I can see I have an odd distribution, which I guess I would say it is left/negatively-skewed, as I have a long tail to the left, compared to that very high bin of values up to 10. Also, the mean is lower than the median, since there are a larger amount of values to the left of the plot, which pulls it away from the median. But, the majority of the cards I have drawn had a value of 10, so they were either a 10 from any of the 4 suites, or they were a face card.\n\nNow, I'll get samples for a new distribution by drawing three cards from the deck (*without* replacement) and then summing up the three cards' values into a single value. I then replace the drawn cards back into the deck and repeat this procedure 10,000 times, and then take a look at the distribution of the card sums.\n\n<center>![***Samples Sums Statistics***](summary.png)</center>\n\nSo I can see I have a mean and median that are quite close, and a standard deviation of just under 5. \n\nNow I must create a histogram of the sampled card sums.\n\n<center>\n```{r samples sums histogram, echo = FALSE}\n#plot 2nd histogram w/ mean and median\nggplot() + \n  aes(x=samples) + \n  geom_histogram(binwidth = 1, boundary = 1, color = 'white', aes(fill = ..count..)) +\n  guides(fill=FALSE) +\n  ylab('Frequency') + \n  xlab('Card Sums') +\n  ylim(0,1200) +\n  geom_vline(aes(xintercept=mean(samples)),\n             color=\"green\", size=1) + \n  geom_vline(aes(xintercept=median(samples)),\n             color=\"red\", size=1) +\n  geom_text(aes(x=mean(samples)-1, label=\"Mean\", y=1100), \n            colour=\"black\", angle=0, size=4) +\n  geom_text(aes(x=median(samples)+1.25, label=\"Median\", y=1100), \n            colour=\"black\", angle=0, size=4)\n\n```\n</center>\n\nI can see here that my distribution is now very normal-looking. But the mean is slightly pulled to the left of the median, showing that it is *slightly* left skewed, but looking at the histogram, it's safe to call this a normal distribution. \n\nCompared to our original distribution, this change to a more-normal distribution can be attributed to increasing the sample size from 1 to 3, because a larger sample size creates a larger Z-score for a sample mean, which in turn decreases the proportion of sample means that vary from the sample mean.\n\nWe know that 90% of our data values in this distribution are those values with a chance of being selected that is between 5% and 95%, which on a Z-table come out to be Z-score values between **-1.645** and **1.645**.\n\n<center>\n![***Negative Z-score***](negative_z.png)\n![***Positive Z-score***](positive_z.png)\n</center>\n\nSo, if the Z-score is equal to the difference between an observation and the mean divided by the standard deviation, to get those observations between which 90% of our data values fall, we need to multiply each of our Z-score values by the standard deviation and then add the mean.\n\nAnd if we do that, we'd have **(-1.645 x 4.89) + 19.59** as our lower value, and **(1.645 x 4.89) + 19.59** as our upper value. These formulas give us an lower boundary of\n```{r lower boundary, echo = FALSE}\n(-1.645*sd(samples)) + mean(samples)\n```\nand an upper boundary of\n```{r upper boundary, echo = FALSE}\n(1.645*sd(samples)) + mean(samples)\n```\n\nSo, 90% of sample sum values fall between **11.3938** and **27.7860**.\n\nTo find the approximate probability I would a draw value of at least 20 from this distribution, I would need to find the Z-score for a value of 20 in this distribution, then find the proportion value in the Z-table corresponding to that Z-score, and then subtract this proportion value from 1.\n\nSo, our Z-score would be **(20 - 19.59) / 4.89**, which gives a value of:\n```{r z, echo = FALSE}\n(20 - mean(samples)) / sd(samples)\n```\n\nThen I look at the Z-table for this score of **0.08** and retrieve that proportion.\n\n<center>![***Z-table for value of 20***](20_perc_z.png)</center>\n\nSo we've got a proportion of **0.5319**, which I subtract from 1 to get the approximate probability I would a draw value of at least 20. So this would be **1 - 0.5319 = 0.4681**, so I have a 46.81% chance of drawing a value of at least 20 from my distribution of sample means.",
    "created" : 1494372039702.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3691143001",
    "id" : "7FEFFAD6",
    "lastKnownWriteTime" : 1494376090,
    "last_content_update" : 1494376090635,
    "path" : "C:/Users/Nimz/Dropbox/DataScienceMasters/Stats/Udacity/DataAnalystNanoDegree/IntroToDescriptiveStats/Final/finalMarkdown.Rmd",
    "project_path" : "finalMarkdown.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}