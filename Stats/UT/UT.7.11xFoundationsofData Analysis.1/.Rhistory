setwd("C:/Users/snewns/Dropbox/RunningAnalysis/R_Backups")
setwd("C:/Users/snewns/Dropbox/RunningAnalysis")
setwd("C:/Users/snewns/Dropbox/RunningAnalysis")
setwd("C:/Users/snewns/Dropbox/RunningAnalysis")
library(devtools)
install_github("tiagomendesdantas/Rspotify")
install.packages("httr")
install.packages("jsonlite")
library("httr")
library("jsonlite")
install.packages("httr")
install.packages("jsonlite")
library("httr")
library("jsonlite")
?oauth_endpoint
?spotifyOAuth
keys <- spotifyOAuth("app_id","client_id","client_secret")
install_github("tiagomendesdantas/Rspotify")
library(Rspotify)
?spotifyOAuth
keys <- spotifyOAuth(app_id = R_Analysis,
client_id = ab0f8dd5358b49668d5da5c7b2368b43,
client_secret =56681b43de334d8a9a9a352222d5c02e)
keys <- spotifyOAuth(app_id = "R_Analysis",
client_id = "ab0f8dd5358b49668d5da5c7b2368b43",
client_secret =" 56681b43de334d8a9a9a352222d5c02e"")
keys <- spotifyOAuth(app_id = "R_Analysis",
client_id = "ab0f8dd5358b49668d5da5c7b2368b43",
client_secret ="56681b43de334d8a9a9a352222d5c02e")
spotifyEndPoint <- oauth_endpoint(request = NULL, "https://accounts.spotify.com/authorize",
"https://accounts.spotify.com/api/token")
?oauth_app
spotifyApp <- ?oauth_app("R_Analysis", spotifyKey, spotifySecret)
spotifyApp <- oauth_app("R_Analysis", spotifyKey, spotifySecret)
spotifyKey <- "ab0f8dd5358b49668d5da5c7b2368b43"
spotifySecret <- "56681b43de334d8a9a9a352222d5c02e"
spotifyApp <- oauth_app("R_Analysis", spotifyKey, spotifySecret)
spotifyToken <- oauth2.0_token(spotifyEndpoint, spotifyApp)
spotifyToken <- oauth2.0_token(spotifyEndPoint, spotifyApp)
spotifyEndPoint <- oauth_endpoint(NULL,
"https://accounts.spotify.com/authorize",
"https://accounts.spotify.com/api/token")
spotifyEndPoint
spotifyKey
spotifySecret
spotifyKey <- ab0f8dd5358b49668d5da5c7b2368b43
spotifySecret <- 56681b43de334d8a9a9a352222d5c02e
spotifyKey <- ab0f8dd5358b49668d5da5c7b2368b43
spotifyKey <- "ab0f8dd5358b49668d5da5c7b2368b43"
spotifySecret <- "56681b43de334d8a9a9a352222d5c02e"
spotifyKey <- "ab0f8dd5358b49668d5da5c7b2368b43"
spotifySecret
spotifyKey
spotifySecret
spotifyApp
spotifyApp <- oauth_app("R_Analysis", spotifyKey, spotifySecret)
spotifyToken <- oauth2.0_token(spotifyEndPoint, spotifyApp)
spotifyEndPoint <- oauth_endpoint(NULL,
"https://accounts.spotify.com/authorize",
"https://accounts.spotify.com/api/token")
spotifyKey <- "ab0f8dd5358b49668d5da5c7b2368b43"
spotifySecret <- "56681b43de334d8a9a9a352222d5c02e"
spotifyApp <- oauth_app("R_Analysis", spotifyKey, spotifySecret)
spotifyToken <- oauth2.0_token(spotifyEndPoint, spotifyApp)
spotifyApp <- oauth_app("R_Analysis", spotifyKey, spotifySecret)
spotifyToken <- oauth2.0_token(spotifyEndPoint, spotifyApp)
?oauth2.0_token
spotifyToken <- ?oauth2.0_token(spotifyEndPoint, spotifyApp)
(150*617)+(16*238)
source('C:/Users/snewns/Dropbox/NewLearn/Edx/AnalyticsEdge/Unit8_LinearOptimization/8_1_AirlineRevenueMgmt.R')
$96,358 - $86,883
96358 - 86883
one of 0.20 (0.08 means there is an 8% chance a user who searches for best LTE network will click on the ad for AT&T if it
0.2*25
budget has dropps from 100 to 4, and the remaining displays of Query 3 has dropped to 0. So there are no more displays of Query 3 remaining that we can use.
So, our decisions are which teams should play each other each week and we model this with binary decision variables. The first constraint is that each team
15*7
(1030+92)/(1030+92+126+227)
Mount Sinai Hospital in Toronto uses integer optimization to schedule their ORs. Hospitals have a limited number of operating rooms,
of what they wanted. We want to maximize this percentage value *for every department*, so that is why we sum over all departments
weekly department OR requirements. Our last set of constraints has to do with departmental targets. We want to make sure we don't give any department more
Our objective value would be a max profitability of 269.9246814, more than 5X that of the greedy approach, with 7 hotels are selected in the solution?
I22x1,22 ≤ 1.2** to say the index of SR 1 at brick 1 plus the index of SR at brick 2 etc. We should have a similar constraint in our model for every SR (1 - 4).
administrative staff could adjust the constraints depending on the importance of the teacher preferences versus parent preferences.
set.seed(200)
kmc <- kmeans(housesNorm, centers = 10, iter.max = 1000)
Pt. 2 - UNDERSTANDING RETAIL CONSUMERS
**Clustering** can be used for **market segmentation**, the idea of dividing airline passengers into small, more similar
groups, and then designing a marketing strategy specifically for each group. We will see how this idea can be applied to
retail consumer data with data collected over 2 years from source files provided by dunnhumby, a customer science company
based in the UK, for a group of 2.5K households. Each row represents a unique household with the following variables:
* NumVisits       = the number of times the household visited the retailer
* AvgProdCount    = the average number of products purchased per transaction
* AvgDiscount     = the average discount per transaction from coupon usage (in %) - NOTE: Do not divide by 100!
* AvgSalesValue   = the average sales value per transaction
* MorningPct      = the percentage of visits in the morning (8am - 1:59pm)
* AfternoonPct    = the percentage of visits in the afternoon (2pm - 7:59pm)
Note that some visits can occur outside of morning and afternoon hours (visits from 8pm - 7:59am are possible)'
houses <- read.csv("Households.csv")
head(houses)
nrow(subset(houses, houses$MorningPct == 100))
nrow(subset(houses, houses$AfternoonPct == 100))
'4 households have logged transactions at the retailer only in the morning and 13 households have logged transactions at
the retailer only in the afternoon.
Of households that spend over $150 per transaction on average, the minimum average discount per transaction is 15.64%'
min(houses$AvgDiscount[houses$AvgSalesValue > 150])
'Of households who have an average discount per transaction greater than 25%, the minimum average sales value per
transaction is 50.1175'
min(houses$AvgSalesValue[houses$AvgDiscount > 25])
'In the dataset, a proportion of 0.0592 or 5.92% of households visited the retailer at least 300 times'
nrow(subset(houses, houses$NumVisits >= 300))/nrow(houses)
'When clustering data, it is often important to normalize the variables so that they are all on the same scale. If you
clustered this dataset without normalizing, we would expect to NumVisits dominate in the distance calculations, because
it is on the largest scale.
Normalize all variables'
library(caret)
preproc = preProcess(houses)
housesNorm = predict(preproc, houses)
'Remember that for each variable, the normalization process subtracts the mean and divides by the standard deviation. So,
in this normalized dataset, all variables should have mean = 0 and standard deviation = 1.
The maximum value of NumVisits in the normalized dataset is 10.28281 and the the minimum value of AfternoonPct in the
normalized dataset is -3.228427.
Create a dendrogram of the normalized data'
set.seed(200)
distances <- dist(housesNorm, method = "euclidean")
ClusterShoppers <- hclust(distances, method = "ward.D")
plot(ClusterShoppers, labels = FALSE)
'Based on the dendrogram, 2, 3, or 5 clusters would be appropriate for this problem. 4 or 6 clusters have very little
"wiggle room", which means the additional clusters are not very distinct from existing clusters. That is, when moving
from 3 clusters to 4 clusters, the additional cluster is *very similar to an existing one* (as well as when moving from 5
clusters to 6 clusters).
Run the k-means clustering algorithm on the normalized dataset, selecting 10 clusters. Right before using kmeans(), set
the seed to 200 again.'
set.seed(200)
kmc <- kmeans(housesNorm, centers = 10, iter.max = 1000)
kmc
str(kmc)
table(kmc$cluster)
order(table(kmc$cluster))
sort(table(kmc$cluster))
healthyClusters <- kmc$cluster
healthyClusters
kmc
str(kmc)
cluster1 <- subset(housesNorm, kmc == 1)
cluster1 <- subset(housesNorm, kmc$cluster == 1)
cluster1 <- subset(housesNorm, kmc$cluster == 1)
cluster2 <- subset(housesNorm, kmc$cluster == 2)
cluster3 <- subset(housesNorm, kmc$cluster == 3)
cluster4 <- subset(housesNorm, kmc$cluster == 4)
cluster5 <- subset(housesNorm, kmc$cluster == 5)
cluster6 <- subset(housesNorm, kmc$cluster == 6)
cluster7 <- subset(housesNorm, kmc$cluster == 7)
cluster8 <- subset(housesNorm, kmc$cluster == 8)
cluster9 <- subset(housesNorm, kmc$cluster == 9)
cluster10 <- subset(housesNorm, kmc$cluster == 10)
cluster1
tail(sort(colMeans(cluster2)))
head(cluster1)
head(cluster1)Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
head(cluster1)
cluster2
head(cluster2)
head(cluster3)
head(cluster4)
head(cluster5)
head(cluster6)
head(cluster7)
head(cluster4) #
head(cluster7)
head(cluster8)
head(cluster9)
head(cluster10)
head(cluster4) #
head(cluster7) #
kmc
str(kmc)
head(kmc)
head(kmc) #check 'centers'
head(kmc) #check 'centers'
set.seed(5000)
kmc <- kmeans(housesNorm, centers = 5, iter.max = 1000)
sort(table(kmc$cluster))
str(kmc)
head(kmc)
rm(list = ls(all = TRUE))
energy <- read.csv("energy.csv")
energy <- read.csv("energy.csv")
table(energy$STATE,energy$GenTotalRenewable)
sort(table(energy$STATE,energy$GenTotalRenewable))
order(table(energy$STATE,energy$GenTotalRenewable))
sort(table(energy$GenTotalRenewable,energy$STATE))
table(energy$GenTotalRenewable,energy$STATE)
table(energy$STATE,energy$GenTotalRenewable)
summary(energy$STATE,energy$GenTotalRenewable)
summary(energy$GenTotalRenewable)
table(energy$STATE,mean(energy$GenTotalRenewable))
table(energy$STATE,mean(energy$GenTotalRenewable)
energy[energy$STATE == 'AZ',]
energy[energy$STATE == 'AZ',]
sum(energy$GenTotalRenewable[energy$STATE == 'AZ'])
sum(energy$GenTotalRenewable[energy$STATE == 'CA'])
sum(energy$GenTotalRenewable[energy$STATE == 'ID'])
sum(energy$GenTotalRenewable[energy$STATE == 'MA'])
max(energy$GenTotalRenewable[energy$STATE == 'AZ'])
max(energy$GenTotalRenewable[energy$STATE == 'CA'])
max(energy$GenTotalRenewable[energy$STATE == 'ID'])
max(energy$GenTotalRenewable[energy$STATE == 'MA'])
tapply(energy$GenTotalRenewable,energy$STATE, max)
sort(tapply(energy$GenTotalRenewable,energy$STATE, max))
which.max(energy$GenTotalRenewable[energy$STATE == 'ID'])
energy[which.max(energy$GenTotalRenewable[energy$STATE == 'ID'])]
energy[which.max(energy$GenTotalRenewable[energy$STATE == 'ID']),]
energy$GenTotalRenewable[energy$STATE == 'ID']
which.max(energy$GenTotalRenewable[energy$STATE == 'ID']
)
idaho <- subset(energy, energy$STATE == 'ID')
idaho
energy[which.max(idaho$GenTotalRenewable,]
energy[which.max(idaho$GenTotalRenewable)
]
idaho$GenTotalRenewable
which.max(idaho$GenTotalRenewable)
idaho[which.max(idaho$GenTotalRenewable)]
idaho[which.max(idaho$GenTotalRenewable),]
energy$AllSourcesCO2[energy$presidential.results == 0]
mean(energy$AllSourcesCO2[energy$presidential.results == 0])
mean(energy$AllSourcesCO2[energy$presidential.results == 0], na.rm = TRUE)
mean(energy$AllSourcesCO2[energy$presidential.results == 1], na.rm = TRUE)
mean(energy$AllSourcesNOx[energy$presidential.results == 0], na.rm = TRUE)
mean(energy$AllSourcesNOx[energy$presidential.results == 1], na.rm = TRUE)
cor(energy$AllSourcesCO2,energy$EPriceIndustrial, use="complete") #use = 'complete' handles NA's
cor(energy$EPriceIndustrial,energy$AllSourcesCO2, use="complete") #use = 'complete' handles NA's
cor(energy$EsalesIndustrial ,energy$AllSourcesCO2, use="complete") #use = 'complete' handles NA's
cor(energy$EsalesIndustrial, energy$AllSourcesCO2, use="complete") #use = 'complete' handles NA's
cor(energy$EsalesIndustrial, energy$AllSourcesSO2, use="complete") #use = 'complete' handles NA's
cor(energy$EsalesIndustrial, energy$AllSourcesNOx, use="complete") #use = 'complete' handles NA's
cor(energy$EsalesIndustrial, energy$AllSourcesSO2, use="complete") #use = 'complete' handles NA's
cor(energy$EsalesResidential, energy$AllSourcesNOx, use="complete") #use = 'complete' handles NA's
cor(energy$EsalesCommercial, energy$AllSourcesCO2, use="complete") #use = 'complete' handles NA's
library(ggplot2)
library(ggplot2)
ggplot(data = energy, aes(x = State, y = EPriceTotal)) + geom_boxplot()
ggplot(data = energy, aes(x = STATE, y = EPriceTotal)) + geom_boxplot()
tapply(energy$EPriceTotal, energy$STATE, mean)
ggplot(data = energy, aes(x = STATE, y = EPriceTotal)) + geom_boxplot() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(data = energy, aes(x = STATE, y = EPriceTotal)) + geom_boxplot() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
tapply(energy$EPriceTotal, energy$STATE, mean)
sort(tapply(energy$EPriceTotal, energy$STATE, mean))
cor(energy$STATE[energy$STATE == 'WY'],max(mean(energy$GenTotal)))
set.seed(144)
spl = sample(1:nrow(energy), size = 0.7*nrow(energy))
train = energy[spl,]
test = energy[-spl,]
model1 <- glm(GenSolarBinary ~ GenHydro + GenSolar + CumlFinancial + CumlRegulatory + Total.salary + Import,
data = train, family = "binomial")
summary(model1)
logModelPredictions <- predict(model1, test, type = "response")
table(test$GenSolarBinary, logModelPredictions > 0.5)
154+18/nrow(test)
(154+18)/nrow(test) #accuracy of
table(test$GenSolarBinary[test$presidential.results == 0], logModelPredictions > 0.5)
republicanLogModelPredictions <- predict(model1, test[test$presidential.results == 0], type = "response")
republicanLogModelPredictions <- predict(model1, test[test$presidential.results == 0,], type = "response")
table(test$GenSolarBinary[test$presidential.results == 0], republicanLogModelPredictions > 0.5)
democratLogModelPredictions <- predict(model1, test[test$presidential.results == 1,], type = "response")
table(test$GenSolarBinary[test$presidential.results == 0], democratLogModelPredictions > 0.5)
democratLogModelPredictions <- predict(model1, test[test$presidential.results == 1,], type = "response")
table(test$GenSolarBinary[test$presidential.results == 1], democratLogModelPredictions > 0.5)
(90+2)/nrow(test[test$presidential.results == 0])
(90+2)/nrow(test[test$presidential.results == 0,])
table(test$GenSolarBinary[test$presidential.results == 1], democratLogModelPredictions > 0.5)
(64+16)/nrow(test[test$presidential.results == 1,])
train.limited <- train[,c('CumlRegulatory','CumlFinancial','presidential.results','Total.salary','Import')]
test.limited <- test[,c('CumlRegulatory','CumlFinancial','presidential.results','Total.salary','Import')]
library(caret)
preProcess(train.limited)
library(caret)
reproc = preProcess(train.limited)
train.limited.norm = predict(preproc, train.limited)
library(caret)
preproc = preProcess(train.limited)
train.limited.norm = predict(preproc, train.limited)
preproc2 = preProcess(test.limited)
test.limited.norm = predict(preproc2, test.limited)
set.seed(144)
kmc.train.norm <- kmeans(train.limited, centers = 2, iter.max = 1000)
str(kmc.train.norm)
head(kmc.train.norm)
install.packages("flexclust")
library(flexclust)
?flexclust
?as.kcca
kmc.train.norm.kcaa <- as.kcca(kmc.train.norm, train.limited.norm)
cluster.train.norm <- predict(kmc.train.norm.kcaa)
cluster.train.norm
str(kmc.train.norm)
head(kmc.train.norm)
train.cluster1 <- subset(train.limited.norm, kmc.train.norm$cluster == 1)
train.cluster2 <- subset(train.limited.norm, kmc.train.norm$cluster == 2)
summary(train.cluster1)
summary(train.cluster2)
train.limited.norm
train.cluster1 <- subset(train, kmc.train.norm$cluster == 1)
train.cluster2 <- subset(train, kmc.train.norm$cluster == 2)
summary(train.cluster1)
summary(train.cluster2)
cluster.train.norm
model2 <- glm(GenSolarBinary ~ GenHydro + GenSolar + CumlFinancial + CumlRegulatory + Total.salary + Import,
data = train.cluster1, family = "binomial")
summary(model2)
test.cluster1 <- subset(test, kmc.train.norm$cluster == 1)
test.cluster2 <- subset(test, kmc.train.norm$cluster == 2)
logModelPredictions2 <- predict(model2, test, type = "response")
table(test.cluster1$GenSolarBinary, logModelPredictions2 > 0.5)
test.cluster1
logModelPredictions2
logModelPredictions2 <- predict(model2, test.cluster1, type = "response")
table(test.cluster1$GenSolarBinary, logModelPredictions2 > 0.5)
(126+25)/nrow(test.cluster1)
logModelPredictions2 <- predict(model2, test.limited.norm, type = "response")
table(test.limited.norm$GenSolarBinary, logModelPredictions2 > 0.5)
?cluster.test
logModelPredictions2 <- predict(model2, test.limited.norm, type = "response")
table(test.limited.norm$GenSolarBinary, logModelPredictions2 > 0.5)
logModelPredictions2 <- predict(model2, test.cluster1, type = "response")
table(test.cluster1$GenSolarBinary, logModelPredictions2 > 0.5)
(126+25)/nrow(test.cluster1)
test.cluster1
nrow(test.cluster1)
(126+25)/nrow(test.cluster1)
logModelPredictions2 <- predict(model2, test.cluster1, type = "response")
table(test.cluster1$GenSolarBinary, logModelPredictions2 > 0.5)
(126+13)(126+13+18+25)
(126+13)/(126+13+18+25)
kmc.train.norm.kcaa <- as.kcca(kmc.train.norm, train.limited.norm)
cluster.train.norm <- predict(kmc.train.norm.kcaa)
kmc.train.norm.kcaa <- as.kcca(kmc.train.norm, train.limited.norm)
cluster.train.norm <- predict(kmc.train.norm.kcaa)
kcm.test.norm.kcaa <- as.kcca(kmc.train.norm, test.limited.norm)
cluster.test.norm <- predict(kcm.test.norm.kcaa)
cluster.test.norm
kcm.test.norm.kcaa
train.cluster1 <- subset(train, kmc.train.norm$cluster == 1)
train.cluster2 <- subset(train, kmc.train.norm$cluster == 2)
test.cluster1 <- subset(test, kcm.test.norm.kcaa$cluster == 1)
test.cluster2 <- subset(test, kcm.test.norm.kcaa$cluster == 2)
kcm.test.norm.kcaa
kmc.train.norm.kcaa
kmc.train.norm.kcaa <- as.kcca(kmc.train.norm, train.limited.norm)
train.cluster1 <- subset(train, kmc.train.norm$cluster == 1)
kcm.test.norm.kcaa <- as.kcca(kmc.train.norm, test.limited.norm)
test.cluster1 <- subset(test, kcm.test.norm.kcaa$cluster == 1)
test.cluster2 <- subset(test, kcm.test.norm.kcaa$cluster == 2)
as.kcca
?as.kcca
set.seed(144)
kmc.test.norm <- kmeans(test.limited, centers = 2, iter.max = 1000)
str(kmc.test.norm)
head(kmc.test.norm)
kmc.train.norm.kcaa <- ?as.kcca(kmc.train.norm, train.limited.norm)
cluster.train.norm <- predict(kmc.train.norm.kcaa)
kcm.test.norm.kcaa <- as.kcca(kmc.train.norm, test.limited.norm)
cluster.test.norm <- predict(kcm.test.norm.kcaa)
train.cluster1 <- subset(train, kmc.train.norm$cluster == 1)
train.cluster2 <- subset(train, kmc.train.norm$cluster == 2)
test.cluster1 <- subset(test, kcm.test.norm.kcaa$cluster == 1)
test.cluster2 <- subset(test, kcm.test.norm.kcaa$cluster == 2)
kmc.test.norm
str(kmc.test.norm)
head(kmc.test.norm)
kcm.test.norm.kcaa <- as.kcca(kmc.test.norm, test.limited.norm)
cluster.test.norm <- predict(kcm.test.norm.kcaa)
train.cluster1 <- subset(train, kmc.train.norm$cluster == 1)
train.cluster2 <- subset(train, kmc.train.norm$cluster == 2)
test.cluster1 <- subset(test, kcm.test.norm.kcaa$cluster == 1)
test.cluster2 <- subset(test, kcm.test.norm.kcaa$cluster == 2)
test.cluster1 <- subset(test, kcm.test.norm$cluster == 1)
test.cluster2 <- subset(test, kcm.test.norm$cluster == 2)
head(kmc.test.norm)
train.cluster1 <- subset(train, kmc.train.norm$cluster == 1)
train.cluster2 <- subset(train, kmc.train.norm$cluster == 2)
test.cluster1 <- subset(test, kmc.test.norm$cluster == 1)
test.cluster2 <- subset(test, kmc.test.norm$cluster == 2)
logModelPredictions2 <- predict(model2, test.cluster1, type = "response")
table(test.cluster1$GenSolarBinary, logModelPredictions2 > 0.5)
2+22/nrow(test.cluster1)
(40*20) + (40*4) + (35*32) + (35*0)
library(SDSFoundations)
animaldata <- AnimalData
install.packages("C:/Users/snewns/Dropbox/DataScienceMasters/Stats/UT/SDSFoundations_1.1.zip", repos = NULL, type = "win.binary")
library(SDSFoundations)
animaldata <- AnimalData
table(animaldata$Age.Intake)
str(animaldata)
table(animaldata$Age.Intake)
adultAnimals <- subset(animaldata, Age.Intake >= 1)
adultAnimals
table(adultAnimals$Age.Intake)
table(adultAnimals$Animal.Type)
adultDogs <- subset(adultDogs, Animal.Type == 'Dog')
adultDogs <- subset(adultAnimals, Animal.Type == 'Dog')
adultCats <- subset(adultAnimals, Animal.Type == 'Cat')
ggplot(adultAnimals) + geom_histogram(aes(x = adultDogs))
ggplot(adultDogs) + geom_histogram(aes(x = Weight))
library(ggplot2)
ggplot(adultDogs) + geom_histogram(aes(x = Weight))
ggplot(adultCats) + geom_histogram(aes(x = Weight))
mean(adultCats$Weight)
sd(adultCats$Weight)
(13 - 8.6)/1.9
mean(adultAnimals$Weight)
sd(adultAnimals$Weight)
(13 - 30.29539) / 23.6356
zScore.cat <- 2.3
1-pnorm(zScore.cat)
fivenum(adultDogs$Weight)
fivenum(adultCats$Weight)
mean(adultDogs$Weight)
sd(adultDogs$Weight)
(13 - 35.67) / 23.47
zScore.dog <- -0.97
1-pnorm(zScore.dog)
(4.5 - 6.7) / 1.1
(5.38 - 6.7) / 1.1
(8.79 - 6.7) / 1.1
minutesStudying <- c(30,45,180,95,130,140,30,80,60,110,0,80)
grade <- c(74,68,87,90,94,84,92,88,82,93,65,90)
cbind(minutesStudying,grade)
df <- data.frame(cbind(minutesStudying,grade))
df
cor(df$minutesStudying,df$grade)
1 - (0.597**2)
library(ggplot2)
ggplot(df) + geom_point(aes(x = minutesStudying, y = grade))
new.df <- df[!df$grade == 92]
new.df <- df[!df$grade == 92,]
new.df
cor(new.df$minutesStudying,new.df$grade) #0.5967026 = 0.597
0.597**2
(0.597**2)
setwd('C:/Users/Nimz/Dropbox/DataScienceMasters/Stats/UT/UT.7.11xFoundationsofData Analysis.1')
library(SDSFoundations)
acl <- read.csv("AustinCityLimits.csv"
)
acl
males <- subset(acl, Gender == 'M')
'Lab 4: Austin City Limits
Known as the “Live Music Capital of the World,” Austin, TX is also home to the longest-running music series in American television
history, Austin City Limits. This dataset includes data on a sample of musicians that performed live on the PBS television series Austin
City Limits over the last 10 years. Data on each artist include measures of commercial popularity, such as the number of social media
followers on Twitter or Facebook, and their success in winning a Grammy Music Award. '
setwd('C:/Users/snewns/Dropbox/DataScienceMasters/Stats/UT/UT.7.11xFoundationsofData Analysis.1')
setwd('C:/Users/Nimz/Dropbox/DataScienceMasters/Stats/UT/UT.7.11xFoundationsofData Analysis.1')
library(SDSFoundations)
acl <- read.csv("AustinCityLimits.csv")
#The probability an event will occur, given that a *different* event has also occurred, is known as a conditional probability
#for 2 events, A and B, to be considered independent: P(A)=P(A|B)
'**Primary Research Question** - Among male artists, is there an association between winning a Grammy and the genre of music played?
. Subset the data (males only).'
males <- subset(acl, Gender == 'M')
2. Create a table to show the marginal distributions for Genre and Grammy.
3. Create a contingency table to show the conditional distribution for Genre and Grammy.
4. Make a bar chart to better visualize how many artists in each Genre received a Grammy.
5. Calculate P(A):  the probability of winning a Grammy.
6. Calculate P(A|B): the probability of winning Grammy, given the artist's Genre.
7. Interpret what these probabilities tell us about the relationship between Genre and winning a Grammy.
males
genre <- table(males$Genre)
grammy  <- table(males$Grammy)
table(males$Genre,males$Grammy)
table(males$Grammy,males$Genre)
cont.tbl <- table(males$Grammy,males$Genre)
barplot(cont.tbl, legend = T, beside = T)
prop.table(grammy
)
prop.table(cont.tbl)
prop.table(cont.tbl,1)
prop.table(cont.tbl,2)
prop.table(cont.tbl,1)
grammy
males
grammy
cont.tbl
prop.table
prop.table(grammy)
cont.tbl
prop.table(grammy)
cont.tbl
prop.table(cont.tbl,1)
prop.table(cont.tbl,2)
grammy
prop.table(grammy)
setwd('C:/Users/Nimz/Dropbox/DataScienceMasters/Stats/UT/UT.7.11xFoundationsofData Analysis.1')
library(SDSFoundations)
acl <- read.csv("AustinCityLimits.csv")
table(acl$Facebook.100k)
table(acl$Age,acl$Facebook.100k)
table(acl$Age.Group,acl$Facebook.100k)
table(acl$Facebook.100k,acl$Age.Group)
table(acl$Facebook.100k)
table(acl$Facebook.100k,acl$Age.Group)
prop.table(table(acl$Facebook.100k,acl$Age.Group))
prop.table(table(acl$Facebook.100k,acl$Age.Group),1)
prop.table(table(acl$Facebook.100k,acl$Age.Group),2)
0.15/0.65
0.15/0.65
0.15/(1-0.35)
0.15/(0.35)
