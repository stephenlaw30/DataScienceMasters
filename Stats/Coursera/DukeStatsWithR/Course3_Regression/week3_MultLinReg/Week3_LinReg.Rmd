---
title: "Wk3 - Mult. Linear Reg."
author: "Steve Newns"
output: html_document
---

Predict book weight by vol + cover type
```{r}
library(DAAG)
library(tidyverse)
library(ggplot2)
data(allbacks)

model1 <- lm(weight ~ volume + cover, data = allbacks)
summary(model1)
```

Note only 1 level of `cover` is in the output = the **NON-reference level** --> hardcover books must be the **reference level**

Multiple R2 = 92.75% --> 92.75% of variability of book weights is explained by volume + cover type

\[
  \hat{y} = 197.96284 + 0.71795 \times volume - 184.04727 \times cover
\]

Remember PB =  non-reference level, meaning HC books = reference level 
<ul>
<li> For reference levels, always plug in 0 in our linear model. </li>
<li> To simplify this linear model to see what it'd look like only for HC books, plug in a 0 for cover. </li>
<li> For a PB, plug in 1 for cover. </li>
</ul>

```{r}
reference_model <- function(x1) {
  197.96284 + .71795*x1
} 

non_reference_model <- function(x1) {
  197.96284 + .71795*x1 - 184.04727
} 

# Predict weight of a PB book 600 cm^3 in volume. 
non_reference_model(600)
```

# Mult. Lin. Reg

```{r, message=F,warning=F}
states <- read_csv("states.csv")

model1 <- lm(poverty ~ female_house, data = states)
summary(model1)

ggplot(data = states, aes(x = female_house, y = poverty)) +
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)

anova(model1)
```
```{r}
model2 <- lm(poverty ~ female_house + white, data = states)
summary(model2)
anova(model2)
```

## Calculate Adj R2

```{r}
sse <- 339.74
sst <- sum(132.57,8.21,339.47)
n <- 51
k <- 2

(adjR2 <- 1 - ((sse/sst)*((n-1)/(n-k-1))))
```

# Inference for MLR

```{r}
cognitive <- read_csv("http://bit.ly/dasi_cognitive")
head(cognitive)

# full model
model1 <- lm(kid_score ~ ., data = cognitive)
summary(model1)
```

## t-score for mom_hsyes

```{r}
pt.estimate <- 5.09482 # slope of var
null <- 0
se <- 2.31450 # SE of var
n <- nrow(cognitive)
k <- ncol(cognitive) - 1
dF <- n - k - 1
(t <- (pt.estimate - null)/se)
```

This the same as in the regression output.

## check p-value for mom_hsyes
```{r}
pt(t, dF, lower.tail = F)*2
```

## calculate 95% CI for mom_work
```{r}
alpha = .95
(t.crit <- abs(qt(p = (1 - alpha)/2, df = dF)))

pt.estimate.work <- 2.53718
se.work <- 2.35067

(mOe <- t.crit*se.work)
(lower <- pt.estimate.work - mOe)
(upper <- pt.estimate.work + mOe)
```

# Diagnostics for MLR

```{r}
# linearity w/ residuals plot
cog_final <- lm(kid_score ~ mom_hs + mom_iq + mom_work, data = cognitive)
plot(cognitive$mom_iq, cog_final$residuals)
abline(0,0)

# normal residuals
hist(cog_final$residuals)
qqnorm(cog_final$residuals)
qqline(cog_final$residuals)

# constant variability of residuals
plot.new()
plot(cog_final$fitted.values, cog_final$residuals)
abline(0,0)
plot(cog_final$fitted.values, abs(cog_final$residuals))

# independence of residuals (+ therfore observations)
plot(cog_final$residuals)
abline(0,0)
```

