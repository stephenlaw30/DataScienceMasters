{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#see documentation in new window-type thing in bottom of browser window\n",
    "pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series** = cross between list + dictionary\n",
    "\n",
    "* items are stored in order = **values**\n",
    "* can retrieve items w/ labels = **index**\n",
    "\n",
    "When passing in list of values to .Series(), pandas creates a Series starting at index 0 and so on for each list element + sets the name of the Series to \"None\"\n",
    "\n",
    "Underneath the hood, panda stores Series values in a typed array using the numpy --> offers significant speed-up when\n",
    "processing data vs. traditional Python lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2    Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list\n",
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "\n",
    "#conver the list to Series to see their indices\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can pass in numbers type\n",
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For missing data in Python, we have the None type to indicate a lack of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2     None\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can pass in None type\n",
    "animals = ['Tiger', 'Bear', None]\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underneath, Pandas does some type conversion here --> Pandas inserts None type element it as a None + uses the type \"Object\" for the underlying array. \n",
    "\n",
    "If we create a list of *numbers, integers, or floats* + put in a None type, Pandas automatically converts this to a\n",
    "special floating point value, **NaN** = not a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1, 2, None]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NaN is not None*** \n",
    "\n",
    "* can't do an equality test of NaN to itself.\n",
    "* Need to use special functions to test for the presence of NaN, isnan(). \n",
    "* Keep in mind when you see NaN, it's meaning is similar to None, but it's a *numeric* value + is treated differently for efficiency reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.nan == None\n",
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we have labeled data we want to manipulate\n",
    "\n",
    "A series can be created from dictionary data --> index is automatically assigned to the keys of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create this series, see that, since it was string data, Pandas set the data type of the series to Object, the list of the countries as the value of the series, + the index values to the dictionary keys\n",
    "\n",
    "Once the series has been created, we can get the index object using the **.index** attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Archery', 'Golf', 'Sumo', 'Taekwondo'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also separate your index creation from the data by passing in the index as a list *explicitly to the series* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India      Tiger\n",
       "America     Bear\n",
       "Canada     Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Tiger', 'Bear', 'Moose'], index=['India', 'America', 'Canada'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a  list of values in the index object are not aligned w/ the keys in a dictionary, Pandas overrides the automatic\n",
    "creation to favor only and all of the indices values provided\n",
    "\n",
    "It will ignore all dictionary keys which are not in your index argument + will add None or NaN values for any index value in the provided index that aren't keys in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Golf      Scotland\n",
       "Sumo         Japan\n",
       "Hockey         NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports, index=['Golf', 'Sumo', 'Hockey'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Querying a Series </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Series can be queried by index position or index label (position + label are effectively the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "\n",
    "# get the value from the 4th item (index 3) w/ .iloc() attribute\n",
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scotland'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the same w/ named index w/ .loc() attribute\n",
    "s.loc['Golf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't need .iloc attribute\n",
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scotland'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't need .loc attribute\n",
    "s['Golf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bhutan'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0] #This won't call s.iloc[0] as one might expect, it generates an error instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't use parentheses to query, but square brackets --> the **indexing operator.**\n",
    "\n",
    "If you pass in an integer parameter, the operator will behave as if you want it to query via iloc attribute. If you pass in an object, it will query as if you wanted to use label-based loc attribute\n",
    "\n",
    "If index = a list of integers, Pandas can't determine automatically whether you're intending to query by position or label. \n",
    "\n",
    "Safer option is to be more explicit + use iloc or loc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-89412c118fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           102: 'South Korea'}\n\u001b[1;32m      5\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msports\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#This won't call s.iloc[0] as one might expect, it generates an error instead\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\NEWNSS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\NEWNSS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2426\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2428\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2429\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4363)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4046)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13913)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13857)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "sports = {99: 'Bhutan',\n",
    "          100: 'Scotland',\n",
    "          101: 'Japan',\n",
    "          102: 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s[0] #This won't call s.iloc[0] as one might expect, it generates an error instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324.0\n"
     ]
    }
   ],
   "source": [
    "# sum up Series elements via loop\n",
    "s = pd.Series([100.00, 120.00, 101.00, 3.00])\n",
    "total = 0\n",
    "for item in s:\n",
    "    total+=item\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324.0\n"
     ]
    }
   ],
   "source": [
    "# do so w/ numpy\n",
    "import numpy as np\n",
    "\n",
    "total = np.sum(s)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop works, but is slow.\n",
    "\n",
    "Modern CPUs can do many tasks simultaneously, especially, but not only, tasks involving mathematics. \n",
    "\n",
    "Pandas + its underlying NumPy libraries support a method of computation called **vectorization** which works with most offunctions in NumPy,\n",
    "\n",
    "Both methods above create the same value, but is one actually faster? \n",
    "\n",
    "Jupyter Notebook has a function to help see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    203\n",
       "1    574\n",
       "2    869\n",
       "3    990\n",
       "4    662\n",
       "dtype: int32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a large series of random numbers\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "summary = 0\n",
    "for item in s:\n",
    "    summary+=item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 111 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "summary = np.sum(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used a **cellular magic function** --> start w/ 2 %'s + modify/**wrap** code in the current Jupyter cell. \n",
    "\n",
    "Function we use = **timeit** --> runs code a few times to determine, on average, how long it takes. \n",
    "\n",
    "Vectorization gives a shocking difference in the speed + demonstrates why data scientists need to be aware of parallel computing features + start thinking in functional programming terms. \n",
    "\n",
    "A related feature in Pandas + NumPy is called **broadcasting** = apply an operation to every value in a Series, changing the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    572\n",
       "1    423\n",
       "2    508\n",
       "3    234\n",
       "4    805\n",
       "dtype: int32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 2 to each item in s using broadcasting\n",
    "s += 2 \n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedural way of doing this would be to iterate through all items in the series + increase the values directly. \n",
    "\n",
    "* Pandas does support iterating through a series much like a dictionary, allowing you to unpack values easily. \n",
    "* But if you find yourself iterating through a series, question whether you're doing things in the best possible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 774 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label]= value + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 479 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "\n",
    "s += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only is broadcasting significantly faster, but more concise and maybe even easier to read. \n",
    "\n",
    "The typical mathematical operations you would expect are vectorized, + NumPy documentation outlines what it takes to create vectorized functions of your own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 1 last note on using the indexing operators to access series data:</h4>\n",
    "\n",
    ".loc attribute lets you not only modify data **in place**, but also **add** new data as well. \n",
    "\n",
    "If a value you pass in as the index doesn't exist, a new entry is added\n",
    "\n",
    "Also keep in mind that indices can have mixed types. \n",
    "\n",
    "* While it's important to be aware of the type underneath, Pandas will automatically change underlying NumPy types as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             1\n",
       "1             2\n",
       "2             3\n",
       "Animal    Bears\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add string index + value to numeric Series + see type swich to Object\n",
    "s = pd.Series([1, 2, 3])\n",
    "s.loc['Animal'] = 'Bears'\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed types for data values or index labels are no problem for Pandas\n",
    "\n",
    "Can also have index values that are NOT unique, + this makes data frames different, conceptually, to an RDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a series\n",
    "original_sports = pd.Series({'Archery': 'Bhutan',\n",
    "                             'Golf': 'Scotland',\n",
    "                             'Sumo': 'Japan',\n",
    "                             'Taekwondo': 'South Korea'})\n",
    "# create a new series\n",
    "cricket_loving_countries = pd.Series(['Australia', 'Barbados','Pakistan','England'], \n",
    "                                   index=['Cricket','Cricket','Cricket','Cricket'])\n",
    "\n",
    "# concatenate Series\n",
    "all_countries = original_sports.append(cricket_loving_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archery           Bhutan\n",
      "Golf            Scotland\n",
      "Sumo               Japan\n",
      "Taekwondo    South Korea\n",
      "dtype: object \n",
      "\n",
      " Cricket    Australia\n",
      "Cricket     Barbados\n",
      "Cricket     Pakistan\n",
      "Cricket      England\n",
      "dtype: object \n",
      "\n",
      " Archery           Bhutan\n",
      "Golf            Scotland\n",
      "Sumo               Japan\n",
      "Taekwondo    South Korea\n",
      "Cricket        Australia\n",
      "Cricket         Barbados\n",
      "Cricket         Pakistan\n",
      "Cricket          England\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(original_sports,'\\n\\n',cricket_loving_countries,'\\n\\n',all_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas takes the 2nd series + tries to infer the best data types to use (everything is a string, here, so no problem)\n",
    "\n",
    "append method doesn't actually *change* the underlying series but instead returns a *NEW* series made up of the 2 appended together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cricket    Australia\n",
       "Cricket     Barbados\n",
       "Cricket     Pakistan\n",
       "Cricket      England\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries.loc['Cricket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice when we query the appended series for those who have cricket as a national sport, we don't get a single value, but a series. \n",
    "\n",
    "This is actually very common, and if you have an RDB background, it's very similar to every table query resulting in a **return set**, which, itself, is a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
