---
title: "ch4_logistic_regression_lab_conceptual"
author: "Steve Newns"
date: "May 23, 2018"
output: html_document
---

## 4.7 Exercises
###Conceptual
**1. Using a little bit of algebra, prove that (4.2) is equivalent to (4.3). In other words, the logistic function representation and logit representation for the logistic regression model are equivalent.**

* 4.2 = `p(X) = (exp(B0 + B1\*X))/(1+exp(B0 + B1\*X)))`
* 4.3 = `p(X)/(1-p(X)) = exp(B0 + B1\*X)`
* From 4.3: 
\[= \frac {\frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}}
        {1 - \frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}}
\\
= \frac {\frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}}
        {
          \frac {1 + e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}
          - \frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}
        }
\\
= \frac {\frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}}
        {\frac {1} {1 + e^{\beta_0 + \beta_1 X}}}
\]        

**2. Classifying an observation to the class for which (4.12)** $p_k(x) = \frac {\pi_k \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} (x - \mu_k)^2)}{\sum {\pi_l \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} (x - \mu_l)^2) }}$
**is largest = equivalent to classifying an observation to the class for which *the discriminant function* (4.13) $\delta_k(x) = x \frac {\mu_k} {\sigma^2} - \frac {\mu_k^2} {2 \sigma^2} + \log(\pi_k)$ is largest. Prove that this is the case. In other words, under the assumption the observations in the kth class are drawn from a $ N(\mu_k, \sigma^2)$ distribution, the Bayes' classifier assigns an observation to the class for which the discriminant function is maximized.**

* ***NOTE***: **LDA** = model distribution of predictors `X` separately in each of response class (given `Y`s) + use Bayes’ theorem to flip these around into estimates for `Pr(Y = k|X = x)`

* Fix `x` + observe that we're maximizing over parameter `k`. Suppose that $\delta_k(x) \geq \delta_i(x)$, show that $f_k(x) \geq f_i(x)$. 
* Assuming $\delta_k(x) \geq \delta_i(x)$, we can write $x \frac {\mu_k} {\sigma^2} - \frac {\mu_k^2} {2 \sigma^2} + \log(\pi_k) \geq x \frac {\mu_i} {\sigma^2} - \frac {\mu_i^2} {2 \sigma^2} + \log(\pi_i)$
* Exponentiation = a **monotonically increasing** (entirely non-decreasing) function, so we can exponentiate and write $\pi_k \exp (x \frac {\mu_k} {\sigma^2} - \frac {\mu_k^2} {2 \sigma^2}) \geq \pi_i \exp (x \frac {\mu_i} {\sigma^2} - \frac {\mu_i^2} {2 \sigma^2})$

* Multipy both sides by constant $c = \frac { \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} x^2)} {\sum { \pi_l \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} (x - \mu_l)^2)}}$

* Gives $\frac {\pi_k \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} (x - \mu_k)^2)}{\sum {\pi_l \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} (x - \mu_l)^2) }} \geq \frac {\pi_i \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} (x - \mu_i)^2)}{\sum {\pi_l \frac {1} {\sqrt{2 \pi} \sigma} \exp(- \frac {1} {2 \sigma^2} (x - \mu_l)^2) }}$ 

* This is the same as $f_k(x) \geq f_i(x)$ and can be reversed to prove that maximizing $\delta_k(x)$ is the same as maximizing $p_k(x)$

**3. This problem relates to the QDA model, in which observations w/in each class are drawn from a normal distribution w/ a class-specific mean vector + a class-specific covariance matrix. Consider the simple case where `p = 1` = only 1 feature. Suppose we have `K` classes, + if an observation belongs to the `k`th class, then `X` comes from a 1D normal distribution: $X \sim N(\mu_k, \sigma_k^2)$ Recall the density function for the 1D normal distribution is given in (4.11): $f_k(x) = \frac {1} {\sqrt{2 \pi} \sigma_k} \exp(- \frac {1} {2 \sigma_k^2} (x - \mu_k)^2)$ Prove that in this case, the Bayes' classifier ($Pr(Y = 1|X = x_0) > 0.5$) is *not* linear. Argue that it is in fact quadratic.**

* **Hint: For this problem, you should follow the arguments laid out in Section 4.4.2, but without making the assumption that $\sigma_1^2  = ... = \sigma_K^2$ = (shared variance term across all K classes)**
* $\mu_k$ and $\simga_k^2$ =k are mean + variance parameters for kth class.
* Now, we are NOT making the shared variance assumtion
* Plugging (4.11) into (4.10) $Pr(Y = 1|X = x) = \frac {\pi_k f_k(x)} {\sum_{l=1}^K \pi_l f_l(x)}$, we find that

where n is the total number of training observations, and nk is the number
of training observations in the kth class. The estimate for μk is simply the
average of all the training observations from the kth class, while ˆσ2 can
be seen as a weighted average of the sample variances for each of the K
classes. Sometimes we have knowledge of the class membership probabilities
π1,...,πK, which can be used directly. In the absence of any additional
information, LDA estimates πk using the proportion of the training observations
that belong to the kth class. In other words,

**4. When the number of features p is large = tends to be deterioration in performance of KNN + other *local* approaches that perform prediction using only observations near the test observation = *curse of dimensionality*, which ties into the fact that *non-parametric approaches often perform poorly when p is large.* We will now investigate this curse.**

**(a) Suppose we have a set of observations, each w/ measurements on p = 1 feature, `X`. Assume `X` = uniformly (evenly) distributed on [0, 1]. Associated w/ each observation = a response value. Suppose we wish to predict a test observation's response using only observations w/in 10 % of the range of X values that're closest to that test observation. For instance, in order to predict the response for a test observation with X = 0.6, use observations in the range [0.55, 0.65]. On average, what fraction of the available observations will we use to make the prediction?**

* 

**(b) Now suppose that we have a set of observations, each with measurements on p = 2 features, X1 and X2. We assume that (X1, X2) are uniformly distributed on [0, 1] ? [0, 1]. We wish to predict a test observation's response using only observations thatare within 10 % of the range of X1 and within 10 % of the range of X2 closest to that test observation. For instance, in order to predict the response for a test observation with X1 = 0.6 and X2 = 0.35, we will use observations in the range [0.55, 0.65] for X1 and in the range [0.3, 0.4] for X2. On average, what fraction of the available observations will we use to make the prediction?**

**(c) Now suppose that we have a set of observations on p = 100 features. Again the observations are uniformly distributed on each feature, and again each feature ranges in value from 0 to 1. We wish to predict a test observation's response using observations within the 10 % of each feature's range that is closest to that test observation. What fraction of the available observations will we use to make the prediction?**

**(d) Using your answers to parts (a)-(c), argue that a drawback of KNN when p is large is that there are very few training observations "near" any given test observation.**

**(e) Now suppose that we wish to make a prediction for a test observation by creating a p-dimensional hypercube centered around the test observation that contains, on average, 10 % of the trainingobservations. For p = 1, 2, and 100, what is the length of each side of the hypercube? Comment on your answer.**

* **Note: A hypercube is a generalization of a cube to an arbitrary number of dimensions. When p = 1, a hypercube is simply a line segment, when p = 2 it is a square, and when p = 100 it is a 100-dimensional cube.**

**5. We now examine the differences between LDA and QDA.**

**(a) If the Bayes decision boundary is linear, do we expect LDA or QDA to perform better on the training set? On the test set?**

**(b) If the Bayes decision boundary is non-linear, do we expect LDA or QDA to perform better on the training set? On the test set?**

**(c) In general, as the sample size n increases, do we expect the test prediction accuracy of QDA relative to LDA to improve, decline, or be unchanged? Why?**

**(d) True or False: Even if the Bayes decision boundary for a given problem is linear, we will probably achieve a superior test error rate using QDA rather than LDA because QDA is flexible enough to model a linear decision boundary. Justify your answer.**

**6. Suppose we collect data for a group of students in a statistics class with variables X1 = hours studied, X2 = undergrad GPA, and Y = receive an A. We fit a logistic regression and produce estimated coefficient, ??^0 = ???6, ??^1 = 0.05, ??^2 = 1.**

**(a) Estimate the probability that a student who studies for 40 h and has an undergrad GPA of 3.5 gets an A in the class.**

**(b) How many hours would the student in part (a) need to study to have a 50 % chance of getting an A in the class?**

**7. Suppose that we wish to predict whether a given stock will issue a dividend this year ("Yes" or "No") based on X, last year's percentprofit. We examine a large number of companies and discover that themean value of X for companies that issued a dividend was X? = 10, while the mean for those that didn't was X? = 0. In addition, the variance of X for these two sets of companies was ^??2 = 36. Finally, 80 % of companies issued dividends. Assuming that X follows a normal distribution, predict the probability that a company will issue a dividend this year given that its percentage profit was X = 4 last year.**

* **Hint: Recall that the density function for a normal random variable is f(x) = ??? 1 2????2 e???(x?????)2/2??2 . You will need to use Bayes' theorem.**

**8. Suppose that we take a data set, divide it into equally-sized training and test sets, and then try out two different classification procedures. First we use logistic regression and get an error rate of 20 % on the training data and 30 % on the test data. Next we use 1-nearest neighbors (i.e. K = 1) and get an average error rate (averaged over both test and training data sets) of 18 %. Based on these results, which method should we prefer to use for classification of new observations? Why?**

**9. This problem has to do with odds.**

**(a) On average, what fraction of people with an odds of 0.37 of defaulting on their credit card payment will in fact default?**

**(b) Suppose that an individual has a 16 % chance of defaulting on her credit card payment. What are the odds that she will default?**
