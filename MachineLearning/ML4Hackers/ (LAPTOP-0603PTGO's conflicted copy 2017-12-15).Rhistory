set.seed(1)
train_indices <- sort(sample(1:(nrow(dtm)-1), round(.5*nrow(dtm))))
test_indices <- which(! 1:nrow(dtm) %in% train_indices)
train_x <- dtm[train_indices[-1], 3:ncol(dtm)]
train_y <- dtm[train_indices[-1], 1]
test_y <- dtm[test_indices, 3:ncol(dtm)]
train_y <- dtm[test_indices, 1]
rm(dtm)
load('data/dtm.RData')
set.seed(1)
train_indices <- sort(sample(1:nrow(dtm), round(.5*nrow(dtm))))
test_indices <- which(! 1:nrow(dtm) %in% train_indices)
train_x <- dtm[train_indices, 3:ncol(dtm)]
train_y <- dtm[train_indices, 1]
test_x <- dtm[test_indices, 3:ncol(dtm)]
train_y <- dtm[test_indices, 1]
rm(dtm)
load('data/dtm.RData')
set.seed(1)
train_indices <- sort(sample(1:nrow(dtm), round(.5*nrow(dtm))))
test_indices <- which(! 1:nrow(dtm) %in% train_indices)
train_x <- dtm[train_indices, 3:ncol(dtm)]
train_y <- dtm[train_indices, 1]
test_x <- dtm[test_indices[-1], 3:ncol(dtm)]
train_y <- dtm[test_indices[-1], 1]
rm(dtm)
library('glmnet')
regularized_logistic_regression <- glmnet(train_x, train_y, family = "binomial")
load('data/dtm.RData')
set.seed(1)
train_indices <- sort(sample(1:nrow(dtm), round(.5*nrow(dtm))))
test_indices <- which(! 1:nrow(dtm) %in% train_indices)
train_x <- dtm[train_indices, 3:ncol(dtm)]
train_y <- dtm[train_indices, 1]
test_x <- dtm[test_indices, 3:ncol(dtm)]
train_y <- dtm[test_indices, 1]
rm(dtm)
library('glmnet')
regularized_logistic_regression <- glmnet(train_x, train_y, family = "binomial")
load('data/dtm.RData')
set.seed(1)
train_indices <- sort(sample(1:nrow(dtm), round(.5*nrow(dtm))))
test_indices <- which(! 1:nrow(dtm) %in% train_indices)
train_x <- dtm[train_indices, 3:ncol(dtm)]
train_y <- dtm[train_indices, 1]
test_x <- dtm[test_indices, 3:ncol(dtm)]
test_y <- dtm[test_indices, 1]
rm(dtm)
library('glmnet')
regularized_logistic_regression <- glmnet(train_x, train_y, family = "binomial")
library(tidyverse)
library(ggplot2)
library(magrittr)
library(e1071)
library(reshape)
load('data/dtm.RData')
set.seed(1)
train_indices <- sort(sample(1:nrow(dtm), round(.5*nrow(dtm))))
test_indices <- which(! 1:nrow(dtm) %in% train_indices)
train_x <- dtm[train_indices, 3:ncol(dtm)]
train_y <- dtm[train_indices, 1]
test_x <- dtm[test_indices, 3:ncol(dtm)]
test_y <- dtm[test_indices, 1]
rm(dtm)
library('glmnet')
regularized_logistic_regression <- glmnet(train_x, train_y, family = "binomial")
(lambdas <- regularized_logistic_regression$lambda)
performance <- data.frame()
for (lambda in  lambdas) {
# test model on new test data with each lambda
temp_predictions <- predict(regularized_logistic_regression, text.x, s = lambda)
predictions <- as.numeric(temp_predictions > 0)
# calculate MSE
mse <- mean(predictions != test.y)
# add row back to DF
performance <- rbind(performance, data.frame(Lambda = lambda, MSE = mse))
}
performance <- data.frame()
for (lambda in  lambdas) {
# test model on new test data with each lambda
temp_predictions <- predict(regularized_logistic_regression, text.x, s = lambda)
predictions <- as.numeric(temp_predictions > 0)
# calculate MSE
mse <- mean(predictions != test_y)
# add row back to DF
performance <- rbind(performance, data.frame(Lambda = lambda, MSE = mse))
}
performance <- data.frame()
for (lambda in  lambdas) {
# test model on new test data with each lambda
temp_predictions <- predict(regularized_logistic_regression, test_x, s = lambda)
predictions <- as.numeric(temp_predictions > 0)
# calculate MSE
mse <- mean(predictions != test_y)
# add row back to DF
performance <- rbind(performance, data.frame(Lambda = lambda, MSE = mse))
}
ggplot(performance, aes(Lambda, MSE)) +
geom_point() +
scale_x_log10()
performance <- data.frame()
for (lambda in  lambdas) {
# test model on new test data with each lambda
temp_predictions <- predict(regularized_logistic_regression, test_x, s = lambda)
predictions <- as.numeric(temp_predictions > 0)
# calculate MSE
mse <- mean(predictions != test_y)
# add row back to DF
performance <- rbind(performance, data.frame(Lambda = lambda, MSE = mse))
}
ggplot(performance, aes(Lambda, MSE)) +
geom_point() +
scale_x_log10()
final_lambda <- with(performance, max(Lambda[which(MSE == min(MSE))]))
(mse <- with(subset(performance, Lambda == final_lambda), MSE))
source('~/.active-rstudio-document', echo=TRUE)
bullshit <- c(22, 33, 21, 28, 22, 31, 44, 50, 19)
median(bullshit)
quantile(bullshit, .25, .75)
quantile(bullshit, c(.25, .75))
bullshit2 <_ sort(bullshit)
bullshit2
bullshit2 <- sort(bullshit)
bullshit2
quantile(bullshit2, c(.25, .75))
median(bullshit2)
quantile(bullshit2, c(.25, .75))
quantile(bullshit2, c(.25, .5, .75))
bs1 <- bullshit2[1:4]
bs2 <- bullshit2[6:9]
median(bs1)
median(bs2)
bs2
bullshit*3
bullshit2*3
suppressMessages(library(tidyverse))
suppressMessages(library(ggplot2))
## import data
restaraunts <- read.tsv("../data/Restaurant_Reviews.tsv")
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
glimpse(restaraunts)
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
glimpse(restaraunts)
head(restaraunts)
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
glimpse(restaraunts)
head(restaraunts)
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
restaraunts2 <- read_delim("../data/Restaurant_Reviews.tsv", delim = "\t")
glimpse(restaraunts)
head(restaraunts)
restaraunts2 = restaraunts
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
restaraunts2 <- read_delim("../data/Restaurant_Reviews.tsv", delim = "\t")
glimpse(restaraunts)
head(restaraunts)
restaraunts2 == restaraunts
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
restaraunts2 <- read_delim("../data/Restaurant_Reviews.tsv", delim = "\t")
glimpse(restaraunts)
head(restaraunts)
sum(restaraunts2 == restaraunts)
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv", stringAsFactors = F)
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv", stringsAsFactors = F)
?read_tsv
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
glimpse(restaraunts)
head(restaraunts)
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review))
head(corpus())
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review))
(corpus())
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review))
head(corpus
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review))
head(corpus)
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review))
head(corpus)
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower)
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower)
as.character(corpus[[1]])
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower)
# check 1st reviews to make sure function worked
as.character(corpus[[1:3]])
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower)
# check 1st reviews to make sure function worked
as.character(corpus[[1]:[3]])
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower)
# check 1st reviews to make sure function worked
as.character(corpus[[1]])
as.character(corpus[[4]])
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeWords)
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers)
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation)
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords) # remove English stopwords
library(tm) # text mining
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) # remove English stopwords
install.packages("SnowballC")
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) # remove English stopwords
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords()) # remove English stopwords
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords # remove English stopwords
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) #%>%
#corpus <- tm_map(corpus, removeWords, stopwords # remove English stopwords
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #%>%
#tm_map(tolower) %>%
#tm_map(removeNumbers) %>%
#tm_map(removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords # remove English stopwords
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) #%>%
tm_map(removeWords, stopwords()) # remove English stopwords
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) # remove English stopwords
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords()) # remove English stopwords
corpus
tm_map(corpus, removeWords, stopwords())
tm_map(corpus, tolower)
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #%>%
corpus <- tm_map(tolower) #%>%
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #%>%
corpus <- tm_map(corpus, tolower) #%>%
corpus <- tm_map(corpus, removeNumbers) #%>%
corpus <- tm_map(corpus, removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords()) # remove English stopwords
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv")
glimpse(restaraunts)
head(restaraunts)
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #%>%
corpus <- tm_map(corpus, tolower) #%>%
corpus <- tm_map(corpus, removeNumbers) #%>%
corpus <- tm_map(corpus, removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords()) # remove English stopwords
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #%>%
corpus <- tm_map(corpus, tolower) #%>%
corpus <- tm_map(corpus, removeNumbers) #%>%
corpus <- tm_map(corpus, removePunctuation)
as.character(corpus[[841]])
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv", stringsAsFactor = F)
## import data
restaraunts <- read_tsv("../data/Restaurant_Reviews.tsv", stringsAsFactors = F)
## import data
restaraunts <- read.tsv("../data/Restaurant_Reviews.tsv", stringsAsFactors = F)
## import data
restaraunts <- read.delim("../data/Restaurant_Reviews.tsv", sep = "t", stringsAsFactors = F)
## import data
restaraunts <- read.delim("../data/Restaurant_Reviews.tsv", sep = "\t", stringsAsFactors = F)
glimpse(restaraunts)
head(restaraunts)
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #%>%
corpus <- tm_map(corpus, tolower) #%>%
corpus <- tm_map(corpus, removeNumbers) #%>%
corpus <- tm_map(corpus, removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords()) # remove English stopwords
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
## import data
restaraunts <- read.delim("../data/Restaurant_Reviews.tsv", quote = "" sep = "\t", stringsAsFactors = F)
## import data
restaraunts <- read.delim("../data/Restaurant_Reviews.tsv", quote = "",
sep = "\t", stringsAsFactors = F)
glimpse(restaraunts)
head(restaraunts)
## import data
restaraunts <- read.delim("../data/Restaurant_Reviews.tsv", quote = "",
stringsAsFactors = F)
glimpse(restaraunts)
head(restaraunts)
## import data
restaraunts <- read.delim("../data/Restaurant_Reviews.tsv", quote = "",
sep = "\t", stringsAsFactors = F)
glimpse(restaraunts)
head(restaraunts)
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #%>%
corpus <- tm_map(corpus, tolower) #%>%
corpus <- tm_map(corpus, removeNumbers) #%>%
corpus <- tm_map(corpus, removePunctuation) #%>%
corpus <- tm_map(corpus, removeWords, stopwords()) # remove English stopwords
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) # remove English stopwords
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) # get the ROOTs of each word via stemming
# check 1st reviews to make sure function worked
#as.character(corpus[[1])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) # get the ROOTs of each word via stemming
# check 1st reviews to make sure function worked
as.character(corpus[[1])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) # get the ROOTs of each word via stemming
# check 1st reviews to make sure function worked
as.character(corpus[[1]])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) %>% # get the ROOTs of each word via stemming
tm_map(stripWhitespace) # get rid of extra spaces
# check reviews to make sure function worked
as.character(corpus[[1]])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument)# %>% # get the ROOTs of each word via stemming
# tm_map(stripWhitespace) # get rid of extra spaces
# check reviews to make sure function worked
as.character(corpus[[1]])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) %>% # get the ROOTs of each word via stemming
tm_map(stripWhitespace) # get rid of extra spaces
# check reviews to make sure function worked
as.character(corpus[[1]])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #
as.character(corpus[[1]])
as.character(corpus[[841]])
corpuse %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) %>% # get the ROOTs of each word via stemming
tm_map(stripWhitespace) # get rid of extra spaces leftover
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #
as.character(corpus[[1]])
as.character(corpus[[841]])
corpus %>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) %>% # get the ROOTs of each word via stemming
tm_map(stripWhitespace) # get rid of extra spaces leftover
# check reviews to make sure function worked
as.character(corpus[[1]])
as.character(corpus[[841]])
library(tm) # text mining
library(SnowballC) # stopwords
corpus <- VCorpus(VectorSource(restaraunts$Review)) #
as.character(corpus[[1]])
as.character(corpus[[841]])
corpus %<>%
tm_map(tolower) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords()) %>% # remove English stopwords
tm_map(stemDocument) %>% # get the ROOTs of each word via stemming
tm_map(stripWhitespace) # get rid of extra spaces leftover
# check reviews to make sure function worked
as.character(corpus[[1]])
as.character(corpus[[841]])
