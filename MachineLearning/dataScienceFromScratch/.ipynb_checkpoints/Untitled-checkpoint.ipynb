{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 3, 0, 2, 3, 3, 2], [3, 2, 1, 1, 2], [1, 0, 2, 1, 2, 0], [0, 2, 3, 0, 2], [3, 2, 1, 3], [3, 2, 0, 0, 0, 3], [0, 3, 2, 1], [2, 0, 1, 1], [1, 1, 3, 0], [0, 2, 3, 0], [2, 2, 0], [2, 1, 2, 3], [0, 3, 2], [1, 2, 1, 1, 1], [0, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "import math, random, re\n",
    "from collections import defaultdict, Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#\n",
    "# TOPIC MODELING\n",
    "#\n",
    "\n",
    "def sample_from(weights):\n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random()       # uniform between 0 and total\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w                        # return the smallest i such that\n",
    "        if rnd <= 0: return i           # sum(weights[:(i+1)]) >= rnd\n",
    "\n",
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]\n",
    "\n",
    "K = 4\n",
    "\n",
    "document_topic_counts = [Counter()\n",
    "                         for _ in documents]\n",
    "\n",
    "topic_word_counts = [Counter() for _ in range(K)]\n",
    "\n",
    "topic_counts = [0 for _ in range(K)]\n",
    "\n",
    "document_lengths = [len(d) for d in documents]\n",
    "\n",
    "distinct_words = set(word for document in documents for word in document)\n",
    "W = len(distinct_words)\n",
    "\n",
    "D = len(documents)\n",
    "\n",
    "def p_topic_given_document(topic, d, alpha=0.1):\n",
    "    \"\"\"the fraction of words in document _d_\n",
    "    that are assigned to _topic_ (plus some smoothing)\"\"\"\n",
    "\n",
    "    return ((document_topic_counts[d][topic] + alpha) /\n",
    "            (document_lengths[d] + K * alpha))\n",
    "\n",
    "def p_word_given_topic(word, topic, beta=0.1):\n",
    "    \"\"\"the fraction of words assigned to _topic_\n",
    "    that equal _word_ (plus some smoothing)\"\"\"\n",
    "\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "            (topic_counts[topic] + W * beta))\n",
    "\n",
    "def topic_weight(d, word, k):\n",
    "    \"\"\"given a document and a word in that document,\n",
    "    return the weight for the k-th topic\"\"\"\n",
    "\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)\n",
    "\n",
    "def choose_new_topic(d, word):\n",
    "    return sample_from([topic_weight(d, word, k)\n",
    "                        for k in range(K)])\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "                   for document in documents]\n",
    "print(document_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({3: 4, 2: 2, 0: 1}), Counter({2: 2, 1: 2, 3: 1}), Counter({1: 2, 0: 2, 2: 2}), Counter({0: 2, 2: 2, 3: 1}), Counter({3: 2, 2: 1, 1: 1}), Counter({0: 3, 3: 2, 2: 1}), Counter({0: 1, 3: 1, 2: 1, 1: 1}), Counter({1: 2, 2: 1, 0: 1}), Counter({1: 2, 3: 1, 0: 1}), Counter({0: 2, 2: 1, 3: 1}), Counter({2: 2, 0: 1}), Counter({2: 2, 1: 1, 3: 1}), Counter({0: 1, 3: 1, 2: 1}), Counter({1: 4, 2: 1}), Counter({0: 1, 2: 1, 3: 1})] \n",
      " [Counter({'scikit-learn': 2, 'pandas': 2, 'HBase': 1, 'R': 1, 'regression': 1, 'Java': 1, 'C++': 1, 'Haskell': 1, 'statistics': 1, 'artificial intelligence': 1, 'Hadoop': 1, 'Big Data': 1, 'statsmodels': 1, 'libsvm': 1}), Counter({'neural networks': 2, 'deep learning': 2, 'Cassandra': 1, 'HBase': 1, 'Python': 1, 'numpy': 1, 'decision trees': 1, 'theory': 1, 'Mahout': 1, 'databases': 1, 'Postgres': 1, 'MySQL': 1, 'MongoDB': 1}), Counter({'Java': 2, 'Python': 2, 'regression': 2, 'R': 2, 'Cassandra': 1, 'MongoDB': 1, 'Postgres': 1, 'scipy': 1, 'statsmodels': 1, 'probability': 1, 'mathematics': 1, 'machine learning': 1, 'statistics': 1, 'C++': 1, 'artificial intelligence': 1, 'HBase': 1}), Counter({'Big Data': 2, 'probability': 2, 'Hadoop': 1, 'Spark': 1, 'Storm': 1, 'NoSQL': 1, 'statistics': 1, 'machine learning': 1, 'libsvm': 1, 'Python': 1, 'programming languages': 1, 'MapReduce': 1, 'R': 1, 'support vector machines': 1})] \n",
      " [16, 15, 20, 16]\n"
     ]
    }
   ],
   "source": [
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1\n",
    "print(document_topic_counts,\"\\n\",topic_word_counts,\"\\n\",topic_counts)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for iter in range(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],\n",
    "                                              document_topics[d])):\n",
    "\n",
    "            # remove this word / topic from the counts\n",
    "            # so that it doesn't influence the weights\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "\n",
    "            # choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "\n",
    "            # and now add it back to the counts\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # topic MODELING\n",
    "\n",
    "    for k, word_counts in enumerate(topic_word_counts):\n",
    "        for word, count in word_counts.most_common():\n",
    "            if count > 0: print(k, word, count)\n",
    "\n",
    "    topic_names = [\"Big Data and programming languages\",\n",
    "                   \"databases\",\n",
    "                   \"machine learning\",\n",
    "                   \"statistics\"]\n",
    "\n",
    "    for document, topic_counts in zip(documents, document_topic_counts):\n",
    "        print(document)\n",
    "        for topic, count in topic_counts.most_common():\n",
    "            if count > 0:\n",
    "                print(topic_names[topic], count)\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
