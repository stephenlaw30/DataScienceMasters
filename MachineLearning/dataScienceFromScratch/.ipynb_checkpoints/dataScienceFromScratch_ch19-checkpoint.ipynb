{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 19. Clustering\n",
    "\n",
    "***Clustering*** = unsupervised learning = completely unlabeled data (or data has labels but we ignore them)\n",
    "\n",
    "### The Idea\n",
    "Whenever you look at some source of data, it’s likely it will somehow form clusters. A data set showing where millionaires live probably has clusters in places like Beverly Hills and Manhattan. A data set showing how many hours people work each week\n",
    "probably has a cluster around 40.. A data set of demographics of registered voters likely forms a variety of clusters (e.g., “soccer moms,” “bored retirees,” “unemployed millennials”) that pollsters + political consultants likely consider relevant.\n",
    "\n",
    "Generally no “correct” clustering. An alternative clustering scheme might group some of the “unemployed millenials” w/ “grad students,” others w/ “parents’ basement dwellers.” Neither scheme is necessarily more correct + each is likely more optimal w/ respect to its own “how good are the clusters?” metric.\n",
    "\n",
    "Furthermore, the **clusters won’t label themselves. You’ll have to do that by looking at the data underlying each one.**\n",
    "\n",
    "### The Model\n",
    "\n",
    "For us, each input = vector in d-dimensional space (represented as a list of #'s) w/ goal = ID clusters of similar inputs + (sometimes) to find a representative value for each cluster.\n",
    "For example, each input could be (a numeric vector that somehow represents) the title of a\n",
    "blog post, in which case the goal might be to find clusters of similar posts, perhaps in\n",
    "order to understand what our users are blogging about. Or imagine that we have a picture\n",
    "containing thousands of (red, green, blue) colors and that we need to screen-print a\n",
    "10-color version of it. Clustering can help us choose 10 colors that will minimize the total\n",
    "“color error.”\n",
    "One of the simplest clustering methods is k-means, in which the number of clusters k is\n",
    "chosen in advance, after which the goal is to partition the inputs into sets in a\n",
    "way that minimizes the total sum of squared distances from each point to the mean of its\n",
    "assigned cluster.\n",
    "There are a lot of ways to assign n points to k clusters, which means that finding an\n",
    "optimal clustering is a very hard problem. We’ll settle for an iterative algorithm that\n",
    "usually finds a good clustering:\n",
    "1. Start with a set of k-means, which are points in d-dimensional space.\n",
    "2. Assign each point to the mean to which it is closest.\n",
    "3. If no point’s assignment has changed, stop and keep the clusters.\n",
    "4. If some point’s assignment has changed, recompute the means and return to step 2.\n",
    "Using the vector_mean function from Chapter 4, it’s pretty simple to create a class that\n",
    "does this:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
