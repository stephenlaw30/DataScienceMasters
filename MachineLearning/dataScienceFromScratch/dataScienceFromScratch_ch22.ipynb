{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 22. Recommender Systems\n",
    "\n",
    "Another common data problem = producing recommendations of some sort. Netflix = movies, Amazon = products, Twitter = users to follow. We’ll look @ a data set of `users_interests` + think about the problem of recommending new interests to a user based on currently specified interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_interests = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Curation\n",
    "Before Internet, for book recommendations = would go to library = librarian was available to suggest books relevant to your interests or similar to books you liked. Given our limited # of users + interests, it would be easy for you to spend an afternoon manually recommending interests for each user. But this method doesn’t scale well + is limited by your personal knowledge +\n",
    "imagination.\n",
    "\n",
    "### Recommending What’s Popular\n",
    "\n",
    "1 easy approach = simply recommend what’s popular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "\n",
    "popular_interests = [('Python', 4),\n",
    "           ('R', 4),\n",
    "           ('Java', 3),\n",
    "           ('regression', 3),\n",
    "           ('statistics', 3),\n",
    "           ('probability', 3)]\n",
    "\n",
    "popular_interests = Counter(interest\n",
    "                            for user_interests in users_interests\n",
    "                            for interest in user_interests).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having computed this, can just suggest to a user the most popular interests that he’s not already interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 4), ('R', 4), ('statistics', 3), ('regression', 3), ('probability', 3)]\n",
      "[('R', 4), ('Big Data', 3), ('HBase', 3), ('Java', 3), ('statistics', 3)]\n"
     ]
    }
   ],
   "source": [
    "def most_popular_new_interests(user_interests,max_results=5):\n",
    "    suggestions = [(interest,frequency) \n",
    "                   for interest,frequency in popular_interests\n",
    "                  if interest not in user_interests]\n",
    "    return suggestions[:max_results]\n",
    "\n",
    "# user 1 new suggested interests \n",
    "print(most_popular_new_interests(users_interests[0],5))\n",
    "# user 3 new suggested interests \n",
    "print(most_popular_new_interests(users_interests[2],5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Lots of people = interested in Python so maybe you should be too” is not a sales pitch. If someone is brand new to our site + we don’t know anything about them, that’s possibly the best we can do. Let’s see how we can do better by basing each user’s recommendations on her interests.\n",
    "\n",
    "### User-Based Collaborative Filtering\n",
    "1 way of taking a user’s interests into account = look for users who are somehow similar to him, + then suggest the things those users are interested in. To do that, need a way to measure how similar 2 users are: say w/ **cosine similarity**: Given 2 vectors, `v` and `w`, it’s measures the “angle” between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "\n",
    "sys.path.insert(0, './../../../00_DataScience/DSFromScratch/code')\n",
    "\n",
    "from linear_algebra import dot\n",
    "\n",
    "def cosine_similarity(v,w):\n",
    "    return dot(v,w) / math.sqrt(dot(v,v) * dot(w,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If v + w point in same direction, then the numerator + denominator are =, + their cosine similarity = 1. If v + w point in opposite directions, their cosine similarity = -1. And if v = 0 whenever w is not (+ vice versa), `dot(v, w) = 0` + so cosine similarity = 0.\n",
    "\n",
    "We’ll apply this to vectors of 0s and 1s, each vector `v` representing 1 user’s interests. `v[i]` = 1 if user is specified the `i`th interest, 0 otherwise. Accordingly, “similar users” will mean *“users whose interest vectors most nearly point in the same direction.”* \n",
    "\n",
    "Users w/ identical interests will have similarity = 1, users w/ no identical interests will have similarity = 0. Otherwise, similarity will fall in between, w/ #'s closer to 1 indicating “very similar” + #'s closer to 0 indicating “not very similar.”\n",
    "\n",
    "A good place to start = collecting *known* interests + (implicitly) assigning indices to them via a **set comprehension** to find the unique interests, putting them in a list, + then sorting. 1st interest in the resulting list will be interest 0, and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Big Data', 'C++', 'Cassandra', 'HBase', 'Hadoop']\n"
     ]
    }
   ],
   "source": [
    "unique_interests = sorted(list({interest\n",
    "                               for user_interests in users_interests\n",
    "                               for interest in user_interests}))\n",
    "print(unique_interests[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next = produce an “interest” vector of 0s + 1s for each user via iterating over `unique_interests`, substituting a 1 if user has each interest, 0 if\n",
    "not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_interest_vector(user_interests):\n",
    "    \"\"\"Given list of interests, produce vector where ith element = 1\n",
    "    if unique_interests set is in list, 0 otherwise\"\"\"\n",
    "    return [1 if interest in user_interests else 0 \n",
    "           for interest in unique_interests]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a matrix of user interests simply by `map`-ping this function\n",
    "against the list of lists of interests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] \n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0] \n",
      "\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_interest_matrix = list(map(user_interest_vector,users_interests))\n",
    "for row in user_interest_matrix:\n",
    "    print(row,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B/c we have a small data set, it’s no problem to compute **pairwise similarities** between all users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_similarities = [[cosine_similarity(interest_vector_i,interest_vector_j)\n",
    "                      for interest_vector_j in user_interest_matrix]\n",
    "                     for interest_vector_i in user_interest_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user_similarities[i][j]` gives similarity between users i + j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5669467095138409\n",
      "0.1889822365046136\n"
     ]
    }
   ],
   "source": [
    "print(user_similarities[0][9])\n",
    "print(user_similarities[0][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users 0 and 9 share interests in Hadoop, Java, Big Data, while users 0 and 8 share only 1 interest, Big Data. In particular, `user_similarities[i]` = vector of user `i`’s similarities to every other user, which can be used to write a function that finds the most similar users to a given user (make sure not to include user themself, nor any users w/ similarity = 0) + sort results from most to least similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_users(user_id):\n",
    "    pairs = [(other_user_id,similarity)\n",
    "            for other_user_id, similarity \n",
    "             in enumerate(user_similarities[user_id])\n",
    "            if user_id != other_user_id and similarity > 0]\n",
    "    \n",
    "    return sorted(pairs, key=lambda pair: pair[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 0.5669467095138409), (1, 0.3380617018914066), (8, 0.1889822365046136), (13, 0.1690308509457033), (5, 0.1543033499620919)]\n"
     ]
    }
   ],
   "source": [
    "print(most_similar_users(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we use this to suggest new interests to a user? For each interest, we can just add up user-similarities of other users interested in it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MapReduce', 0.5669467095138409) \n",
      "\n",
      "('MongoDB', 0.50709255283711) \n",
      "\n",
      "('Postgres', 0.50709255283711) \n",
      "\n",
      "('NoSQL', 0.3380617018914066) \n",
      "\n",
      "('neural networks', 0.1889822365046136) \n",
      "\n",
      "('deep learning', 0.1889822365046136) \n",
      "\n",
      "('artificial intelligence', 0.1889822365046136) \n",
      "\n",
      "('databases', 0.1690308509457033) \n",
      "\n",
      "('MySQL', 0.1690308509457033) \n",
      "\n",
      "('Python', 0.1543033499620919) \n",
      "\n",
      "('R', 0.1543033499620919) \n",
      "\n",
      "('C++', 0.1543033499620919) \n",
      "\n",
      "('Haskell', 0.1543033499620919) \n",
      "\n",
      "('programming languages', 0.1543033499620919) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def user_based_suggestions(user_id,include_current_interests=False):\n",
    "    # sum up other users similarities\n",
    "    suggestions = defaultdict(float)\n",
    "    for other_user_id, similarity in most_similar_users(user_id):\n",
    "        for interest in users_interests[other_user_id]:\n",
    "            suggestions[interest] += similarity\n",
    "    \n",
    "    # convert sums to sorted list\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                        key=lambda pair: pair[1], reverse = True)\n",
    "    \n",
    "    # include/exclude current interests\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion,weight)\n",
    "                for suggestion,weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]\n",
    "    \n",
    "for i in user_based_suggestions(0):\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These seem like pretty decent suggestions for someone whose stated interests are “Big Data” + database-related. (weights aren’t intrinsically meaningful; + just used for ordering.) \n",
    "\n",
    "This approach doesn’t work as well when # of items gets very large. Recall **curse of dimensionality** == in large-dimensional vector spaces, most vectors = very far apart (+ therefore point in very different directions) = when there're a large # of interests, “most similar users” to a given user might not be similar at all.\n",
    "\n",
    "* Ex: Amazon.com: could attempt to ID similar users based on buying patterns, but most likely in all the world there’s no one whose purchase history looks even remotely like anothers.\n",
    "\n",
    "### Item-Based Collaborative Filtering\n",
    "Alternative approach = compute similarities between interests *directly* + then generate suggestions for each user by aggregating interests similar to her their current interests.\n",
    "\n",
    "To start = transpose `user-interest matrix` so rows = interests + columns = users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0] \n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] \n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] \n",
      "\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] \n",
      "\n",
      "[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] \n",
      "\n",
      "[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] \n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] \n",
      "\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] \n",
      "\n",
      "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] \n",
      "\n",
      "[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] \n",
      "\n",
      "[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] \n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interest_users_matrix = [[user_interest_vector[j]\n",
    "                         for user_interest_vector in user_interest_matrix]\n",
    "                        for j,_ in enumerate(unique_interests)]\n",
    "for row in interest_users_matrix:\n",
    "    print(row,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row `j` of `interest_user_matrix` = column `j` of `user_interest_matrix` = has 1 for each user w/ that interest + 0 for each user w/out that interest (`unique_interests[0]` = Big Data)\n",
    "\n",
    "Can now use `cosine_similarity` again + if precisely the same users are interested in 2 topics, their similarity = 1. If no 2 users are interested in both topics, similarity = 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hadoop', 0.8164965809277261) \n",
      "\n",
      "('Java', 0.6666666666666666) \n",
      "\n",
      "('MapReduce', 0.5773502691896258) \n",
      "\n",
      "('Spark', 0.5773502691896258) \n",
      "\n",
      "('Storm', 0.5773502691896258) \n",
      "\n",
      "('Cassandra', 0.4082482904638631) \n",
      "\n",
      "('artificial intelligence', 0.4082482904638631) \n",
      "\n",
      "('deep learning', 0.4082482904638631) \n",
      "\n",
      "('neural networks', 0.4082482904638631) \n",
      "\n",
      "('HBase', 0.3333333333333333) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interest_similarities = [[cosine_similarity(user_vector_i,user_vector_j)\n",
    "                         for user_vector_j in interest_users_matrix]\n",
    "                        for user_vector_i in interest_users_matrix]\n",
    "\n",
    "# find interests most similar to big data (0)\n",
    "def most_similar_interests(interest_id):\n",
    "    similarities = interest_similarities[interest_id]\n",
    "    pairs = [(unique_interests[other_interest_id], similarity)\n",
    "            for other_interest_id, similarity in enumerate(similarities)\n",
    "            if interest_id != other_interest_id and similarity > 0]\n",
    "    \n",
    "    return sorted(pairs, key=lambda pair: pair[1], reverse=True)\n",
    "\n",
    "for i in most_similar_interests(0):\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can now create recommendations for a user by summing up similarities of interests similar to his:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MapReduce', 1.861807319565799) \n",
      "\n",
      "('MongoDB', 1.3164965809277263) \n",
      "\n",
      "('Postgres', 1.3164965809277263) \n",
      "\n",
      "('NoSQL', 1.2844570503761732) \n",
      "\n",
      "('MySQL', 0.5773502691896258) \n",
      "\n",
      "('databases', 0.5773502691896258) \n",
      "\n",
      "('Haskell', 0.5773502691896258) \n",
      "\n",
      "('programming languages', 0.5773502691896258) \n",
      "\n",
      "('artificial intelligence', 0.4082482904638631) \n",
      "\n",
      "('deep learning', 0.4082482904638631) \n",
      "\n",
      "('neural networks', 0.4082482904638631) \n",
      "\n",
      "('C++', 0.4082482904638631) \n",
      "\n",
      "('Python', 0.2886751345948129) \n",
      "\n",
      "('R', 0.2886751345948129) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def item_based_suggestions(user_id,include_current_interests=False):\n",
    "    # sum up other users similarities\n",
    "    suggestions = defaultdict(float)\n",
    "    user_interest_vector = user_interest_matrix[user_id]\n",
    "    \n",
    "    for interest_id, is_interested in enumerate(user_interest_vector):\n",
    "        if is_interested == 1:\n",
    "            similar_interests = most_similar_interests(interest_id)\n",
    "            for interest, similarity in similar_interests:\n",
    "                suggestions[interest] += similarity\n",
    "    \n",
    "    # convert sums to sorted list by weight\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                        key=lambda pair: pair[1], reverse = True)\n",
    "    \n",
    "    # include/exclude current interests\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion,weight)\n",
    "                for suggestion,weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]\n",
    "    \n",
    "for i in item_based_suggestions(0):\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Further Exploration\n",
    "* Crab is a framework for building recommender systems in Python.\n",
    "* Graphlab also has a recommender toolkit.\n",
    "* Netflix Prize was a somewhat famous competition to build a better system to recommend movies to Netflix user"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
