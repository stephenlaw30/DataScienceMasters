---
title: "Udemy - ML AZ - Simple Linear Regression"
author: "Steve Newns"
date: "October 2, 2017"
output: html_document
---

## Business Problem

We had 30 randomly selected employees from the company and surveyed years of experience in the workforce and salary.

We want to know if there is a correlation between salary + years of experience, and if so, what is it?

The Business Value of the project = If the business does not have set policies on setting salaries, we can use *this model* to set them based off of.

```{r libraries and data, warning = FALSE, message = FALSE}

library(caTools) # library for splitting data
library(ggplot2)
library(tidyverse)
```


```{r eda}
salary <- read.csv('./Salary_Data.csv')
glimpse(salary)
head(salary)
summary(salary)
hist(salary$Salary)
```

This data looks relatively normal. Now to split it into test and training sets for a linear regression model. We have 30 observations, and I want 20 in the training set and 10 in the test set.
```{r split data}
set.seed(123) # for reproducibility

# split data based on the labels = YearExperience
spl <- sample.split(salary$YearsExperience, SplitRatio = 2/3)
training <- subset(salary, spl == T)
test <- subset(salary, spl == F)
hist(training$Salary)
hist(test$Salary)
```

I wasn't expecting the test set to be too normal, as there is a very small sample size, but it's not too skewed. The training set is also moderately normal, maybe slightly bimodal.

Now to use the training data to train a simple linear model to predict Salary based on years of experience.

```{r simple model}
simpleModel1 <- lm(Salary ~ YearsExperience, training)
summary(simpleModel1)
```

So **YearsExperience** is very statistically significant (p < .0001 which is below our alpha level = 0.05). This means there is a greater effect/impact on the dependent variable by the independent variable. This signifies a strong positive linear relationship between these 2 variables.

We can see the high coefficient for YearsExperience (> 9000), which means that for 1 unit change in YearsExperience (1 year), we would have a about a 9300 unit change in Salary ($9k increase per year).

We also have an intercept term of 25592, which tells us that with no years of experience, we'd still have a baseline salary of about $25k per year.

We also have a very good R2 and Adjusted R2, which tells us that about 96% of the variability in Salary can be explained by the variability in years experience.

The formula for this model ends up being **y^ = 9364*YearsExperience + 25592**

## PREDICTIONS

Now we need to use the trained model above on the test data to make sure it generalizes to new data that the model has not seen yet.

```{r predictions}
y.pred.train <- predict(simpleModel1, training)
y.pred.test <- predict(simpleModel1, test)
```

'Now that we have some predictions of salaries based on our linear model, we can check our accuracy of these predictions, and therefore of our model.

## VISUALIZE TRAINING SET RESULTS

```{r training histogram}
training %>%
  ggplot() + 
  geom_point(aes(YearsExperience, Salary), colour = 'green') + # plot training points
  geom_line(aes(YearsExperience, y.pred.train), colour = 'red') + # plot regression line
  xlab('Years of Experience') + 
  ggtitle('Salary by Years of Experience (Training Set)')
```
We can see that our model fits pretty well to our training data, and hopefully is not overfitting it.

Now to check it on the test data.

```{r test data predictions}
ggplot() + 
  geom_point(aes(test$YearsExperience, test$Salary), colour = 'green') + # plot test points
  geom_line(aes(training$YearsExperience, y.pred.train), colour = 'red') + # plot same regression line
  xlab('Years of Experience') + 
  ylab('Salary') + 
  ggtitle('Salary by Years of Experience (Testing Set)')
```
We wanted to use the same regression line for both graphs, since our regression model was created using the training set.

Looking at the test set plot, most of our predictions look good, with maybe 2 "far" points, at around 6 years and 8 years.