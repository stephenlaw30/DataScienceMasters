---
title: "Multiple Linear Regression - Udemy MLAZ"
author: "Steve Newns"
date: "October 3, 2017"
output: html_document
---

## Business Problem - Venture Capatalism

Our VC firm has data on 50 companies, including extracts from their P&L for the given financial year. So we know how much they spent on R&D, on Admin costs (salaries), and on Marketing. We also know their profits and which US state they operate in.

We want to be able to predict profits based on the different expenses of a company as well as the state they operate in via a multiple linear regression model.

With this model, the VC firm will know which new companies they'd want to invest in. This will also depend whether our VC firm is more concerned with each the spends and which would yield more profits.

```{r message=F, warning=F}
# library for splitting data
library(caTools)
library(ggplot2)
library(tidyverse)

# inspect
startups <- read.csv('50_Startups.csv')
head(startups)
summary(startups)
glimpse(startups)
```

We have no missing values, and it appears that the median and mean scores are all relatively close for each of the spends, so they might be normal distributions.

```{r}
ggplot(startups) + 
  geom_histogram(aes(R.D.Spend), binwidth = 20000)

ggplot(startups) + 
  geom_histogram(aes(Administration), binwidth = 20000)

ggplot(startups) + 
  geom_histogram(aes(Marketing.Spend), binwidth = 100000)
```

Or maybe not. Whatever. This is what I was given. 

**State** is a factor variable, and when dealing with factors in a linear regression, we need to create **dummy variables** for each unique level of the factor and use *only ONE of these dummy variables in the regression*.

```{r}
# encode categorical data (State)
startups$State <- factor(startups$State, 
                         levels = c('New York', 'California', 'Florida'),
                         labels = c(1,2,3))

head(startups)
```

Now our factor is using integers, so it can actually be affected by the regression coefficient assigned to it. Now let's split and train the data with 80% of our 50 observations in the training set and the remaining 20% in the test set.

```{r}
# split data
set.seed(123)
spl <- sample.split(startups$Profit, SplitRatio = .8) # 40 in train, 10 in test
training <- subset(startups, spl == T)
test <- subset(startups, spl == F)

dim(training)
dim(test)

# create regressor (model) and do backwards elimination
regressor.all <- lm(Profit ~ ., training)
summary(regressor.all)
```

We see that only R&D spend is significant in this model, but State2 has highest p-value, and increases in Administration costs seem to cause a *decrease* in profit.

Let's check a model with only the significant R.D.Spend variable.

```{r}
regressor.RD <- lm(Profit ~ R.D.Spend, training)
summary(regressor.RD)
```

Now we need to use the model to train it on the traning and test data.

```{r}
y.pred.train <- predict(regressor.RD, training)
y.pred.test <- predict(regressor.RD, test)

# compare test w/ actuals
y.pred.test
test$Profit[0:10]
```

We see that our predictions are kind of close to the actual values in the test set for profit.

Now that we have some predictions of profits based on our linear model, we can check our accuracy of these predictions, and therefore of our model.

```{r visualize training set accuracy}
ggplot(training) + 
  geom_point(aes(R.D.Spend, Profit), colour = 'green') + # plot traning points
  geom_line(aes(R.D.Spend, y.pred.train), colour = 'red') + # plot regression line
  xlab('R&D Spend ($)') +
  ylab('Profits ($)') +
  ggtitle('Profits by Amount of R&D Spend (Training Set)')

ggplot() + 
  geom_point(aes(test$R.D.Spend, test$Profit), colour = 'green') + # plot test points
  geom_line(aes(training$R.D.Spend, y.pred.train), colour = 'red') + # plot same regression line
  xlab('R&D Spend ($)') +
  ylab('Profits ($)') +
ggtitle('Profits by Amount of R&D Spend (Test Set)')
```
We wanted to use the same regression line for both graphs, since our regression model was created using the training set, and it looks like most of our predictions are pretty close, with estimates for R&D spend around $100k and $110k being a bit more off.


## BACKWARDS ELIMINATION

Let's look at backwards elimination of the dummy variables.

```{r}
regressor.all <- lm(Profit ~ ., training)
summary(regressor.all)
```

State 2 and 3 have the highest p-values (> .95), so they have minimal impact on profits. 

Remove both by removing "State" from the model to remove all dummy variables.

If we only used 1 of the state variables, the one *not* included will become the *default state* for the model and is included in the intercept term, **b0**. So, when the chosen State variable's coefficient = 0, we have an "alternate" equation for the non-included state.

Then, when the chosen State *does* have a coefficient, the model is adding the difference between the chosen and excluded States to alter the formula into the chosen State (like an on/off switch).

**Dummy Variable Trap**
.	If we include all dummy variables above, we are then *duplicating* a variable
.	D2 always = 1 - D1
.	So, because of the above, there's **multicollinearity** = 1 or more independent variables predicts another 
.	When this happens the model cannot differentiate the difference between the effects of D1 vs. the effects of D2 and therefore won't work properly
.	Cannot have the intercept term b0 and all dummy variables in a model at the same time
.	Must always remove ONE dummy variable (ex: 9 states = 8 dummy variables)
.	If we have 2 sets of dummy variables, we'd apply the same rules to each set (ex: weather type + state)

```{r}
regressor.noState <- lm(Profit ~ R.D.Spend + Administration + Marketing.Spend, training)
summary(regressor.noState)
```

Now Admin costs have the highest p-value, so remove that variable.

```{r}
regressor.noStateAdmin <- lm(Profit ~ R.D.Spend + Marketing.Spend, training)
summary(regressor.noStateAdmin)
```

We see that Marketing spend now is *barely significant*. Should we remove it?

This is an arbitrary choice, depending on the significance level, but let's remove it for now, which we already did in an earlier model.

```{r}
summary(regressor.RD)
```

So we only have 1 variable left in our model and it is indeed significant, but *our Adj R2 has decreased from the previous model (.9468 -> .9434)*. That doesn't matter. We'll take a simpler model with all significant predictors if our Adjusted R2 is not decreased too much.


Now let's use the final model on the full dataset.

```{r}
finalModel.RD <- lm(Profit ~ R.D.Spend, startups)
summary(finalModel.RD)
```

## Building a model
When building a linear regression. model, we	don't necessarily need *all* predictors/features in the model.
What we *really* need is a simple model that is easy to explain/present, so we only want to keep *very important* variables that *significantly* predict/have an effect on the outcome.
There are multiple methods to designing a model:
  - **All-in**
    - throw in all variables (only do this if we know *for sure* from our domain knowledge/previous knowledge that ALL ofthe factors are important)
      - Or we may be required to do so due to some framework in the company (i.e. not your decision)
  - **Backwards elimination** 
    1) Select significance level for the variable to reach to STAY in the model
    2) Fit all variables into a model
    3) Consider predictor w/ highest p-value (worst predictor) + remove it
    4) Fit new model w/out that variable 
    5) Repeat step 3 and 4 until all variable p-values are < significance level
  - **Forward selection**
    1) Select significance level for the variable to ENTER the model
    2) Fit all possible (i.e. multiple) SIMPLE regression models (y = b1*x1) 
    3) Select simple linear regression model w/ lowest p-value
    4) Fit all possible regression models w/ the variable from step 3 PLUS a 2nd predictor
    5) Select new linear regression model w/ lowest p-value
    6) Add 3rd, then 4th variable.. ??? repeat until variable added becomes > significance
    7) Keep model prior to adding this variable that has too large of a p-value
  - **Bidirectional elimination (Stepwise regression)**
    1) Select a significance level for the variable to ENTER the model + to STAY in the model
    2) Perform Step 2 of forward selection (fit all simple linear regression models)
    3) Perform ALL steps of backward elimination
    4) Repeat Step 2 and 3 until we cannot add nor remove any variables
  - **Score comparison/All possible models**
    1) Select criterion of goodness of fit (e.g. **Akaike information criterion (AIC)**)
      - AIC = Given a collection of models for data, AIC estimates the *quality* of each model, relative to each of the other models
      - AIC provides a means for model selection.
    2) Construct all possible regression models (2^n - 1 total combinations) 
    3) Select model that best meets the criterion
    - NOTE: 10 columns = 1023 models
