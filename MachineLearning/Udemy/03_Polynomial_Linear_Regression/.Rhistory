'3d. What is MSBetween for this problem? (Round to 1 decimal place.)'
sec1.mu <- mean(sec1)
sec2.mu <- mean(sec2)
sec3.mu <- mean(sec3)
SS.w <- sum((sec1 - sec1.mu)^2,(sec2 - sec2.mu)^2,(sec3 - sec3.mu)^2)
SS.b = SS.t - SS.w
SS.b
sec1.mu
(sec1 - sec1.mu)
(sec2 - sec2.mu)
SS.w <- sum((sec1 - sec1.mu)^2,(sec2 - sec2.mu)^2,(sec3 - sec3.mu)^2)
SS.b = SS.t - SS.w
SS.b
MS.b <- SS.b / 2
MS.w <- SS.w / 15
MS.b
MS.w
f <- MS.b / MS.w
f
MS.b
MS.w <- SS.w / 15
MS.w
f
f.crit <- 3.6823
f > f.crit
SS.t <- 2147
SS.b <- 782
SS.w <- SS.t - SS.b
SS.w
MS.w <- SS.w / 34
MS.w
1365/34
MS.b <- SS.b / 2
f <- MS.b / MS.w
f
MS.w <- round(SS.w / 34,2) # 40.14706 = 40.15
f <- MS.b / MS.w # 9.739194 = 9.739194
f
MS.b <- round(SS.b / 2,2)
f <- MS.b / MS.w # 9.739194 = 9.739194
f
bonferroni <- (3 * (3-1)) / 2)
bonferroni <- (3 * (3-1)) / 2
0.05 / bonferroni
round(0.05 / bonferroni,3)
'4h. Here are the results from your post-hoc analysis. These are the p-values from the actual t-tests. They are not adjusted, so be sure to compare them to the significance level you calculated above.
d
)
library(SDSFoundations)
res <- TempskiResilience
head(res[res$QoL==10,])
head(res)
res$QoL[:10]
res$QoL[0:10]
sum(res$QoL[0:10] > 5)
(res$QoL[0:10] > 5)
(res$MS.QoL[0:10] > 5)
sum(res$MS.QoL[0:10] > 5)
names(res)
head(res
)
clin.sci <- res[res$Group == 'Clinical Sciences']
clin.sci <- res[res$Group == 'Clinical Sciences',]
cor(clin.sci$BDI,clin.sci$QoL)
cor.test(clin.sci$BDI,clin.sci$QoL) # -0.3746403
install.packages('psych')
library(psych)
corr(clin.sci$BDI,clin.sci$QoL) # -0.3746403
corr.test(clin.sci$BDI,clin.sci$QoL) # -0.3746403
?corr.test
vars <- c('BDI','QoL')
corr.test(clin.sci[,vars]) # -0.3746403
corr.test(clin.sci[,vars])$r
corr.test(clin.sci[,vars])$r
corr.test(clin.sci[,vars])$p
corr.test(clin.sci[,vars])$t
clin.sci.model <- lm(QoL~BDI, clin.sci)
summary(clin.sci.model)
names(clin.sci)
vars <- c('DREEM.S.SP','DREEM.A.SP','Resilience', 'BDI', 'Age')
corr.test(clin.sci[,vars])$r
corr.test(clin.sci[,vars])$r
corr.test(clin.sci[,vars],use = 'pairwise.complete.obs')$r
names(clin.sci)
vars <- c('MS.QoL','DREEM.S.SP','DREEM.A.SP','Resilience', 'BDI', 'Age')
corr.test(clin.sci[,vars],)$r
vars <- c('MS.QoL','DREEM.S.SP','DREEM.A.SP','Resilience', 'BDI', 'Age')
corr.test(clin.sci[,vars])$r
clin.sci.model2 <- lm(MS.QoL ~ DREEM.S.SP + DREEM.A.SP + Resilience + BDI + Age, clin.sci)
summary(clin.sci.model2)
confint(clin.sci.model)
confint(clin.sci.model2) # confident intervals
plot(clin.sci.model, which = 1)
plot(clin.sci.model)
plot(clin.sci.model, which = 1)
# have linearity and homoscedasticity
# observations w/ numeric labels are the row #'s of outliers --> 1055, 871, 1107
#cooks distance plot
cutoff <- 4/(clin.sci.model$df) # cutoff of influence for cook's distance is 4 / dF in the LM model
plot(clin.sci.model, which = 4, cook.levels=cutoff)
plot(clin.sci.model, which = 4, cook.levels = cutoff, id.n = 5)
plot(clin.sci.model2, which = 1)
cutoff <- 4/(clin.sci.model2$df) # cutoff of influence for cook's distance is 4 / dF in the LM model
plot(clin.sci.model2, which = 4, cook.levels = cutoff, id.n = 5)
vif(clin.sci.model2)
library(car)
vif(clin.sci.model2)
library(car)
install.packages('car')
library(car)
vif(clin.sci.model2)
1/vif(clin.sci.model2)
plot(clin.sci.model2, which = 1)
lmBeta(clin.sci.model2)
round(pCorr(clin.sci.model2), 4)
cor(clin.sci$BDI,clin.sci$QoL) # -0.3746403
cor(clin.sci$BDI,clin.sci$QoL,use = "pairwise.complete.obs") # -0.3746403
cor(clin.sci$BDI,clin.sci$QoL,use = "pairwise.complete.obs") # -0.3746403
cor(clin.sci[,vars]) # -0.3746403
cor(clin.sci[,vars],use = "pairwise.complete.obs") # -0.3746403
vars <- c('BDI','QoL')
round(corr.test(clin.sci[,vars]),3)
vars <- c('BDI','QoL')
round(cor(clin.sci[,vars]),3)
cor(clin.sci[,vars])
corr.test(clin.sci[,vars])$t
round(corr.test(clin.sci[,vars])$t,3)
summary(clin.sci.model)$r
summary(clin.sci.model)
summary(clin.sci.model2)
lmBeta(clin.sci.model2)
round(lmBeta(clin.sci.model2),3)
round(pCorr(clin.sci.model2),3)
round(100*pCorr(clin.sci.model2),3)
round(100*pCorr(clin.sci.model2),2)
summary(clin.sci.model2
)
library(SDSFoundations)
res <- TempskiResilience
res <- TempskiResilience
table(res$Group)
bas.sci <- res[res$Group == 'Basic Sciences']
bas.sci <- res[res$Group == 'Basic Sciences',]
names(bas.sci)
whoModel <- lm(QoL ~ WHOQOL.PH + WHOQOL.PSY + WHOQOL.SOC + WHOQOL.ENV, bas.sci)
summary(whoModel)
library(car)
vif(whoModel)
1/vif(whoModel)
plot(whoModel, which = 1)
cutoff <- 4/(whoModel$df)
plot(whoModel, which = 4, cook.levels = cutoff, id.n = 5)
lmBeta(whoModel)
round(pCorr(whoModel), 4)
round(100*pCorr(whoModel),2) # 8.23
corr.test(bas.sci[,vars])$r
vars <- c('QoL', 'WHOQOL.PH', 'WHOQOL.PSY', 'WHOQOL.SOC', 'WHOQOL.ENV')
corr.test(bas.sci[,vars])$r
cor(bas.sci[,vars])
cor(bas.sci[,vars])$r
vars <- c('QoL', 'WHOQOL.PH', 'WHOQOL.PSY', 'WHOQOL.SOC', 'WHOQOL.ENV')
cor(bas.sci[,vars])
vars <- c('QoL', 'WHOQOL.PH', 'WHOQOL.PSY', 'WHOQOL.SOC', 'WHOQOL.ENV')
cor(res[,vars])
whoModel <- lm(MS.QoL ~ WHOQOL.PH + WHOQOL.PSY + WHOQOL.SOC + WHOQOL.ENV, bas.sci)
summary(whoModel)
vars <- c('MS.QoL', 'WHOQOL.PH', 'WHOQOL.PSY', 'WHOQOL.SOC', 'WHOQOL.ENV')
vars <- c('MS.QoL', 'WHOQOL.PH', 'WHOQOL.PSY', 'WHOQOL.SOC', 'WHOQOL.ENV')
cor(res[,vars])
corr.test(res[,vars])$r
vars <- c('MS.QoL', 'WHOQOL.PH', 'WHOQOL.PSY', 'WHOQOL.SOC', 'WHOQOL.ENV')
corr.test(res[,vars])$r
corr.test(res[,vars],use = "pairwise.complete.obs)$r
corr.test(res[,vars], use = "pairwise.complete.obs')$r
corr.test(res[,vars], use = "pairwise.complete.obs')$r
corr.test(res[,vars], use = 'pairwise.complete.obs')$r
corr.test(res[,vars], use = 'pairwise.complete.obs')$r
corr.test(res[,vars], use = 'pairwise.complete.obs')$r
corr.test(res[,vars], use = 'pairwise.complete.obs')$r
corr.test(res[,vars], use = 'pairwise.complete.obs')$r
corr.test(res[,vars], use = 'pairwise.complete.obs')$r
corr.test(res[,vars], use = 'pairwise.complete.obs')
corr.test(res[,vars], use = 'pairwise.complete.obs')$r
vif(whoModel)
1/vif(whoModel)
whoModel
whoModel <- lm(MS.QoL ~ WHOQOL.PH + WHOQOL.PSY + WHOQOL.SOC + WHOQOL.ENV, bas.sci)
summary(whoModel)
vif(whoModel)
plot(whoModel, which = 1)
cutoff <- 4/(whoModel$df)
plot(whoModel, which = 4, cook.levels = cutoff, id.n = 5)
lmBeta(whoModel)
function (model)
round(100*pCorr(whoModel),2) # 8.23
round(100*pCorr(whoModel),2) # 8.23
whoModel$t
whoModel
res <- TempskiResilience
clin.sci <- res[res$Group == 'Clinical Sciences',]
clin.sci
summary(lm(BDI~Age+State.Anxiety+Trait.anxiety,clin.sci))
summary(lm(BDI~Gender+State.Anxiety+Trait.anxiety,clin.sci))
summary(lm(BDI~Gender+Age+State.Anxiety+Trait.anxiety,clin.sci))
summary(lm(BDI~Age+State.Anxiety+Trait.anxiety,clin.sci))
summary(lm(BDI~Female+State.Anxiety+Trait.anxiety,clin.sci))
summary(lm(BDI~Female+Age+State.Anxiety+Trait.anxiety,clin.sci))
model1 <- summary(lm(BDI~Female+Age+State.Anxiety+Trait.anxiety,clin.sci))
summary(model1)
summary(model1)
model1 <- lm(BDI~Female+Age+State.Anxiety+Trait.anxiety,clin.sci)
summary(model1)
lmBeta(model1)
round(lmBeta(model1),3)
round(100*pCorr(model1),2)
SS = 1848.76
df <- 20-2
SS = 1848.76
SS = 1848.76
df <- 20-2
25592/2646
-23.4325 / 12.74
22.245*421
8.32*0.1528
480.78 / 1848.76
480.78 / (1848.76+480.78)
480.78 / (1848.76 - 480.78)
1848.76 / (1848.76 - 480.78)
1848.76 / (1848.76 + 480.78)
'Now we are building non-linear regression models (relationship between output and
inputs is NOT linear)
Business Problem:
- Want to predict salaries based on position title and the level
- We are in HR and are about to give an offer to a potential new employee
- We must negotiate a salary for an interviewee who has 25 yrs experience asking for
a minimum of $160k/yr.
- You in HR + call the previous employer to check that info about their previous salary
- All the info you get from HR is the simple table of salaries for 10 positions + levels'
setwd('C:/Users/NEWNSS/Dropbox/DataScienceMasters/MachineLearning/Udemy/03_Polynomial_Linear_Regression')
# import data
salary <- read.csv('Position_Salaries.csv')
summary(salary)
library(ggplot2)
ggplot(salary) +
geom_point(aes(Level, Salary), colour = 'red') + # plot points
ggtitle('Salary by Position Level')
'   - After plotting, we see a non-linear relationship between salary and position level
- However we know the prospective employee was a regional manager, and it usually
takes ~4 years to get from regional manager to partner (next level up)
- So this employer was between levels 6 and 7, so we can say he was at level 6.5
- Therefore, we can use regression to see if he was bluffing about his previous salary'
head(salary)
# notice that position is directly equivalent to position (basically already encoded)
# only need to use 1 of these cols
new_salaries <- salary[,c('Level','Salary')]
head(new_salaries,10)
# library for splitting data
library(caTools)
set.seed(123)
# don't need to split or feature scale b/c this is such a small dataset (10 obs)
simpleModel1 <- lm(Salary ~ ., training)
summary(simpleModel1)
'Now we are building non-linear regression models (relationship between output and
inputs is NOT linear)
Business Problem:
- Want to predict salaries based on position title and the level
- We are in HR and are about to give an offer to a potential new employee
- We must negotiate a salary for an interviewee who has 25 yrs experience asking for
a minimum of $160k/yr.
- You in HR + call the previous employer to check that info about their previous salary
- All the info you get from HR is the simple table of salaries for 10 positions + levels'
setwd('C:/Users/NEWNSS/Dropbox/DataScienceMasters/MachineLearning/Udemy/03_Polynomial_Linear_Regression')
# import data
salary <- read.csv('Position_Salaries.csv')
summary(salary)
library(ggplot2)
ggplot(salary) +
geom_point(aes(Level, Salary), colour = 'red') + # plot points
ggtitle('Salary by Position Level')
'   - After plotting, we see a non-linear relationship between salary and position level
- However we know the prospective employee was a regional manager, and it usually
takes ~4 years to get from regional manager to partner (next level up)
- So this employer was between levels 6 and 7, so we can say he was at level 6.5
- Therefore, we can use regression to see if he was bluffing about his previous salary'
head(salary)
# notice that position is directly equivalent to position (basically already encoded)
# only need to use 1 of these cols
new_salaries <- salary[,c('Level','Salary')]
head(new_salaries,10)
# library for splitting data
library(caTools)
set.seed(123)
# don't need to split or feature scale b/c this is such a small dataset (10 obs)
lin_reg <- lm(Salary ~ ., new_salaries)
summary(lin_reg)
setwd('C:/Users/NEWNSS/Dropbox/DataScienceMasters/MachineLearning/Udemy/03_Polynomial_Linear_Regression')
# import data
salary <- read.csv('Position_Salaries.csv')
summary(salary)
library(ggplot2)
ggplot(salary) +
geom_point(aes(Level, Salary), colour = 'red') + # plot points
ggtitle('Salary by Position Level')
'   - After plotting, we see a non-linear relationship between salary and position level
- However we know the prospective employee was a regional manager, and it usually
takes ~4 years to get from regional manager to partner (next level up)
- So this employer was between levels 6 and 7, so we can say he was at level 6.5
- Therefore, we can use regression to see if he was bluffing about his previous salary'
head(salary)
# notice that position is directly equivalent to position (basically already encoded)
# only need to use 1 of these cols
new_salaries <- salary[,c('Level','Salary')]
head(new_salaries,10)
# library for splitting data
library(caTools)
set.seed(123)
# don't need to split or feature scale b/c this is such a small dataset (10 obs)
lin_reg <- lm(Salary ~ ., new_salaries)
summary(lin_reg)
new_salaries$level_sq <- new_salaries$Level^2
head(new_salaries)
poly_reg <- lm(Salary ~., new_salaries)
summary(poly_reg)
y.pred <- predict(poly_reg, new_salaries)
ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'green') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Years of Experience') +
ggtitle('Salary by Years of Experience (Training Set)')
ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Salary by Years of Experience (Training Set)')
new_salaries$level_cub <- new_salaries$Level^3
poly_reg_3 <- lm(Salary ~., new_salaries)
summary(poly_reg_3)
ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_3), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Salary by Years of Experience (Training Set)')
y.pred_3 <- predict(poly_reg_3, new_salaries)
ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_3), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Salary by Years of Experience (Training Set)')
y.pred_lr <- predict(lin_reg, new_salaries)
ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_lr), colour = 'red') + # plot regression line
xlab('Levels')
ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_lr), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Linear Regression')
cubed_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_3), colour = 'red') + # plot regression line
xlab('Levels')
squared_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Levels') +
squared_plot
squared_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Levels') +
squared_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Levels')
squared_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Levels')
squared_plot
cubed_plot
cubed_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_3), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Cubed Polynomial Regression')
squared_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Squared Polynomial Regression')
squared_plot
cubed_plot
new_salaries$level_quart <- new_salaries$Level^4
poly_reg_4 <- lm(Salary ~., new_salaries)
summary(poly_reg_4)
y.pred_4 <- predict(poly_reg_4, new_salaries)
cubed_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_4), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Quartered(?) Polynomial Regression')
quartered_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_4), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Quartered(?) Polynomial Regression')
quartered_plot
single_prediction <- data.frame(Level = 6.5)
final_y_predict_lr <- predict(lin_reg, single_prediction)
final_y_predict_lr
final_y_predict_poly <- predict(lin_reg, single_prediction)
final_y_predict_poly
final_y_predict_poly <- predict(poly_reg_4, single_prediction)
final_y_predict_poly
single_prediction_lin_reg <- data.frame(Level = 6.5)
final_y_predict_lr <- predict(lin_reg, single_prediction_lin_reg)
final_y_predict_lr
poly_reg_3
new_salaries
single_prediction_poly_reg <- data.frame(Level = 6.5, Level2 = 6.5^2, Level3 = 6.5^3, Level4 = 6.5^4)
final_y_predict_poly <- predict(poly_reg_4, single_prediction_poly_reg)
single_prediction_poly_reg <- data.frame(Level = 6.5, Level2 = 6.5^2, Level3 = 6.5^3, Level4 = 6.5^4)
single_prediction_poly_reg
final_y_predict_poly <- predict(poly_reg_4, single_prediction_poly_reg)
single_prediction_poly_reg <- data.frame(Level = 6.5, level_sq = 6.5^2, level_cub = 6.5^3, level_quart = 6.5^4)
final_y_predict_poly <- predict(poly_reg_4, single_prediction_poly_reg)
final_y_predict_poly
setwd('C:/Users/NIMZ/Dropbox/DataScienceMasters/MachineLearning/Udemy/03_Polynomial_Linear_Regression')
library(tidyverse)
library(ggplot2)
library(caTools)
# import data
salary <- read.csv('Position_Salaries.csv')
summary(salary)
glimpse(salary)
head(salary)
library(tidyverse)
library(ggplot2)
library(caTools)
# import data
salary <- read.csv('Position_Salaries.csv')
summary(salary)
glimpse(salary)
head(salary)
ggplot(salary) +
geom_histogram(salary)
ggplot(salary) +
geom_histogram(aes(salary))
ggplot(salary) +
geom_histogram(aes(Salary))
ggplot(salary) +
geom_histogram(aes(Salary), binwidth = 20000)
ggplot(salary) +
geom_histogram(aes(Salary), binwidth = 200000)
ggplot(salary) +
geom_histogram(aes(Salary), binwidth = 100000)
ggplot(salary) +
geom_point(aes(Level, Salary), colour = 'red') + # plot points
ggtitle('Salary by Position Level')
# remove positions col
new_salaries <- salary[,c('Level','Salary')]
head(new_salaries,10)
set.seed(123)
lin_reg <- lm(Salary ~ ., new_salaries)
summary(lin_reg)
# add new 2-nd order polynomial Level
new_salaries$level_sq <- new_salaries$Level^2
head(new_salaries)
poly_reg <- lm(Salary ~., new_salaries)
summary(poly_reg)
# training predictions
y.pred <- predict(poly_reg, new_salaries)
(squared_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Squared Polynomial Regression)'))
new_salaries$level_cub <- new_salaries$Level^3
poly_reg_3 <- lm(Salary ~., new_salaries)
summary(poly_reg_3)
y.pred_3 <- predict(poly_reg_3, new_salaries)
(cubed_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_3), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Cubed Polynomial Regression'))
y.pred_lr <- predict(lin_reg, new_salaries)
ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_lr), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Linear Regression)')
squared_plot
cubed_plot
new_salaries$level_quart <- new_salaries$Level^4
poly_reg_4 <- lm(Salary ~., new_salaries)
summary(poly_reg_4)
y.pred_4 <- predict(poly_reg_4, new_salaries)
(quartered_plot <- ggplot(new_salaries) +
geom_point(aes(Level, Salary), colour = 'blue') + # plot points
geom_line(aes(Level, y.pred_4), colour = 'red') + # plot regression line
xlab('Levels') +
ggtitle('Truth or Bluff (Quartered(?) Polynomial Regression'))
single_prediction_lin_reg <- data.frame(Level = 6.5)
(final_y_predict_lr <- predict(lin_reg, single_prediction_lin_reg))
## predict a single new result with Polynomial Linear Regression
single_prediction_poly_reg <- data.frame(Level = 6.5, level_sq = 6.5^2, level_cub = 6.5^3, level_quart = 6.5^4)
final_y_predict_poly <- predict(poly_reg_4, single_prediction_poly_reg)
## predict a single new result with Polynomial Linear Regression
single_prediction_poly_reg <- data.frame(Level = 6.5, level_sq = 6.5^2, level_cub = 6.5^3, level_quart = 6.5^4)
(final_y_predict_poly <- predict(poly_reg_4, single_prediction_poly_reg))
